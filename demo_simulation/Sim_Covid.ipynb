{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d78638a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import SplineTransformer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from collections import OrderedDict\n",
    "from torch import nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "import glob\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ce2513e-3f5f-4b62-9dcb-d786cf7a0063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diag_mat_weights(dimp, type = 'first'):\n",
    "    if type == 'first':\n",
    "        dg = np.zeros((dimp-1, dimp))\n",
    "        for i in range(dimp-1):\n",
    "            dg[i,i] = -1\n",
    "            dg[i,i+1]= 1\n",
    "    elif type == 'second':\n",
    "        dg = np.zeros((dimp-2, dimp))\n",
    "        for i in range(dimp-2):\n",
    "            dg[i,i] = -1\n",
    "            dg[i,i+1]= 2\n",
    "            dg[i,i+2]= -1\n",
    "    else:\n",
    "        pass\n",
    "    return torch.Tensor(dg)\n",
    "    \n",
    "\n",
    "class BSL(nn.Module):\n",
    "    def __init__(self, degree, num_knots, num_neurons, bias = True):\n",
    "        super(BSL, self).__init__()\n",
    "        self.degree = degree\n",
    "        self.num_knots = num_knots\n",
    "        self.num_neurons = num_neurons\n",
    "        self.control_p = nn.Parameter(torch.randn(self.num_knots, self.num_neurons))\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.randn(self.num_neurons))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        self.inter = {}\n",
    "    \n",
    "    def basis_function(self, x, i, k, t):\n",
    "    \n",
    "        # Base case: degree 0 spline\n",
    "        if k == 0:\n",
    "            return ((t[i] <= x) & (x < t[i + 1])).float()\n",
    "    \n",
    "        # Recursive case\n",
    "        denom1 = t[i + k] - t[i]\n",
    "        denom2 = t[i + k + 1] - t[i + 1]\n",
    "    \n",
    "        term1 = 0\n",
    "        if denom1 != 0:\n",
    "            term1 = (x - t[i]) / denom1 * self.basis_function(x, i, k - 1, t)\n",
    "    \n",
    "        term2 = 0\n",
    "        if denom2 != 0:\n",
    "            term2 = (t[i + k + 1] - x) / denom2 * self.basis_function(x, i + 1, k - 1, t)\n",
    "    \n",
    "        return term1 + term2\n",
    "\n",
    "    def knots_distribution(self, dg, nk):\n",
    "\n",
    "        knots = torch.cat([torch.linspace(-0.002, -0.001, steps=dg),            # Add repeated values at the start for clamping\n",
    "            torch.linspace(0, 1, nk-2*dg-2),  # Uniform knot spacing in the middle\n",
    "            torch.linspace(1.001, 1.002, steps=dg)           # Add repeated values at the end for clamping\n",
    "            ]).view(-1,1)\n",
    "        \n",
    "        knots = torch.cat([torch.linspace(0, 1, nk-2)          # Add repeated values at the end for clamping\n",
    "            ]).view(-1,1)\n",
    "\n",
    "        return knots\n",
    "    \n",
    "    def basis_function2(self, x, spl):\n",
    "        basis_output = spl.fit_transform(x.cpu().numpy())\n",
    "        return basis_output\n",
    "            \n",
    "    def forward(self, x):\n",
    "        batch_size, num_features = x.size()\n",
    "        device = x.device\n",
    "        \n",
    "        # Create knot vector and apply B-spline basis functions for each feature\n",
    "\n",
    "        '''\n",
    "        knots = torch.cat([\n",
    "                        torch.zeros(self.degree),               # Add repeated values at the start for clamping\n",
    "                        torch.linspace(0, 1, self.num_knots - self.degree + 1),  # Uniform knot spacing in the middle\n",
    "                        torch.ones(self.degree)                 # Add repeated values at the end for clamping\n",
    "                    ]).to(device)\n",
    "\n",
    "        # Apply B-spline basis functions for each feature\n",
    "\n",
    "        basises = []\n",
    "        \n",
    "        \n",
    "        for feature in range(num_features):\n",
    "            # Calculate B-spline basis functions for this feature\n",
    "            basis = torch.stack([self.basis_function(x[:, feature], i, self.degree, knots) \n",
    "                                 for i in range(self.num_knots)], dim=-1)\n",
    "            basises.append(basis)\n",
    "            \n",
    "        '''\n",
    "    \n",
    "        basises = []\n",
    "        knots = self.knots_distribution(self.degree, self.num_knots)\n",
    "        #knots = knots.to(device)\n",
    "        spl = SplineTransformer(n_knots=self.num_knots, degree=self.degree, knots = knots)\n",
    "\n",
    "        \n",
    "        for feature in range(num_features):\n",
    "            # Calculate B-spline basis functions for this feature\n",
    "            \n",
    "            basis = self.basis_function2(x[:, feature].reshape(-1,1), spl)\n",
    "            basis = torch.Tensor(basis).to(device)\n",
    "            basises.append(basis)\n",
    "        \n",
    "        if num_features == 1:\n",
    "            tout = basises[0] @ self.control_p\n",
    "            self.inter['basic'] = basises[0].T\n",
    "        else:\n",
    "            self.inter['basic'] = torch.reshape(torch.stack(basises, dim = 1), (batch_size, self.num_knots * self.num_neurons)).T\n",
    "            basises = torch.stack(basises)\n",
    "            tout = basises.permute(1,2,0) * self.control_p\n",
    "            tout = tout.sum(dim =1)\n",
    "                \n",
    "        if self.bias is not None:\n",
    "            tout += self.bias        \n",
    "            \n",
    "        return tout\n",
    "\n",
    "\n",
    "class NormLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NormLayer, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        min_val = torch.min(x, axis = 1).values.reshape(-1,1)\n",
    "        max_val = torch.max(x, axis = 1).values.reshape(-1,1)\n",
    "\n",
    "        x = (x - min_val)/(max_val - min_val)  # Rescale to [0, 1]\n",
    "        return x.detach()\n",
    "    \n",
    "class BSpline_block(nn.Module):\n",
    "    def __init__(self, degree, num_knots, num_neurons, dropout = 0.0, bias = True):\n",
    "        super(BSpline_block, self).__init__()\n",
    "\n",
    "        self.block = nn.Sequential(OrderedDict([\n",
    "            ('norm', NormLayer()),\n",
    "            ('BSL', BSL(degree = degree, num_knots = num_knots, num_neurons = num_neurons, bias = bias)),\n",
    "            ('drop', nn.Dropout(dropout)),\n",
    "        ]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "        \n",
    "class StackBS_block(nn.Module):\n",
    "    def __init__(self, block, degree, num_knots, num_neurons, num_blocks, dropout = 0.0, bias = True):\n",
    "        super().__init__()\n",
    "        self.model = nn.ModuleDict({\n",
    "            f'block_{i}': block(degree = degree, num_knots = num_knots, num_neurons = num_neurons)\n",
    "            for i in range(num_blocks)\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        for name, block in self.model.items():\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3231c48-f7b3-4619-8cf8-4a7bdd4cf4be",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46c7eef1-9f10-48e6-a6ec-fc1df9ac3a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "        scheduler.step()\n",
    "        \n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            output = torch.log_softmax(output, dim=1)\n",
    "            _, pred = torch.max(output, dim = 1)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac7b108b-06e9-4891-b340-66fe802bfa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "dataset_root = '/home/users/yhung7/DPS/Chest'\n",
    "train_dir = os.path.join(dataset_root, 'train')\n",
    "test_dir = os.path.join(dataset_root, 'val')\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform_train)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform_test)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cd18a6-5a45-4860-98a7-2bf0e99b63ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torchvision.models.densenet121(pretrained=True).to(device)\n",
    "\n",
    "#for param in model.parameters():\n",
    "    #param.requires_grad = False   \n",
    "    \n",
    "dg = 3; nk = 15; nm = 50; nl = 2; doutput = 2; Iteration = 100\n",
    "\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    torch.nn.Linear(num_ftrs, nm),\n",
    "    StackBS_block(BSpline_block, degree = dg, num_knots = nk, num_neurons = nm, num_blocks = nl, dropout = 0.0),\n",
    "    torch.nn.Linear(nm, doutput),\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) # Learning Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a9942-375c-4965-a78e-d4bfcb5fd617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2a1697c-2a51-44e0-b467-cd4aecd081d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100 [0/5216 (0%)]\tLoss: 0.914918\n",
      "Train Epoch: 100 [640/5216 (12%)]\tLoss: 0.707362\n",
      "Train Epoch: 100 [1280/5216 (25%)]\tLoss: 0.693475\n",
      "Train Epoch: 100 [1920/5216 (37%)]\tLoss: 0.658648\n",
      "Train Epoch: 100 [2560/5216 (49%)]\tLoss: 0.641516\n",
      "Train Epoch: 100 [3200/5216 (61%)]\tLoss: 0.686845\n",
      "Train Epoch: 100 [3840/5216 (74%)]\tLoss: 0.659099\n",
      "Train Epoch: 100 [4480/5216 (86%)]\tLoss: 0.670284\n",
      "Train Epoch: 100 [5120/5216 (98%)]\tLoss: 0.675621\n",
      "\n",
      "Test set: Average loss: -0.4572, Accuracy: 352/703 (50%)\n",
      "\n",
      "Train Epoch: 100 [0/5216 (0%)]\tLoss: 0.658564\n",
      "Train Epoch: 100 [640/5216 (12%)]\tLoss: 0.677514\n",
      "Train Epoch: 100 [1280/5216 (25%)]\tLoss: 0.637707\n",
      "Train Epoch: 100 [1920/5216 (37%)]\tLoss: 0.635972\n",
      "Train Epoch: 100 [2560/5216 (49%)]\tLoss: 0.679317\n",
      "Train Epoch: 100 [3200/5216 (61%)]\tLoss: 0.721688\n",
      "Train Epoch: 100 [3840/5216 (74%)]\tLoss: 0.708932\n",
      "Train Epoch: 100 [4480/5216 (86%)]\tLoss: 0.670424\n",
      "Train Epoch: 100 [5120/5216 (98%)]\tLoss: 0.616953\n",
      "\n",
      "Test set: Average loss: -0.4423, Accuracy: 360/703 (51%)\n",
      "\n",
      "Train Epoch: 100 [0/5216 (0%)]\tLoss: 0.712413\n",
      "Train Epoch: 100 [640/5216 (12%)]\tLoss: 0.685355\n",
      "Train Epoch: 100 [1280/5216 (25%)]\tLoss: 0.699610\n",
      "Train Epoch: 100 [1920/5216 (37%)]\tLoss: 0.682908\n",
      "Train Epoch: 100 [2560/5216 (49%)]\tLoss: 0.712385\n",
      "Train Epoch: 100 [3200/5216 (61%)]\tLoss: 0.714602\n",
      "Train Epoch: 100 [3840/5216 (74%)]\tLoss: 0.692214\n",
      "Train Epoch: 100 [4480/5216 (86%)]\tLoss: 0.682504\n",
      "Train Epoch: 100 [5120/5216 (98%)]\tLoss: 0.647173\n",
      "\n",
      "Test set: Average loss: -0.4417, Accuracy: 339/703 (48%)\n",
      "\n",
      "Train Epoch: 100 [0/5216 (0%)]\tLoss: 0.659666\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [68], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, Iteration\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIteration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     test(model, device, test_loader)\n",
      "Cell \u001b[0;32mIn [65], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 7\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[1;32m      9\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/sysapps/ubuntu-applications/python/venv/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/sysapps/ubuntu-applications/python/venv/pytorch/lib/python3.9/site-packages/torchvision/models/densenet.py:214\u001b[0m, in \u001b[0;36mDenseNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 214\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(features, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    216\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(out, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/sysapps/ubuntu-applications/python/venv/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/sysapps/ubuntu-applications/python/venv/pytorch/lib/python3.9/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/sysapps/ubuntu-applications/python/venv/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/sysapps/ubuntu-applications/python/venv/pytorch/lib/python3.9/site-packages/torchvision/models/densenet.py:123\u001b[0m, in \u001b[0;36m_DenseBlock.forward\u001b[0;34m(self, init_features)\u001b[0m\n\u001b[1;32m    121\u001b[0m features \u001b[38;5;241m=\u001b[39m [init_features]\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 123\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(new_features)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(features, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/sysapps/ubuntu-applications/python/venv/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/sysapps/ubuntu-applications/python/venv/pytorch/lib/python3.9/site-packages/torchvision/models/densenet.py:91\u001b[0m, in \u001b[0;36m_DenseLayer.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn_function(prev_features)\n\u001b[0;32m---> 91\u001b[0m new_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbottleneck_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     93\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(new_features, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[0;32m/sysapps/ubuntu-applications/python/venv/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/sysapps/ubuntu-applications/python/venv/pytorch/lib/python3.9/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sysapps/ubuntu-applications/python/venv/pytorch/lib/python3.9/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(1, Iteration+1):\n",
    "    train(model, device, train_loader, optimizer, Iteration)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ab76e1-4588-4bcb-97e4-e0eaf8164a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dfaedd-becf-4ab8-9419-809e72c05d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3644a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model setting:\n",
    "\n",
    "`device`: running the program with cpu or gpu\n",
    "`tmc`: the classifier that equip with DNN-S \n",
    "`nm` : number of neuron in DNN-S\n",
    "`nk` : number of knot in DNN-S\n",
    "`patientc` : (early-stop crierion) If the model didn't improve in n epoch then stop.\n",
    "`patientr` : If the model didn't improve in n epoch then decrease learning rate with specific factor.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# experiment setting\n",
    "Iteration = 10000; bloss_list = []; tor = 1e-5; lr_tor = 1e-6\n",
    "patientc = 10; patientr = 5; tpat = 0; bloss = 9999\n",
    "nm = 100; nk = 15; doutput = 2\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model parameter \n",
    "tmc = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True)\n",
    "learning_r = 1e-2\n",
    "optimizer = torch.optim.Adam(tmc.parameters(), lr=learning_r)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6a07ad2-d621-40af-8634-8a143e45361d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Iteration):\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Forward pass: Compute predicted y by passing x to the modelsp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     pyb_af \u001b[38;5;241m=\u001b[39m tmc(\u001b[43mX_train\u001b[49m)\n\u001b[1;32m      5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(pyb_af, y_train); bloss_list\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (t \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m ((bloss_list[t\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mbloss_list[t])\u001b[38;5;241m<\u001b[39mtor):        \n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "for t in range(Iteration):\n",
    "\n",
    "    # Forward pass: Compute predicted y by passing x to the modelsp\n",
    "    pyb_af = tmc(X_train)\n",
    "    loss = criterion(pyb_af, y_train); bloss_list.append(loss.item())\n",
    "    \n",
    "    if (t > 0) and ((bloss_list[t-1]-bloss_list[t])<tor):        \n",
    "        if (tpat % patientr) == 0:\n",
    "            learning_r *= 0.2 \n",
    "            tpat += 1\n",
    "            #print('Learning rate reduce to ', learning_r)\n",
    "            optimizer = torch.optim.Adam(tmc.parameters(), lr=learning_r)\n",
    "            if learning_r <= lr_tor:\n",
    "                print('Convergence!')\n",
    "                break\n",
    "        elif tpat < patientc:\n",
    "            tpat += 1\n",
    "            pass\n",
    "        else:\n",
    "            print('Convergence!')\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        if loss < bloss:\n",
    "            #torch.save(tmc.state_dict(), './brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk))\n",
    "            bloss = loss.item()\n",
    "            tpat = 0\n",
    "        tpat += 1\n",
    "\n",
    "    if tpat == patientc:\n",
    "        print('Convergence!')\n",
    "        break\n",
    "    \n",
    "    prediction = torch.argmax(pyb_af, axis = 1)\n",
    "    acc = (torch.argmax(pyb_af, axis = 1) == y_train).sum()/len(y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if(t % 10 == 0):\n",
    "        print('| Epoch: ',t+1,'/',str(Iteration),' | Loss: ', np.round(loss.item(), 4),' | Acc: ', acc.item())\n",
    "        if(t % 50 == 0):\n",
    "            with torch.no_grad():\n",
    "                print((torch.argmax(tmc(X_test).detach(), axis = 1) == y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f42ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "`ECM_epoch`: number of epoch to run the ecm tuning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"Running the ECM tunning for penalty in each layer\")\n",
    "\n",
    "ECM_epoch = 10\n",
    "with torch.no_grad():\n",
    "    eval_model = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "    eval_model.load_state_dict(torch.load('./brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "\n",
    "    WB = eval_model.classifier.sp1.control_p\n",
    "    DB = diag_mat_weights(WB.size()[0], 'second').to(device)\n",
    "    \n",
    "    BestGCV = np.inf\n",
    "    n = X_train.size()[0]\n",
    "    \n",
    "    for i in range(ECM_epoch):\n",
    "        eval_model.train()\n",
    "        MPSy = eval_model(X_train)\n",
    "\n",
    "        # update following layer except for last layer\n",
    "        LambdaB1 = ECM(model = eval_model.classifier, num_neurons = nm, num_knots = nk, L = 1)\n",
    "        \n",
    "        B1 = eval_model.classifier.inter['ebasic']\n",
    "        By1 = eval_model.classifier.inter['basic']\n",
    "        P2 = By1 @ torch.inverse(By1.T @ By1) @ By1.T\n",
    "\n",
    "        \n",
    "        size1 = B1.size()[1]\n",
    "        B1 = B1.view(nk, nm, size1)\n",
    "\n",
    "        NW1 = torch.empty((nk, nm))\n",
    "        NB1 = torch.empty((nm))\n",
    "\n",
    "        \n",
    "        for i in range(nm):\n",
    "            B1y = By1[:,i] - eval_model.classifier.sp1.bias.data[i]\n",
    "            BB1 = B1[:,i].T\n",
    "\n",
    "            # Update the weights and bias\n",
    "            NW1[:, i] = (torch.inverse(BB1.T @ BB1 + (LambdaB1/size1) * (DB.T @ DB)) @ BB1.T @ B1y)\n",
    "            NB1[i] = torch.mean(By1[:,i] - (NW1[:,i] @ BB1.T))\n",
    "            \n",
    "        # update the weight\n",
    "        getattr(eval_model.classifier.sp1, 'control_p').data = NW1; getattr(eval_model.classifier.sp1, 'bias').data = NB1\n",
    "\n",
    "        # update the last layer\n",
    "        WholeB = torch.cat((torch.ones((n,1)), By1), dim = 1)\n",
    "        NLn2W = (torch.inverse(WholeB.T @ WholeB) @ WholeB.T @ MPSy.type(torch.FloatTensor)).T\n",
    "        getattr(eval_model.classifier.ln2, 'bias').data = NLn2W[:,0]; getattr(eval_model.classifier.ln2, 'weight').data = NLn2W[:,1:]\n",
    "        \n",
    "        eval_model.eval()\n",
    "        pred_postecm = eval_model(X_train)\n",
    "        CLoss = criterion(pred_postecm.detach(), y_train)\n",
    "        trainGCV = CLoss/(n-torch.trace(P2))**2\n",
    "        \n",
    "        if trainGCV < BestGCV:\n",
    "            BestLambdaB = LambdaB1\n",
    "            BestGCV = trainGCV\n",
    "            \n",
    "        print(f\"Lambda: {np.round(LambdaB1, 5)}| Training Loss: {np.round(CLoss, 5)}| Training GCV: {trainGCV.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f20ef1a-c2f0-4e8a-984c-d0d016afc0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "`fast_epoch`: number of epoch to run the fast tuning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "fast_epoch = 201\n",
    "DPS = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "DPS.load_state_dict(torch.load('./brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "lr_ft = 1e-2\n",
    "optimizer = torch.optim.Adam(DPS.parameters(), lr=lr_ft)\n",
    "\n",
    "for t in range(1, fast_epoch):\n",
    "\n",
    "    # Forward pass: Compute predicted y by passing x to the modelsp\n",
    "    pyb_af = DPS(X_train)\n",
    "\n",
    "    WB1 = DPS.classifier.sp1.control_p.data; DB1 = diag_mat_weights(WB1.size()[0]).to(device)\n",
    "\n",
    "    loss = criterion(pyb_af, y_train) + (BestLambdaB/n) * torch.norm(DB1 @ WB1)\n",
    "    bloss_list.append(loss.item())\n",
    "    \n",
    "    prediction = torch.argmax(pyb_af, axis = 1)\n",
    "    acc = (torch.argmax(pyb_af, axis = 1) == y_train).sum()/len(y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if t % 10 == 0:\n",
    "        print('| Epoch: ',t+1,'/',str(Iteration),' | Loss: ', loss.item(),' | Acc: ', np.round(acc.item(), 5))\n",
    "        if t % 100 == 0:\n",
    "            with torch.no_grad():\n",
    "                print((torch.argmax(DPS(X_test).detach(), axis = 1) == y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd8e860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c657077",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRODBSplineLayerMultiFeature(nn.Module):\n",
    "    def __init__(self, input_dim, degree, num_knots, output_dim, num_neurons, bias = True):\n",
    "        super(PRODBSplineLayerMultiFeature, self).__init__()\n",
    "        self.degree = degree\n",
    "        self.num_knots = num_knots\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_neurons = num_neurons\n",
    "        \n",
    "        if input_dim == 2:\n",
    "            self.control_p = nn.Parameter(torch.randn(self.num_knots**2, self.output_dim))\n",
    "        else:\n",
    "            self.control_p = nn.Parameter(torch.randn(self.num_knots, self.num_neurons))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.randn(self.num_neurons))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        self.inter = {}\n",
    "    \n",
    "    def basis_function(self, x, i, k, t):\n",
    "    \n",
    "        # Base case: degree 0 spline\n",
    "        if k == 0:\n",
    "            return ((t[i] <= x) & (x < t[i + 1])).float()\n",
    "    \n",
    "        # Recursive case\n",
    "        denom1 = t[i + k] - t[i]\n",
    "        denom2 = t[i + k + 1] - t[i + 1]\n",
    "    \n",
    "        term1 = 0\n",
    "        if denom1 != 0:\n",
    "            term1 = (x - t[i]) / denom1 * self.basis_function(x, i, k - 1, t)\n",
    "    \n",
    "        term2 = 0\n",
    "        if denom2 != 0:\n",
    "            term2 = (t[i + k + 1] - x) / denom2 * self.basis_function(x, i + 1, k - 1, t)\n",
    "    \n",
    "        return term1 + term2\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, num_features = x.size()\n",
    "        device = x.device\n",
    "        \n",
    "        # Create knot vector\n",
    "        # knots = torch.linspace(0, 1, self.num_knots + self.degree + 1).to(device)\n",
    "        knots = torch.cat([\n",
    "                        torch.zeros(self.degree),               # Add repeated values at the start for clamping\n",
    "                        torch.linspace(0, 1, self.num_knots - self.degree + 1),  # Uniform knot spacing in the middle\n",
    "                        torch.ones(self.degree)                 # Add repeated values at the end for clamping\n",
    "                    ]).to(device)\n",
    "        # Apply B-spline basis functions for each feature\n",
    "        basises = []\n",
    "    \n",
    "        \n",
    "        for feature in range(num_features):\n",
    "            # Calculate B-spline basis functions for this feature\n",
    "            basis = torch.stack([self.basis_function(x[:, feature], i, self.degree, knots) \n",
    "                                 for i in range(self.num_knots)], dim=-1)\n",
    "            basises.append(basis)\n",
    "            \n",
    "        if num_features == 1:\n",
    "            tout = basises[0] @ self.control_p\n",
    "            self.inter['eachbasic'] = basises[0].T\n",
    "        else:\n",
    "            #self.inter['basic'] = torch.reshape(torch.stack(basises, dim = 1), (batch_size, self.num_knots * self.num_neurons)).T\n",
    "            self.inter['eachbasic'] = torch.reshape(torch.stack(basises, dim = 1), (batch_size, self.num_knots * self.num_neurons)).T\n",
    "            \n",
    "            basises = torch.stack(basises)\n",
    "            tout = basises.permute(1,2,0) * self.control_p\n",
    "            tout = tout.sum(dim =1)\n",
    "                \n",
    "        if self.bias is not None:\n",
    "            tout += self.bias        \n",
    "\n",
    "        self.inter['basicoutput'] = tout\n",
    "        \n",
    "        return tout\n",
    "        \n",
    "class DNNS2(nn.Module):\n",
    "    def __init__(self, input_dim, degree, num_knots, num_neurons, output_dim, bias):\n",
    "        super(DNNS2, self).__init__()\n",
    "        self.num_neurons = num_neurons\n",
    "        self.num_knots = num_knots\n",
    "        self.ln1 = nn.Linear(input_dim, num_neurons)\n",
    "        self.nm1 = NormLayer() \n",
    "        self.sp1 = PRODBSplineLayerMultiFeature(input_dim = 1, degree = degree, num_knots = num_knots, num_neurons = num_neurons, output_dim= output_dim, bias = True)\n",
    "        self.nm2 = NormLayer() \n",
    "        self.sp2 = PRODBSplineLayerMultiFeature(input_dim = 1, degree = degree, num_knots = num_knots, num_neurons = num_neurons, output_dim= output_dim, bias = True)\n",
    "        self.ln2 = nn.Linear(num_neurons, output_dim)\n",
    "        self.inter = {}\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ln1out = self.ln1(x)\n",
    "        ln1out = self.nm1(ln1out)\n",
    "        \n",
    "        device = ln1out.device\n",
    "        batch_size, _ = x.size()\n",
    "        \n",
    "        # # # # # # # # # # # # # #\n",
    "        #         SPLINE          #\n",
    "        # # # # # # # # # # # # # #\n",
    "        \n",
    "        sp1out = self.sp1(ln1out)\n",
    "        sp1out = self.nm2(sp1out)\n",
    "\n",
    "        # # # # # # # # # # # # # #\n",
    "        #         SPLINE 2        #\n",
    "        # # # # # # # # # # # # # #\n",
    "        \n",
    "        sp2out = self.sp2(sp1out)\n",
    "        ln2out = self.ln2(sp2out)\n",
    "        \n",
    "        return ln2out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdfa154",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TumorClassifier(nn.Module):\n",
    "    def __init__(self, Fin, dg, nk, nm, Fout, bias):\n",
    "        super(TumorClassifier, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.gap = nn.Flatten()\n",
    "        self.classifier = DNNS2(input_dim = 32*56*56, degree = dg, num_knots = nk, num_neurons = nm, output_dim = Fout, bias = True).to(device)\n",
    "        self.sm = nn.Softmax(dim = 1)\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.gap(x)\n",
    "        x = self.classifier(x)\n",
    "        x = self.sm(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "95e298a8-e59c-4e6f-a128-97f89518f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\"\"\"\n",
    "Model setting:\n",
    "\n",
    "`device`: running the program with cpu or gpu\n",
    "`tmc`: the classifier that equip with DNN-S \n",
    "`nm` : number of neuron in DNN-S\n",
    "`nk` : number of knot in DNN-S\n",
    "`patientc` : (early-stop crierion) If the model didn't improve in n epoch then stop.\n",
    "`patientr` : If the model didn't improve in n epoch then decrease learning rate with specific factor.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# experiment setting\n",
    "Iteration = 10000; bloss_list = []; tor = 1e-5; lr_tor = 1e-6\n",
    "patientc = 10; patientr = 5; tpat = 0; bloss = 9999\n",
    "nm = 100; nk = 15; doutput = 2\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model parameter \n",
    "tmc = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True)\n",
    "learning_r = 1e-2\n",
    "optimizer = torch.optim.Adam(tmc.parameters(), lr=learning_r)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3b8d95b3-4114-4843-868c-f0fb71da6b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:  1 / 100  | Loss:  0.6802  | Acc:  0.593999981880188\n",
      "tensor(0.5733)\n",
      "| Epoch:  11 / 100  | Loss:  0.6035  | Acc:  0.722000002861023\n",
      "| Epoch:  21 / 100  | Loss:  0.5478  | Acc:  0.7919999957084656\n",
      "| Epoch:  31 / 100  | Loss:  0.5064  | Acc:  0.8199999928474426\n",
      "| Epoch:  41 / 100  | Loss:  0.4776  | Acc:  0.8560000061988831\n",
      "| Epoch:  51 / 100  | Loss:  0.4547  | Acc:  0.8899999856948853\n",
      "tensor(0.7667)\n",
      "| Epoch:  61 / 100  | Loss:  0.4357  | Acc:  0.8939999938011169\n",
      "| Epoch:  71 / 100  | Loss:  0.4198  | Acc:  0.9139999747276306\n",
      "| Epoch:  81 / 100  | Loss:  0.4061  | Acc:  0.9259999990463257\n",
      "| Epoch:  91 / 100  | Loss:  0.3934  | Acc:  0.9419999718666077\n"
     ]
    }
   ],
   "source": [
    "for t in range(Iteration):\n",
    "\n",
    "    # Forward pass: Compute predicted y by passing x to the modelsp\n",
    "    pyb_af = tmc(X_train)\n",
    "    loss = criterion(pyb_af, y_train); bloss_list.append(loss.item())\n",
    "    \n",
    "    if (t > 0) and ((bloss_list[t-1]-bloss_list[t])<tor):        \n",
    "        if (tpat % patientr) == 0:\n",
    "            learning_r *= 0.2 \n",
    "            tpat += 1\n",
    "            #print('Learning rate reduce to ', learning_r)\n",
    "            optimizer = torch.optim.Adam(tmc.parameters(), lr=learning_r)\n",
    "            if learning_r <= lr_tor:\n",
    "                print('Convergence!')\n",
    "                break\n",
    "        elif tpat < patientc:\n",
    "            tpat += 1\n",
    "            pass\n",
    "        else:\n",
    "            print('Convergence!')\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        if loss < bloss:\n",
    "            #torch.save(tmc.state_dict(), './brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk))\n",
    "            bloss = loss.item()\n",
    "            tpat = 0\n",
    "        tpat += 1\n",
    "\n",
    "    if tpat == patientc:\n",
    "        print('Convergence!')\n",
    "        break\n",
    "    \n",
    "    prediction = torch.argmax(pyb_af, axis = 1)\n",
    "    acc = (torch.argmax(pyb_af, axis = 1) == y_train).sum()/len(y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if(t % 10 == 0):\n",
    "        print('| Epoch: ',t+1,'/',str(Iteration),' | Loss: ', np.round(loss.item(), 4),' | Acc: ', acc.item())\n",
    "        if(t % 100 == 0):\n",
    "            with torch.no_grad():\n",
    "                print((torch.argmax(tmc(X_test).detach(), axis = 1) == y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "225c6bee-4b98-451f-8491-a49f4bba31d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    eval_model = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "    eval_model.load_state_dict(torch.load('./2brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "    pred_postecm = eval_model(X_train)\n",
    "    CLoss = criterion(pred_postecm.detach(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ae012a20-9b3f-4152-846f-c7d04b52301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ECM(model, num_neurons, num_knots, initial_xi = 1, initial_sigma = 1, initial_lambda = 1e-4):\n",
    "    lambdab = initial_lambda\n",
    "    sigma = initial_sigma\n",
    "    xi = initial_xi\n",
    "\n",
    "    B = model.inter['eachbasic']\n",
    "    By = model.inter['basicoutput']\n",
    "    WB = model.control_p\n",
    "        \n",
    "    DB = diag_mat_weights(WB.size()[0]).to(device)\n",
    "    size = B.size()[1]\n",
    "    S = DB.T @ DB\n",
    "    Cov_a = (xi**2)* torch.linalg.pinv(S)\n",
    "    Cov_e = torch.eye(size*num_neurons)* sigma\n",
    "    \n",
    "    block_y = torch.reshape(By, (-1,1))\n",
    "    flatB = B.view(num_neurons, num_knots, size)\n",
    "        \n",
    "    sqr_xi= 0\n",
    "    sqr_sig = 0\n",
    "    \n",
    "    for i in range(num_neurons):\n",
    "        Ncov = (Cov_a -(Cov_a @ flatB[i]) @ (torch.linalg.pinv(flatB[i].T @ Cov_a @ flatB[i] + Cov_e[size*i:size*(i+1),size*i:size*(i+1)]) @ flatB[i].T @ Cov_a))\n",
    "        Nmu = (Cov_a @ flatB[i]) @ (torch.linalg.pinv(flatB[i].T @ Cov_a @ flatB[i] + Cov_e[size*i:size*(i+1),size*i:size*(i+1)])) @ By[:,i].reshape(-1,1)\n",
    "        \n",
    "        first_xi = S @ Ncov\n",
    "        second_xi = (Nmu.T @ S @ Nmu)\n",
    "        sqr_xi += torch.trace(first_xi) + second_xi\n",
    "            \n",
    "        first_sig = torch.norm(By[:,i])\n",
    "        second_sig = 2 * (By[:,i] @ flatB[i].T) @ Nmu \n",
    "        third_sig = torch.trace((flatB[i] @ flatB[i].T) @ Ncov)\n",
    "        four_sig = (Nmu.T @ flatB[i] @ flatB[i].T @ Nmu)\n",
    "        \n",
    "        sqr_sig += (first_sig + second_sig + third_sig + four_sig)\n",
    "    \n",
    "    sqr_xi /= num_neurons\n",
    "    sqr_sig /= (num_neurons*size)\n",
    "    \n",
    "    Lambda = sqr_sig/sqr_xi\n",
    "    \n",
    "    return Lambda.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "eda1c8f3-fd95-40e3-9816-d4edac44456f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the ECM tunning for penalty in each layer\n",
      "Lambda: [0.30183088779449463, 0.30312493443489075]| Training Loss: 0.7657999992370605| Training GCV: 4.786255885846913e-06\n",
      "Lambda: [0.973455011844635, 0.6522708535194397]| Training Loss: 0.8041099905967712| Training GCV: 4.120976882404648e-06\n",
      "Lambda: [1.3706945180892944, 0.3747212588787079]| Training Loss: 0.7974600195884705| Training GCV: 5.1150018407497555e-06\n",
      "Lambda: [1.8239096403121948, 0.3827195465564728]| Training Loss: 0.8612599968910217| Training GCV: 4.769452061736956e-06\n",
      "Lambda: [1.5904974937438965, 1.7096126079559326]| Training Loss: 0.7672600150108337| Training GCV: 3.7891347801632946e-06\n",
      "Lambda: [1.670275092124939, 1.7180237770080566]| Training Loss: 0.7532600164413452| Training GCV: 3.5555015074351104e-06\n",
      "Lambda: [1.777961254119873, 0.859359860420227]| Training Loss: 0.907260000705719| Training GCV: 4.15523027186282e-06\n",
      "Lambda: [1.9107773303985596, 1.430779218673706]| Training Loss: 0.7932599782943726| Training GCV: 3.4246222639922053e-06\n",
      "Lambda: [1.9577510356903076, 2.0410945415496826]| Training Loss: 0.8152599930763245| Training GCV: 3.541840897014481e-06\n",
      "Lambda: [1.9773733615875244, 1.1929782629013062]| Training Loss: 0.7972599864006042| Training GCV: 3.7175316265347647e-06\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "`ECM_epoch`: number of epoch to run the ecm tuning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "LoP = 2\n",
    "PSname = ['sp'+str(i+1) for i in range(LoP)]\n",
    "ECM_epoch = 10\n",
    "\n",
    "print(\"Running the ECM tunning for penalty in each layer\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    eval_model = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "    eval_model.load_state_dict(torch.load('./2brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "\n",
    "    BestGCV = np.inf\n",
    "    n = X_train.size()[0]\n",
    "    \n",
    "    for i in range(ECM_epoch):\n",
    "        eval_model.train()\n",
    "        MPSy = eval_model(X_train)\n",
    "    \n",
    "        # update following layer except for last layer\n",
    "        LambdaL = []\n",
    "        for layer in PSname:\n",
    "            splayer = getattr(eval_model.classifier, layer)\n",
    "            WB = getattr(splayer, 'control_p')\n",
    "            DB = diag_mat_weights(WB.size()[0], 'second').to(device)\n",
    "            LambdaB = ECM(model = getattr(eval_model.classifier, layer), num_neurons = nm, num_knots = nk)\n",
    "            LambdaL.append(LambdaB)\n",
    "            \n",
    "            B1 = getattr(eval_model.classifier, layer).inter['eachbasic']\n",
    "            By1 = getattr(eval_model.classifier, layer).inter['basicoutput']\n",
    "            P2 = By1 @ torch.inverse(By1.T @ By1) @ By1.T\n",
    "    \n",
    "            size1 = B1.size()[1]\n",
    "            B1 = B1.view(nk, nm, size1)\n",
    "    \n",
    "            NW1 = torch.empty((nk, nm))\n",
    "            NB1 = torch.empty((nm))\n",
    "    \n",
    "        \n",
    "            for i in range(nm):\n",
    "                B1y = By1[:,i] - getattr(eval_model.classifier, layer).bias.data[i]\n",
    "                BB1 = B1[:,i].T\n",
    "        \n",
    "                # Update the weights and bias\n",
    "                NW1[:, i] = (torch.inverse(BB1.T @ BB1 + (LambdaB/size1) * (DB.T @ DB)) @ BB1.T @ B1y)\n",
    "                NB1[i] = torch.mean(By1[:,i] - (NW1[:,i] @ BB1.T))\n",
    "                \n",
    "            # update the weight\n",
    "            getattr(splayer, 'control_p').data = NW1; getattr(splayer, 'bias').data = NB1\n",
    "    \n",
    "        # update the last layer\n",
    "        WholeB = torch.cat((torch.ones((n,1)), By1), dim = 1)\n",
    "        NLn2W = (torch.inverse(WholeB.T @ WholeB) @ WholeB.T @ MPSy.type(torch.FloatTensor)).T\n",
    "        \n",
    "        getattr(eval_model.classifier.ln2, 'bias').data = NLn2W[:,0]; getattr(eval_model.classifier.ln2, 'weight').data = NLn2W[:,1:]\n",
    "        \n",
    "        eval_model.eval()\n",
    "        pred_postecm = eval_model(X_train)\n",
    "        CLoss = criterion(pred_postecm.detach(), y_train)\n",
    "        trainGCV = CLoss/(n-torch.trace(P2))**2\n",
    "        \n",
    "        if trainGCV < BestGCV:\n",
    "            BestLambdaB = LambdaB1\n",
    "            BestGCV = trainGCV\n",
    "            \n",
    "        print(f\"Lambda: {LambdaL}| Training Loss: {np.round(CLoss, 5)}| Training GCV: {trainGCV.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a9449ea7-7a9c-4ad4-8659-94451e6fc730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "`fast_epoch`: number of epoch to run the fast tuning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "fast_epoch = 201\n",
    "D2PS = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "D2PS.load_state_dict(torch.load('./2brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "lr_ft = 1e-2\n",
    "optimizer = torch.optim.Adam(D2PS.parameters(), lr=lr_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72b6da-e9b1-40dd-a842-5716c2d02a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(1, fast_epoch):\n",
    "\n",
    "    # Forward pass: Compute predicted y by passing x to the modelsp\n",
    "    pyb_af = D2PS(X_train)\n",
    "    loss = criterion(pyb_af, y_train)\n",
    "    \n",
    "    for l in range(len(PSname)):\n",
    "        WB = getattr(D2PS.classifier, PSname[l]).control_p.data; DB = diag_mat_weights(WB.size()[0]).to(device)\n",
    "        loss += (LambdaL[l]/n) * torch.norm(DB @ WB)\n",
    "            \n",
    "    prediction = torch.argmax(pyb_af, axis = 1)\n",
    "    acc = (torch.argmax(pyb_af, axis = 1) == y_train).sum()/len(y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if t % 10 == 0:\n",
    "        print('| Epoch: ',t+1,'/',str(Iteration),' | Loss: ', loss.item(),' | Acc: ', np.round(acc.item(), 5))\n",
    "        if t % 100 == 0:\n",
    "            with torch.no_grad():\n",
    "                print((torch.argmax(D2PS(X_test).detach(), axis = 1) == y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd468e2a-5be2-4a58-a89e-464add088fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07b9d3f-6c96-455e-a47f-9d373b800622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38f6af04-255a-4ac1-a0d8-c6331dc598c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ECM(par, initial_xi = 1, initial_sigma = 1, initial_lambda = 1e-4):\n",
    "    lambdab = initial_lambda\n",
    "    sigma = initial_sigma\n",
    "    xi = initial_xi\n",
    "    \n",
    "    n_block, num_knots, num_neurons = par['wbasic'].size()\n",
    "    ls_lambda = torch.empty(n_block)\n",
    "    \n",
    "    for l in range(n_block):\n",
    "        B = par['ebasic'][l]\n",
    "        By = par['basic'][l]\n",
    "        WB = par['wbasic'][l]\n",
    "        \n",
    "        DB = diag_mat_weights(WB.size()[0]).to(device)\n",
    "        size = B.size()[1]\n",
    "        S = DB.T @ DB\n",
    "        Cov_a = (xi**2)* torch.linalg.pinv(S)\n",
    "        Cov_a.to(device)\n",
    "        Cov_e = (torch.eye(size*num_neurons)* sigma).to(device)\n",
    "        \n",
    "        block_y = torch.reshape(By, (-1,1))\n",
    "        flatB = B.view(num_neurons, num_knots, size)\n",
    "            \n",
    "        sqr_xi= 0\n",
    "        sqr_sig = 0\n",
    "\n",
    "        for i in range(num_neurons):\n",
    "            Ncov = (Cov_a -(Cov_a @ flatB[i]) @ (torch.linalg.inv(flatB[i].T @ Cov_a @ flatB[i] + Cov_e[size*i:size*(i+1),size*i:size*(i+1)]) @ flatB[i].T @ Cov_a))\n",
    "            Nmu = (Cov_a @ flatB[i]) @ (torch.linalg.inv(flatB[i].T @ Cov_a @ flatB[i] + Cov_e[size*i:size*(i+1),size*i:size*(i+1)])) @ By[:,i].reshape(-1,1)\n",
    "            \n",
    "            first_xi = S @ Ncov\n",
    "            second_xi = (Nmu.T @ S @ Nmu)\n",
    "            sqr_xi += torch.trace(first_xi) + second_xi\n",
    "                \n",
    "            first_sig = torch.norm(By[:,i])\n",
    "            second_sig = 2 * (By[:,i] @ flatB[i].T) @ Nmu \n",
    "            third_sig = torch.trace((flatB[i] @ flatB[i].T) @ Ncov)\n",
    "            four_sig = (Nmu.T @ flatB[i] @ flatB[i].T @ Nmu)\n",
    "            \n",
    "            sqr_sig += (first_sig + second_sig + third_sig + four_sig)\n",
    "            \n",
    "            del first_xi, second_xi, first_sig, second_sig, third_sig, four_sig\n",
    "\n",
    "        sqr_xi /= num_neurons\n",
    "        sqr_sig /= (num_neurons*size)\n",
    "\n",
    "        ls_lambda[l] = (sqr_sig/sqr_xi).item()\n",
    "        \n",
    "        del Cov_a, Cov_e, flatB\n",
    "    \n",
    "    return ls_lambda\n",
    "    \n",
    "def ECM_layersise_update(model, par, Lambda, x, y):\n",
    "\n",
    "    model.eval()\n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        DSy = model(x)\n",
    "        print('Training Error: ', np.round(criterion(y, DSy.detach()).item(), 5))\n",
    "    '''\n",
    "    \n",
    "    device = x.device\n",
    "    \n",
    "    B_out, B_in, B_w, B_b = par['basic'], par['ebasic'], par['wbasic'], par['bbasic']\n",
    "    n_layer, nk, nm = B_w.size()\n",
    "    DB = diag_mat_weights(B_w[0].size()[0], 'second').to(device)\n",
    "\n",
    "    Project_matrix = (torch.linalg.pinv(B_in[-1].T @ B_in[-1]) @ B_in[-1].T @ B_in[-1])\n",
    "    Size = [b.size()[1] for b in B_in]\n",
    "    B_in = B_in.view(n_layer, nm, nk, Size[0])\n",
    "    \n",
    "    for l in range(n_layer):    \n",
    "        NW = torch.empty((nk, nm)).to(device)\n",
    "        NB = torch.empty((nm)).to(device)\n",
    "        \n",
    "        for i in range(nm):\n",
    "            B1y = B_out[l][:,i] - B_b[l][i]\n",
    "            BB = B_in[l][i].T\n",
    "    \n",
    "            # Update the weights and bias\n",
    "            NW[:, i] = (torch.linalg.inv(BB.T @ BB + (Lambda[l]/Size[l]) * (DB.T @ DB)) @ BB.T @ B1y)\n",
    "            NB[i] = torch.mean(B_out[l][:,i] - (NW[:,i] @ BB.T))\n",
    "                \n",
    "        # update the weight\n",
    "        block = getattr(model.Spline_block.model, f'block_{l}')\n",
    "        getattr(block.block.BSL, 'control_p').data = NW\n",
    "        getattr(block.block.BSL, 'bias').data = NB\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        DPSy = model(x)\n",
    "        #Update_Train_Loss = np.round(criterion(y, DPSy.detach()).item(), 5)\n",
    "        GCV = np.round((torch.sum((y - DPSy)**2)/(x.size()[0]-torch.trace(Project_matrix))**2).item(), 5)\n",
    "        \n",
    "    return model, GCV\n",
    "\n",
    "def ECM_update(model, max_iter, x, y):\n",
    "    BestGCV = 9999\n",
    "    patient = 10\n",
    "    pcount = 0\n",
    "    for i in range(max_iter):\n",
    "        _ = model(x)\n",
    "        ECM_para = model.get_para_ecm(x)\n",
    "        ECM_Lambda = ECM(ECM_para, initial_xi = 1, initial_sigma = 1, initial_lambda = 1e-4)\n",
    "\n",
    "        print('Lambda: ', ECM_Lambda)\n",
    "        model, GCV = ECM_layersise_update(model, ECM_para, ECM_Lambda, x, y)\n",
    "        print(GCV)\n",
    "        if GCV < BestGCV:\n",
    "            \n",
    "            BestLambda = ECM_Lambda\n",
    "            BestGCV = GCV\n",
    "            pcount = 0\n",
    "        else:\n",
    "            pcount += 1\n",
    "\n",
    "        if pcount == patient:\n",
    "            break\n",
    "\n",
    "        del ECM_para, ECM_Lambda\n",
    "    \n",
    "    return BestLambda\n",
    "\n",
    "class BSL(nn.Module):\n",
    "    def __init__(self, degree, num_knots, num_neurons, bias = True):\n",
    "        super(BSL, self).__init__()\n",
    "        self.degree = degree\n",
    "        self.num_knots = num_knots\n",
    "        self.num_neurons = num_neurons\n",
    "        self.control_p = nn.Parameter(torch.randn(self.num_knots, self.num_neurons))\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.randn(self.num_neurons))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        self.inter = {}\n",
    "    \n",
    "    def basis_function(self, x, i, k, t):\n",
    "    \n",
    "        # Base case: degree 0 spline\n",
    "        if k == 0:\n",
    "            return ((t[i] <= x) & (x < t[i + 1])).float()\n",
    "    \n",
    "        # Recursive case\n",
    "        denom1 = t[i + k] - t[i]\n",
    "        denom2 = t[i + k + 1] - t[i + 1]\n",
    "    \n",
    "        term1 = 0\n",
    "        if denom1 != 0:\n",
    "            term1 = (x - t[i]) / denom1 * self.basis_function(x, i, k - 1, t)\n",
    "    \n",
    "        term2 = 0\n",
    "        if denom2 != 0:\n",
    "            term2 = (t[i + k + 1] - x) / denom2 * self.basis_function(x, i + 1, k - 1, t)\n",
    "    \n",
    "        return term1 + term2\n",
    "\n",
    "    def knots_distribution(self, dg, nk):\n",
    "\n",
    "        knots = torch.cat([torch.linspace(-0.002, -0.001, steps=dg),            # Add repeated values at the start for clamping\n",
    "            torch.linspace(0, 1, nk-2*dg-2),  # Uniform knot spacing in the middle\n",
    "            torch.linspace(1.001, 1.002, steps=dg)           # Add repeated values at the end for clamping\n",
    "            ]).view(-1,1)\n",
    "        \n",
    "        knots = torch.cat([torch.linspace(0, 1, nk-2)          # Add repeated values at the end for clamping\n",
    "            ]).view(-1,1)\n",
    "\n",
    "        return knots\n",
    "    \n",
    "    def basis_function2(self, x, spl):\n",
    "        basis_output = spl.fit_transform(x.cpu().numpy())\n",
    "        return basis_output\n",
    "            \n",
    "    def forward(self, x):\n",
    "        batch_size, num_features = x.size()\n",
    "        device = x.device\n",
    "        \n",
    "        # Create knot vector and apply B-spline basis functions for each feature\n",
    "\n",
    "        '''\n",
    "        knots = torch.cat([\n",
    "                        torch.zeros(self.degree),               # Add repeated values at the start for clamping\n",
    "                        torch.linspace(0, 1, self.num_knots - self.degree + 1),  # Uniform knot spacing in the middle\n",
    "                        torch.ones(self.degree)                 # Add repeated values at the end for clamping\n",
    "                    ]).to(device)\n",
    "\n",
    "        # Apply B-spline basis functions for each feature\n",
    "\n",
    "        basises = []\n",
    "        \n",
    "        \n",
    "        for feature in range(num_features):\n",
    "            # Calculate B-spline basis functions for this feature\n",
    "            basis = torch.stack([self.basis_function(x[:, feature], i, self.degree, knots) \n",
    "                                 for i in range(self.num_knots)], dim=-1)\n",
    "            basises.append(basis)\n",
    "            \n",
    "        '''\n",
    "    \n",
    "        basises = []\n",
    "        knots = self.knots_distribution(self.degree, self.num_knots)\n",
    "        #knots = knots.to(device)\n",
    "        spl = SplineTransformer(n_knots=self.num_knots, degree=self.degree, knots = knots)\n",
    "\n",
    "        \n",
    "        for feature in range(num_features):\n",
    "            # Calculate B-spline basis functions for this feature\n",
    "            \n",
    "            basis = self.basis_function2(x[:, feature].reshape(-1,1), spl)\n",
    "            basis = torch.Tensor(basis).to(device)\n",
    "            basises.append(basis)\n",
    "        \n",
    "        if num_features == 1:\n",
    "            tout = basises[0] @ self.control_p\n",
    "            self.inter['basic'] = basises[0].T\n",
    "        else:\n",
    "            self.inter['basic'] = torch.reshape(torch.stack(basises, dim = 1), (batch_size, self.num_knots * self.num_neurons)).T\n",
    "            basises = torch.stack(basises)\n",
    "            tout = basises.permute(1,2,0) * self.control_p\n",
    "            tout = tout.sum(dim =1)\n",
    "                \n",
    "        if self.bias is not None:\n",
    "            tout += self.bias        \n",
    "            \n",
    "        return tout\n",
    "\n",
    "\n",
    "class NormLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NormLayer, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        min_val = torch.min(x, axis = 1).values.reshape(-1,1)\n",
    "        max_val = torch.max(x, axis = 1).values.reshape(-1,1)\n",
    "\n",
    "        x = (x - min_val)/(max_val - min_val)  # Rescale to [0, 1]\n",
    "        return x.detach()\n",
    "    \n",
    "class BSpline_block(nn.Module):\n",
    "    def __init__(self, degree, num_knots, num_neurons, dropout = 0.0, bias = True):\n",
    "        super(BSpline_block, self).__init__()\n",
    "\n",
    "        self.block = nn.Sequential(OrderedDict([\n",
    "            ('norm', NormLayer()),\n",
    "            ('BSL', BSL(degree = degree, num_knots = num_knots, num_neurons = num_neurons, bias = bias)),\n",
    "            ('drop', nn.Dropout(dropout)),\n",
    "        ]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "        \n",
    "class StackBS_block(nn.Module):\n",
    "    def __init__(self, block, degree, num_knots, num_neurons, num_blocks, dropout = 0.0, bias = True):\n",
    "        super().__init__()\n",
    "        self.model = nn.ModuleDict({\n",
    "            f'block_{i}': block(degree = degree, num_knots = num_knots, num_neurons = num_neurons)\n",
    "            for i in range(num_blocks)\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        for name, block in self.model.items():\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "980ddc22-c028-4fc3-a675-0fbe25cffd89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d7c3a3c1-64bf-49e0-b52c-97993bb1b579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "#trainset = torch.utils.data.Subset(trainset, list(range(10000)))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "#testset = torch.utils.data.Subset(testset, list(range(1000)))\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7c076fee-d634-4233-9d99-e6544681dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "class DPS_Image(nn.Module):\n",
    "    def __init__(self, dg, nk, nm, nbl, dropout, Fout, bias):\n",
    "        super(DPS_Image, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.gap = nn.Flatten()\n",
    "        self.ln1 = nn.Linear(2048, nm)\n",
    "        self.Spline_block = StackBS_block(BSpline_block, degree = dg, num_knots = nk, num_neurons = nm, num_blocks = nbl, dropout = dropout)\n",
    "        self.ln3 = nn.Linear(nm, Fout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.gap(x)\n",
    "        x = F.relu(self.ln1(x))\n",
    "        #x = self.Spline_block(x)\n",
    "        x = self.ln3(x)\n",
    "        #x = self.Spline_block(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return output\n",
    "\n",
    "'''\n",
    "train_kwargs = {'batch_size': 32}\n",
    "test_kwargs = {'batch_size': 32}\n",
    "\n",
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                   transform=transform)\n",
    "\n",
    "mnist_subset_train = torch.utils.data.Subset(dataset1, list(range(10000)))\n",
    "mnist_subset_test = torch.utils.data.Subset(dataset2, list(range(1000)))\n",
    "\n",
    "\n",
    "# Create a DataLoader for the subset\n",
    "train_loader = torch.utils.data.DataLoader(mnist_subset_train,**train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_subset_test, **test_kwargs)\n",
    "'''\n",
    "\n",
    "# experiment setting\n",
    "Iteration = 10000; dg = 3; nm = 20; nk = 8; doutput = 10; nl = 1\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model parameter \n",
    "tmc = DPS_Image(dg = dg, nk = nk, nm = nm, nbl = nl, dropout = 0.0, Fout = doutput, bias = True).to(device)\n",
    "learning_r = 3e-3; gamma = 0.5\n",
    "optimizer = torch.optim.Adam(tmc.parameters(), lr=learning_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8c41d54c-d930-463d-a79b-63fc75f6285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True).to(device)\n",
    "    \n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False   \n",
    "  \n",
    "'''\n",
    "model.fc = nn.Sequential(\n",
    "               nn.Linear(2048, nm),\n",
    "                #StackBS_block(BSpline_block, degree = dg, num_knots = nk, num_neurons = nm, num_blocks = nl, dropout = 0.0),\n",
    "                nn.Linear(nm, 10)).to(device)\n",
    "'''\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 1024)\n",
    "model.fc = nn.Sequential(\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(num_ftrs, 1024),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(1024, 512),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(256, nm),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    #StackBS_block(BSpline_block, degree = dg, num_knots = nk, num_neurons = nm, num_blocks = nl, dropout = 0.0),\n",
    "    torch.nn.Linear(nm, doutput),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04372927-11f4-48ff-8bbe-136c57e4d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_r, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "for epoch in range(1, Iteration + 1):\n",
    "    train(model, device, trainloader, optimizer, Iteration)\n",
    "    test(model, device, testloader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b688e2d-afdb-494c-b44f-64a95bf635ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5e87ada4-c90a-4038-88d5-c7aa17ba90f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, dg, nk, nm, nbl, dropout, Fout, bias):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(800, nm)\n",
    "        self.Spline_block = StackBS_block(BSpline_block, degree = dg, num_knots = nk, num_neurons = nm, num_blocks = nbl, dropout = dropout)\n",
    "        self.fc2 = nn.Linear(nm, Fout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.Spline_block(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "Iteration = 10000; dg = 3; nm = 10; nk = 50; doutput = 10; nl = 1; learning_r = 5e-2\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "network = Net(dg = dg, nk = nk, nm = nm, nbl = nl, dropout = 0.0, Fout = doutput, bias = True).to(device)\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=learning_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e8d8f6-898b-4548-81c7-5dcd3e23dc73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "85a6be30-b134-4215-a22a-aa353320fc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10000 [0/10000 (0%)]\tLoss: 2.663716\n",
      "Train Epoch: 10000 [320/10000 (3%)]\tLoss: 2.395219\n",
      "Train Epoch: 10000 [640/10000 (6%)]\tLoss: 2.427862\n",
      "Train Epoch: 10000 [960/10000 (10%)]\tLoss: 2.261920\n",
      "Train Epoch: 10000 [1280/10000 (13%)]\tLoss: 2.381605\n",
      "Train Epoch: 10000 [1600/10000 (16%)]\tLoss: 2.310886\n",
      "Train Epoch: 10000 [1920/10000 (19%)]\tLoss: 2.220517\n",
      "Train Epoch: 10000 [2240/10000 (22%)]\tLoss: 2.204608\n",
      "Train Epoch: 10000 [2560/10000 (26%)]\tLoss: 2.274376\n",
      "Train Epoch: 10000 [2880/10000 (29%)]\tLoss: 2.248163\n",
      "Train Epoch: 10000 [3200/10000 (32%)]\tLoss: 2.128055\n",
      "Train Epoch: 10000 [3520/10000 (35%)]\tLoss: 2.082510\n",
      "Train Epoch: 10000 [3840/10000 (38%)]\tLoss: 2.216907\n",
      "Train Epoch: 10000 [4160/10000 (42%)]\tLoss: 2.105896\n",
      "Train Epoch: 10000 [4480/10000 (45%)]\tLoss: 2.121691\n",
      "Train Epoch: 10000 [4800/10000 (48%)]\tLoss: 2.360017\n",
      "Train Epoch: 10000 [5120/10000 (51%)]\tLoss: 2.316518\n",
      "Train Epoch: 10000 [5440/10000 (54%)]\tLoss: 2.004809\n",
      "Train Epoch: 10000 [5760/10000 (58%)]\tLoss: 2.236133\n",
      "Train Epoch: 10000 [6080/10000 (61%)]\tLoss: 2.132386\n",
      "Train Epoch: 10000 [6400/10000 (64%)]\tLoss: 2.070580\n",
      "Train Epoch: 10000 [6720/10000 (67%)]\tLoss: 2.061389\n",
      "Train Epoch: 10000 [7040/10000 (70%)]\tLoss: 2.046881\n",
      "Train Epoch: 10000 [7360/10000 (73%)]\tLoss: 2.381138\n",
      "Train Epoch: 10000 [7680/10000 (77%)]\tLoss: 2.130539\n",
      "Train Epoch: 10000 [8000/10000 (80%)]\tLoss: 2.334434\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nSplineTransformer does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [88], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m StepLR(optimizer, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m gamma)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, Iteration \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIteration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     test(network, device, test_loader)\n\u001b[1;32m      5\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn [65], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      4\u001b[0m data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 6\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(output, target)\n\u001b[1;32m      8\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/sysapps/ubuntu-applications/python/venv/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [87], line 17\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[1;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n\u001b[0;32m---> 17\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSpline_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#x = F.dropout(x, training=self.training)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n",
      "File \u001b[0;32m/sysapps/ubuntu-applications/python/venv/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [17], line 263\u001b[0m, in \u001b[0;36mStackBS_block.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 263\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/sysapps/ubuntu-applications/python/venv/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [17], line 251\u001b[0m, in \u001b[0;36mBSpline_block.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sysapps/ubuntu-applications/python/venv/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/sysapps/ubuntu-applications/python/venv/pytorch/lib/python3.9/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/sysapps/ubuntu-applications/python/venv/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [17], line 210\u001b[0m, in \u001b[0;36mBSL.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    204\u001b[0m spl \u001b[38;5;241m=\u001b[39m SplineTransformer(n_knots\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_knots, degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree, knots \u001b[38;5;241m=\u001b[39m knots)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_features):\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;66;03m# Calculate B-spline basis functions for this feature\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m     basis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasis_function2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m     basis \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(basis)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    212\u001b[0m     basises\u001b[38;5;241m.\u001b[39mappend(basis)\n",
      "Cell \u001b[0;32mIn [17], line 172\u001b[0m, in \u001b[0;36mBSL.basis_function2\u001b[0;34m(self, x, spl)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbasis_function2\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, spl):\n\u001b[0;32m--> 172\u001b[0m     basis_output \u001b[38;5;241m=\u001b[39m \u001b[43mspl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m basis_output\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    903\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    904\u001b[0m             (\n\u001b[1;32m    905\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    914\u001b[0m         )\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/preprocessing/_polynomial.py:847\u001b[0m, in \u001b[0;36mSplineTransformer.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute knot positions of splines.\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \n\u001b[1;32m    829\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;124;03m        Fitted transformer.\u001b[39;00m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 847\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    856\u001b[0m         sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m     )\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nSplineTransformer does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "scheduler = StepLR(optimizer, step_size=1, gamma= gamma)\n",
    "for epoch in range(1, Iteration + 1):\n",
    "    train(network, device, train_loader, optimizer, Iteration)\n",
    "    test(network, device, test_loader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2164fea2-142e-4abd-a295-0833b5664603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
