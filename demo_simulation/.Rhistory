y = "k_median",
color = "Tier 1")
## create smooth scatterplot of `k_median` vs `sticker_price_2013`
ggplot(df2, aes(x = sticker_price_2013, y = k_median)) +
geom_point(aes(color = tier_1)) +
geom_smooth() +
labs(title = "Smooth Scatterplot of `k_median` vs `sticker_price_2013`",
x = "sticker_price_2013",
y = "k_median",
color = "Tier 1")
## create smooth scatterplot of `k_median` vs `par_median`
ggplot(df2, aes(x = par_median, y = k_median)) +
geom_point(aes(color = tier_1)) +
geom_smooth() +
labs(title = "Smooth Scatterplot of `k_median` vs `par_median`",
x = "par_median",
y = "k_median",
color = "Tier 1")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(caret)
library(ggplot2)
library(MASS)
library(leaps)
library(MPV)
library(MASS)
library(tidyverse)
library(lme4)
library(lmtest)
library(effects)
library(mgcv)
library(earth)
library(car)
df <- read.csv("/Users/a080528/Desktop/Purdue/Courses/STAT 526 [Qifan Song]/final_project/college_mobility_data.csv")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(caret)
library(ggplot2)
library(MASS)
library(leaps)
library(MPV)
library(MASS)
library(tidyverse)
library(lme4)
library(lmtest)
library(effects)
library(mgcv)
library(earth)
library(car)
df <- read.csv("/Users/a080528/Desktop/Purdue/Courses/STAT 526 [Qifan Song]/final_project/college_mobility_data.csv")
## create df1 that filters out rows with `kq5_cond_parq1` < 1
df1 <- df %>% filter(kq5_cond_parq1 >= 1)
## create df2 that filters out rows with missing `sat_avg_2013` values
df2 <- df %>% filter(!is.na(sat_avg_2013))
## create kernel histogram of `kq5_cond_parq1` variable
ggplot(df1, aes(x = kq5_cond_parq1)) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
geom_density(alpha = 0.2, fill = "red") +
labs(title = "Kernel Histogram of `kq5cond_parq1` Variable",
x = "kq5cond_parq1",
y = "Density")
ggplot(df1, aes(x = log(kq5_cond_parq1))) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
geom_density(alpha = 0.2, fill = "red") +
labs(title = "Kernel Histogram of log `kq5cond_parq1` Variable",
x = "Log kq5cond_parq1",
y = "Density")
## create kernel histogram of `k_median` variable
ggplot(df1, aes(x = k_median)) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
geom_density(alpha = 0.2, fill = "red") +
labs(title = "Kernel Histogram of `k_median` Variable",
x = "k_median",
y = "Density")
# Ensure the factor variables are treated as such, especially if they're currently coded as integers
df1$tier_1 <- factor(df1$tier_1, levels = c(1, 2, 3, 4), labels = c("nonselective", "selective", "highly selective", "elite"))
df1$region <- factor(df1$region, levels = c(1, 2, 3, 4), labels = c("Northeast", "Midwest", "South", "West"))
df1$public <- as.factor(df1$public)  # Making sure 'public' is a factor
# Impute or handle missing data for 'sat_avg_2013' if necessary
# Here is a simple imputation, you might need a more sophisticated approach
df1$sat_avg_2013[is.na(df1$sat_avg_2013)] <- mean(df1$sat_avg_2013, na.rm = TRUE)
## create df1 that filters out rows with `kq5_cond_parq1` < 1
df1 <- df %>% filter(kq5_cond_parq1 >= 1)
## create df2 that filters out rows with missing `sat_avg_2013` values
df2 <- df %>% filter(!is.na(sat_avg_2013))
## create kernel histogram of `kq5_cond_parq1` variable
ggplot(df1, aes(x = kq5_cond_parq1)) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
geom_density(alpha = 0.2, fill = "red") +
labs(title = "Kernel Histogram of `kq5cond_parq1` Variable",
x = "kq5cond_parq1",
y = "Density")
ggplot(df1, aes(x = log(kq5_cond_parq1))) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
geom_density(alpha = 0.2, fill = "red") +
labs(title = "Kernel Histogram of log `kq5cond_parq1` Variable",
x = "Log kq5cond_parq1",
y = "Density")
## create kernel histogram of `k_median` variable
ggplot(df1, aes(x = k_median)) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
geom_density(alpha = 0.2, fill = "red") +
labs(title = "Kernel Histogram of `k_median` Variable",
x = "k_median",
y = "Density")
# Ensure the factor variables are treated as such, especially if they're currently coded as integers
df1$tier_1 <- factor(df1$tier_1, levels = c(1, 2, 3, 4), labels = c("nonselective", "selective", "highly selective", "elite"))
df1$region <- factor(df1$region, levels = c(1, 2, 3, 4), labels = c("Northeast", "Midwest", "South", "West"))
df1$public <- as.factor(df1$public)  # Making sure 'public' is a factor
# Impute or handle missing data for 'sat_avg_2013' if necessary
# Here is a simple imputation, you might need a more sophisticated approach
df1$sat_avg_2013[is.na(df1$sat_avg_2013)] <- mean(df1$sat_avg_2013, na.rm = TRUE)
## create linear model for `k_median`
olm <- lm(k_median ~ sat_avg_2013 + sticker_price_2013 + par_median, data = df2)
summary(olm)
plot(Effect("sat_avg_2013", olm, partial.residual = TRUE))
plot(Effect("sticker_price_2013", olm, partial.residual = TRUE))
plot(Effect("par_median", olm, partial.residual = TRUE))
ggplot(df1, aes(x = avgfacsal_2013, y = k_median)) +
geom_point(aes(color = tier_1)) +
labs(title = "Scatterplot of `k_median` vs `avgfacsal_2013`",
x = "avgfacsal_2013",
y = "k_median",
color = "Tier 1")
ggplot(df2, aes(x = par_median, y = k_median)) +
geom_point(aes(color = tier_1)) +
geom_smooth() +
labs(title = "Smooth Scatterplot of `k_median` vs `par_median`",
x = "par_median",
y = "k_median",
color = "Tier 1")
num_data_2002 = df2002[,1:12]
ndf <- df[c('k_median','par_median', 'par_q1', 'par_top1pc', 'kq5_cond_parq1','ktop1pc_cond_parq1','mr_kq5_pq1','mr_ktop1_pq1','trend_parq1','trend_bottom40','sticker_price_2013','sat_avg_2013','sticker_price_2000','sat_avg_2001','region','tier_1','public')]
ndf$tier_1[ndf$tier_1 == '.'] <- '0'
ndf$Region <- factor(ndf$region)
ndf$Tier <- factor(ndf$tier_1)
ndf$Public <- factor(ndf$public)
DMR <- model.matrix(~ Region - 1, data = ndf)
DMT <- model.matrix(~ Tier - 1, data = ndf)
DMP <- model.matrix(~ Public - 1, data = ndf)
D <- cbind(ndf, DMR, DMT, DMP)
df2013 <- D[c('k_median','par_median', 'par_q1', 'par_top1pc', 'kq5_cond_parq1','ktop1pc_cond_parq1','mr_kq5_pq1','mr_ktop1_pq1','trend_parq1','trend_bottom40','sticker_price_2013','sat_avg_2013','Region1','Region2','Region3','Tier0','Tier1','Tier2','Tier3','Public0')]
df2013$year = c(rep(0,dim(df2013)[1]))
df2002 <- D[c('k_median','par_median', 'par_q1', 'par_top1pc', 'kq5_cond_parq1','ktop1pc_cond_parq1','mr_kq5_pq1','mr_ktop1_pq1','trend_parq1','trend_bottom40','sticker_price_2000','sat_avg_2001','Region1','Region2','Region3','Tier0','Tier1','Tier2','Tier3','Public0')]
df2002$year = c(rep(1,dim(df2002)[1]))
df2013 <- df2013 %>% drop_na()
df2002 <- df2002 %>% drop_na()
colnames(df2013)[11] <- 'sticker_price'
colnames(df2013)[12] <- 'sat_avg'
colnames(df2002)[11] <- 'sticker_price'
colnames(df2002)[12] <- 'sat_avg'
dfcomb = rbind(df2002, df2013)
num_data_2002 = df2002[,1:12]
num_data_2013 = df2002[,1:12]
pairs(num_data_2002)
pairs(num_data_2013)
linear_model <- lm(k_median~.-year, data = df2002)
summary(linear_model)
dwtest(linear_model)
plot(linear_model, which = 3)
bptest(linear_model)
qqnorm(dfcomb$k_median)
qqline(dfcomb$k_median)
shapiro.test(dfcomb$k_median)
box = boxcox(linear_model)
lambda=box$x[which.max(box$y)]
linear_model_lambda <- lm(k_median^lambda~.-year, data = df2002)
linear_model_log <- lm(log(k_median)~.-year, data = df2002)
summary(linear_model_lambda)
summary(linear_model_log)
X <- model.matrix(linear_model)[,-1]  # Exclude intercept
corr_matrix <- cor(X)
# Calculate eigenvalues
eigenvalues <- eigen(corr_matrix)$values
# Calculate condition number
condition_number <- sqrt(max(eigenvalues) / min(eigenvalues))
print(condition_number)
vif(linear_model)
box = boxcox(linear_model)
lambda=box$x[which.max(box$y)]
linear_model_lambda <- lm(k_median^lambda~.-year, data = df2002)
linear_model_log <- lm(log(k_median)~.-year, data = df2002)
summary(linear_model_lambda)
summary(linear_model_log)
linear_model.noreg <- lm(k_median~.-year-Region1-Region2-Region3, data = df2002)
linear_model.notier <- lm(k_median~.-year-Tier0-Tier1-Tier2-Tier3, data = df2002)
linear_model.nopub <- lm(k_median~.-year-Public0, data = df2002)
print(summary(linear_model)$adj.r.squared)
print(summary(linear_model.noreg)$adj.r.squared)
print(summary(linear_model.notier)$adj.r.squared)
print(summary(linear_model.nopub)$adj.r.squared)
all.possible.reg <- regsubsets(k_median ~ .- year,  data = df2002,  nvmax = ncol(df2002) - 1, method = "exhaustive")
reg.summary <- summary(all.possible.reg)
best.reg.models <- coef(all.possible.reg, id = order(reg.summary$cp)[1])
all.possible.lreg <- regsubsets(log(k_median) ~ . - year,  data =df2002,  nvmax = ncol(df2002) - 1, method = "exhaustive")
reg.summary <- summary(all.possible.lreg)
best.reg.lmodels <- coef(all.possible.lreg, id = order(reg.summary$cp)[1])
all.possible.breg <- regsubsets(k_median^lambda ~ . - year,  data = df2002,  nvmax = ncol(df2002) - 1, method = "exhaustive")
reg.summary <- summary(all.possible.breg)
best.reg.bmodels <- coef(all.possible.breg, id = order(reg.summary$cp)[1])
bmodels = lm(k_median/100000~ par_median + par_top1pc + kq5_cond_parq1+ ktop1pc_cond_parq1 + mr_kq5_pq1 + sticker_price + sat_avg +Region1+Region2+Region3+ Tier0+ Tier1 + Tier2+ Tier3+Public0, data = df2002)
bsomodels = lm((k_median/100000)~ par_median + par_top1pc + kq5_cond_parq1+ ktop1pc_cond_parq1+ mr_kq5_pq1 + sticker_price + sat_avg + I(par_median**2) + I(par_top1pc**2) + I(kq5_cond_parq1**2) + I(kq5_cond_parq1**2) + I(mr_kq5_pq1**2)+ I(sticker_price**2) + I(sat_avg**2)+ (Tier0 +  Tier1 + Tier2 + Tier3 + Region1 +  Region2 + Region3 + Public0), data = df2002)
bitmodels = lm( k_median/100000 ~ par_median + par_top1pc + kq5_cond_parq1+ ktop1pc_cond_parq1+ mr_kq5_pq1 + sticker_price + sat_avg + (Tier0 +  Tier1 + Tier2 + Tier3 + Region1 +  Region2 + Region3 + Public0)*(par_median + par_top1pc + kq5_cond_parq1+ ktop1pc_cond_parq1+ mr_kq5_pq1 + sticker_price + sat_avg), data = df2002)
bsitmodels = lm(k_median/100000 ~ par_median + par_top1pc + kq5_cond_parq1+ ktop1pc_cond_parq1+ mr_kq5_pq1 + sticker_price + sat_avg + I(par_median**2) + I(par_top1pc**2) + I(kq5_cond_parq1**2) + I(kq5_cond_parq1**2) + I(mr_kq5_pq1**2)+ I(sticker_price**2) + I(sat_avg**2)+ (Tier0 +  Tier1 + Tier2 + Tier3 + Region1 +  Region2 + Region3 + Public0)*(par_median + par_top1pc + kq5_cond_parq1+ ktop1pc_cond_parq1+ mr_kq5_pq1 + sticker_price + sat_avg), data = df2002)
cat('blm (fo): R^2',summary(bmodels)$adj.r.squared,' PRESS ' , PRESS(bmodels),'\n')
cat('blm (so): R^2',summary(bsomodels)$adj.r.squared,' PRESS ' , PRESS(bsomodels),'\n')
cat('blm (it): R^2',summary(bitmodels)$adj.r.squared,' PRESS ' , PRESS(bitmodels),'\n')
cat('blm (sit): R^2',summary(bsitmodels)$adj.r.squared,' PRESS ' , PRESS(bsitmodels),'\n')
all.possible.reg <- regsubsets(k_median/100000~ par_median + par_top1pc + kq5_cond_parq1+ ktop1pc_cond_parq1 + mr_kq5_pq1 + sticker_price + sat_avg +Region1+Region2+Region3+ Tier0+ Tier1 + Tier2+ Tier3+Public0,  data = df2002,  nvmax = ncol(df2002) - 1, method = "exhaustive")
best.reg.models <- which.min(summary(all.possible.reg)$cp)
coef_names <- names(coef(all.possible.reg, best.reg.models))
reg_scm <- lm(as.formula(paste("k_median/100000 ~", paste(coef_names[-1], collapse = " + "))), data = df2002)
cat('reg.blm (fo): R^2', summary(reg_scm)$adj.r.squared,' PRESS ' , PRESS(reg_scm),'\n')
all.possible.reg <- regsubsets(k_median/100000~ par_median + par_top1pc + kq5_cond_parq1+ ktop1pc_cond_parq1+ mr_kq5_pq1 + sticker_price + sat_avg + I(par_median**2) + I(par_top1pc**2) + I(kq5_cond_parq1**2) + I(kq5_cond_parq1**2) + I(mr_kq5_pq1**2)+ I(sticker_price**2) + I(sat_avg**2)+ (Tier0 +  Tier1 + Tier2 + Tier3 + Region1 +  Region2 + Region3 + Public0),  data = df2002,  nvmax = ncol(df2002) - 1, method = "exhaustive")
best.reg.models <- which.min(summary(all.possible.reg)$cp)
coef_names <- names(coef(all.possible.reg, best.reg.models))
reg_scm <- lm(as.formula(paste("k_median/100000 ~", paste(coef_names[-1], collapse = " + "))), data = df2002)
print(summary(reg_scm)$adj.r.squared)
cat('reg.blm (so): R^2', summary(reg_scm)$adj.r.squared,' PRESS ' , PRESS(reg_scm),'\n')
stepwise_blm1 <- step(bmodels, direction = "both")
stepwise_blm2 <- step(bsomodels, direction = "both")
stepwise_blm3 <- step(bitmodels, direction = "both")
stepwise_blm4 <- step(bsitmodels, direction = "both")
cat('step.blm (fo): R^2',summary(stepwise_blm1)$adj.r.squared,' PRESS ' , PRESS(stepwise_blm1),'\n')
cat('step.blm (so): R^2',summary(stepwise_blm2)$adj.r.squared,' PRESS ' , PRESS(stepwise_blm2),'\n')
cat('step.blm (it): R^2',summary(stepwise_blm3)$adj.r.squared,' PRESS ' , PRESS(stepwise_blm3),'\n')
cat('step.blm (sit): R^2',summary(stepwise_blm4)$adj.r.squared,' PRESS ' , PRESS(stepwise_blm4),'\n')
plot(k.bsitmodel, which = 3)
ndf <- df[c('k_median','par_median', 'par_q1', 'par_top1pc', 'kq5_cond_parq1','ktop1pc_cond_parq1','mr_kq5_pq1','mr_ktop1_pq1','trend_parq1','trend_bottom40','sticker_price_2013','sat_avg_2013','sticker_price_2000','sat_avg_2001','region','tier_1','public')]
ndf$tier_1[ndf$tier_1 == '.'] <- '0'
ndf$Region <- factor(ndf$region)
ndf$Tier <- factor(ndf$tier_1)
ndf$Public <- factor(ndf$public)
DMR <- model.matrix(~ Region - 1, data = ndf)
DMT <- model.matrix(~ Tier - 1, data = ndf)
DMP <- model.matrix(~ Public - 1, data = ndf)
D <- cbind(ndf, DMR, DMT, DMP)
df2013 <- D[c('k_median','par_median', 'par_q1', 'par_top1pc', 'kq5_cond_parq1','ktop1pc_cond_parq1','mr_kq5_pq1','mr_ktop1_pq1','trend_parq1','trend_bottom40','sticker_price_2013','sat_avg_2013','Region1','Region2','Region3','Tier0','Tier1','Tier2','Tier3','Public0')]
df2013$year = c(rep(0,dim(df2013)[1]))
df2002 <- D[c('k_median','par_median', 'par_q1', 'par_top1pc', 'kq5_cond_parq1','ktop1pc_cond_parq1','mr_kq5_pq1','mr_ktop1_pq1','trend_parq1','trend_bottom40','sticker_price_2000','sat_avg_2001','Region1','Region2','Region3','Tier0','Tier1','Tier2','Tier3','Public0')]
df2002$year = c(rep(1,dim(df2002)[1]))
df2013 <- df2013 %>% drop_na()
df2002 <- df2002 %>% drop_na()
colnames(df2013)[11] <- 'sticker_price'
colnames(df2013)[12] <- 'sat_avg'
colnames(df2002)[11] <- 'sticker_price'
colnames(df2002)[12] <- 'sat_avg'
dfcomb = rbind(df2002, df2013)
View(dfcomb)
k.bsitmodel
plot(stepwise_bcl4, which = 3)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(caret)
library(ggplot2)
library(MASS)
library(leaps)
library(MPV)
library(MASS)
library(tidyverse)
library(lme4)
library(lmtest)
library(effects)
library(mgcv)
library(earth)
library(car)
df <- read.csv("/Users/a080528/Desktop/Purdue/Courses/STAT 526 [Qifan Song]/final_project/college_mobility_data.csv")
## create df1 that filters out rows with `kq5_cond_parq1` < 1
df1 <- df %>% filter(kq5_cond_parq1 >= 1)
## create df2 that filters out rows with missing `sat_avg_2013` values
df2 <- df %>% filter(!is.na(sat_avg_2013))
## create kernel histogram of `kq5_cond_parq1` variable
ggplot(df1, aes(x = kq5_cond_parq1)) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
geom_density(alpha = 0.2, fill = "red") +
labs(title = "Kernel Histogram of `kq5cond_parq1` Variable",
x = "kq5cond_parq1",
y = "Density")
ggplot(df1, aes(x = log(kq5_cond_parq1))) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
geom_density(alpha = 0.2, fill = "red") +
labs(title = "Kernel Histogram of log `kq5cond_parq1` Variable",
x = "Log kq5cond_parq1",
y = "Density")
## create kernel histogram of `k_median` variable
ggplot(df1, aes(x = k_median)) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
geom_density(alpha = 0.2, fill = "red") +
labs(title = "Kernel Histogram of `k_median` Variable",
x = "k_median",
y = "Density")
# Ensure the factor variables are treated as such, especially if they're currently coded as integers
df1$tier_1 <- factor(df1$tier_1, levels = c(1, 2, 3, 4), labels = c("nonselective", "selective", "highly selective", "elite"))
df1$region <- factor(df1$region, levels = c(1, 2, 3, 4), labels = c("Northeast", "Midwest", "South", "West"))
df1$public <- as.factor(df1$public)  # Making sure 'public' is a factor
# Impute or handle missing data for 'sat_avg_2013' if necessary
# Here is a simple imputation, you might need a more sophisticated approach
df1$sat_avg_2013[is.na(df1$sat_avg_2013)] <- mean(df1$sat_avg_2013, na.rm = TRUE)
## create linear model for `k_median`
olm <- lm(k_median ~ sat_avg_2013 + sticker_price_2013 + par_median, data = df2)
summary(olm)
plot(Effect("sat_avg_2013", olm, partial.residual = TRUE))
plot(Effect("sticker_price_2013", olm, partial.residual = TRUE))
plot(Effect("par_median", olm, partial.residual = TRUE))
ggplot(df1, aes(x = avgfacsal_2013, y = k_median)) +
geom_point(aes(color = tier_1)) +
labs(title = "Scatterplot of `k_median` vs `avgfacsal_2013`",
x = "avgfacsal_2013",
y = "k_median",
color = "Tier 1")
ggplot(df2, aes(x = par_median, y = k_median)) +
geom_point(aes(color = tier_1)) +
geom_smooth() +
labs(title = "Smooth Scatterplot of `k_median` vs `par_median`",
x = "par_median",
y = "k_median",
color = "Tier 1")
## Create smooth scatterplot of `k_median` vs `sat_avg_2013`
ggplot(df2, aes(x = sat_avg_2013, y = k_median)) +
geom_point(aes(color = tier_1)) +
geom_smooth() +
labs(title = "Smooth Scatterplot of `k_median` vs `sat_avg_2013`",
x = "sat_avg_2013",
y = "k_median",
color = "Tier 1")
## create smooth scatterplot of `k_median` vs `avgfacsal_2013`
ggplot(df2, aes(x = avgfacsal_2013, y = k_median)) +
geom_point(aes(color = tier_1)) +
geom_smooth() +
labs(title = "Smooth Scatterplot of `k_median` vs `avgfacsal_2013`",
x = "avgfacsal_2013",
y = "k_median",
color = "Tier 1")
## create smooth scatterplot of `k_median` vs `mr_kq5_pq1`
ggplot(df2, aes(x = mr_kq5_pq1, y = k_median)) +
geom_point(aes(color = tier_1)) +
geom_smooth() +
labs(title = "Smooth Scatterplot of `k_median` vs `mr_kq5_pq1`",
x = "mr_kq5_pq1",
y = "k_median",
color = "Tier 1")
## create smooth scatterplot of `k_median` vs `sticker_price_2013`
ggplot(df2, aes(x = sticker_price_2013, y = k_median)) +
geom_point(aes(color = tier_1)) +
geom_smooth() +
labs(title = "Smooth Scatterplot of `k_median` vs `sticker_price_2013`",
x = "sticker_price_2013",
y = "k_median",
color = "Tier 1")
## create smooth scatterplot of `k_median` vs `par_median`
ggplot(df2, aes(x = par_median, y = k_median)) +
geom_point(aes(color = tier_1)) +
geom_smooth() +
labs(title = "Smooth Scatterplot of `k_median` vs `par_median`",
x = "par_median",
y = "k_median",
color = "Tier 1")
ndf <- df[c('k_median','par_median', 'par_q1', 'par_top1pc', 'kq5_cond_parq1','ktop1pc_cond_parq1','mr_kq5_pq1','mr_ktop1_pq1','trend_parq1','trend_bottom40','sticker_price_2013','sat_avg_2013','sticker_price_2000','sat_avg_2001','region','tier_1','public')]
ndf$tier_1[ndf$tier_1 == '.'] <- '0'
ndf$Region <- factor(ndf$region)
ndf$Tier <- factor(ndf$tier_1)
ndf$Public <- factor(ndf$public)
DMR <- model.matrix(~ Region - 1, data = ndf)
DMT <- model.matrix(~ Tier - 1, data = ndf)
DMP <- model.matrix(~ Public - 1, data = ndf)
D <- cbind(ndf, DMR, DMT, DMP)
df2013 <- D[c('k_median','par_median', 'par_q1', 'par_top1pc', 'kq5_cond_parq1','ktop1pc_cond_parq1','mr_kq5_pq1','mr_ktop1_pq1','trend_parq1','trend_bottom40','sticker_price_2013','sat_avg_2013','Region1','Region2','Region3','Tier0','Tier1','Tier2','Tier3','Public0')]
df2013$year = c(rep(0,dim(df2013)[1]))
df2002 <- D[c('k_median','par_median', 'par_q1', 'par_top1pc', 'kq5_cond_parq1','ktop1pc_cond_parq1','mr_kq5_pq1','mr_ktop1_pq1','trend_parq1','trend_bottom40','sticker_price_2000','sat_avg_2001','Region1','Region2','Region3','Tier0','Tier1','Tier2','Tier3','Public0')]
df2002$year = c(rep(1,dim(df2002)[1]))
df2013 <- df2013 %>% drop_na()
df2002 <- df2002 %>% drop_na()
colnames(df2013)[11] <- 'sticker_price'
colnames(df2013)[12] <- 'sat_avg'
colnames(df2002)[11] <- 'sticker_price'
colnames(df2002)[12] <- 'sat_avg'
dfcomb = rbind(df2002, df2013)
num_data_2002 = df2002[,1:12]
num_data_2013 = df2002[,1:12]
pairs(num_data_2002)
pairs(num_data_2013)
num_data_2002 = df2002[,1:12]
num_data_2013 = df2013[,1:12]
pairs(num_data_2002)
pairs(num_data_2013)
num_data_2002
matrixX = as.matric(num_data_2002)
matrixX = as.matrix(num_data_2002)
dim(matrixX)
H = (t(matrixX) %*% matrixX)
H = matrixX%*%solve(t(matrixX) %*% matrixX)
H = matrixX%*%solve(t(matrixX) %*% matrixX)%*%t(matrixX)
diag(H)
plot(diag(H))
threshold = 2*dim(matrixX)[2]/dim(matrixX)[1]
abline(threshold)
threshold = 2*dim(matrixX)[2]/dim(matrixX)[1]
plot(diag(H))
abline(threshold)
line(threshold)
plot(diag(H))
line(threshold)
plot(diag(H))
abline(h=threshold, col="red")
plot(diag(H), title = 'leverage plot')
plot(diag(H), main = 'leverage plot')
abline(h=threshold, col="red")
plot(diag(H), main = 'leverage plot')
abline(h=threshold, col="red")
linear_model <- lm(k_median~.-year, data = df2002)
summary(linear_model)
dwtest(linear_model)
plot(linear_model, which = 3)
bptest(linear_model)
qqnorm(dfcomb$k_median)
qqline(dfcomb$k_median)
shapiro.test(dfcomb$k_median)
cooks_d <- cooks.distance(linear_model)
plot(cooks_d, type = 'h', main = "Cook's Distance Plot")
influential <- which(cooks_d > 4 / n)
plot(cooks_d, type = 'h', main = "Cook's Distance Plot")
influential <- which(cooks_d > 1)
plot(cooks_d, type = 'h', main = "Cook's Distance Plot")
matrixX = as.matrix(num_data_2002)
linear_model <- lm(k_median~.-year, data = df2002)
H = matrixX%*%solve(t(matrixX) %*% matrixX)%*%t(matrixX)
threshold = 2*dim(matrixX)[2]/dim(matrixX)[1]
plot(diag(H), main = 'leverage plot')
abline(h=threshold, col="red")
cooks_d <- cooks.distance(linear_model)
plot(cooks_d, type = 'h', main = "Cook's Distance Plot")
influential <- which(cooks_d > 1)
sum(diag(H))
threshold = 2*sum(diag(H))/dim(matrixX)[1]
matrixX = as.matrix(num_data_2002)
linear_model <- lm(k_median~.-year, data = df2002)
H = matrixX%*%solve(t(matrixX) %*% matrixX)%*%t(matrixX)
threshold = 2*sum(diag(H))/dim(matrixX)[1]
plot(diag(H), main = 'leverage plot')
abline(h=threshold, col="red")
cooks_d <- cooks.distance(linear_model)
plot(cooks_d, type = 'h', main = "Cook's Distance Plot")
influential <- which(cooks_d > 1)
library(MaxPro)
library(ggplot2)
library(rkriging)
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
#                         Kriging                           #
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
X = read.csv('./dataset/output_feature.csv')
setwd("~/")
write.csv(CCCtrain,"./dataset/trainsample.csv", row.names = FALSE)
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
#                         Kriging                           #
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
X = read.csv('./dataset/output_feature.csv')
setwd("~/Desktop/Github/DPSpline/demo_simulation")
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
#                         Kriging                           #
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
X = read.csv('./dataset/output_feature.csv')
y = read.csv('./dataset/output_eta.csv')
X = as.matrix(X)
y = as.matrix(y)
testX = read.csv('./dataset/test_output_feature.csv')
testy = read.csv('./dataset/test_output_eta.csv')
testX = as.matrix(testX)
testy = as.matrix(testy)
X
X[5,]
X[6,]
testX = as.matrix(testX)
testy = as.matrix(testy)
model <- Fit.Kriging(X, y, interpolation=TRUE, fit=TRUE, model="OK",
kernel.parameters=list(type="Gaussian"))
pred <- Predict.Kriging(model, testX)
pred_eta = pred$mean
pred_std = pred$sd
eta_max = pred_eta[which.max(pred_eta)]
sd_eta_max = pred_std[which.max(pred_eta)]
beta_max = 1.6459 # mapping from test data
sdSt <- function(t, e, b, sde){
dSt <- (b*t**(b-1)/e**(b))*exp(-(t/e)**b)
sqrt((dSt**2)*(sde**2))
}
st <- function(t,e,b){
exp(-(t/e)**b)
}
sdeSt <- function(t, e, b, sde){
dSt <- exp(-(t/exp(e))**b)*(-t**b)*(-b)* exp(-b*e)
sqrt((dSt**2)*(sde**2))
}
sdst <- function(t,e,b){
exp(-(t/exp(e))**b)
}
t <- seq(0, 150, by = 0.1)
## without log-transformation
stv = st(t, eta_max, beta_max)
sdstv = sdSt(t, eta_max, beta_max, sd_eta_max)
## with log-transformation
stv = sdst(t, eta_max, beta_max)
sdstv = sdeSt(t, eta_max, beta_max, sd_eta_max)
dft <- data.frame (
time = t,
vst = stv,
uvst = stv+1.96*sdstv,
lvst = stv-1.96*sdstv
)
ggplot(data = dft, aes(x = t, y = vst)) +
geom_ribbon(aes(ymin = lvst, ymax = uvst), fill = "deepskyblue", alpha = 0.2) + geom_line(aes(y = vst), color = "white", size = 1.5) +geom_point() +
ggtitle("Regression Line, 95% Confidence and Prediction Bands") + ylab('S(t)')
exp(eta_max)
