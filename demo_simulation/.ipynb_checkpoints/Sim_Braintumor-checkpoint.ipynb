{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d78638a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import glob\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6fe4a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_brain(imgdir, w, h):\n",
    "\n",
    "    WIDTH, HEIGHT = w, h\n",
    "    \n",
    "    x = []\n",
    "    for i in range(len(imgdir)):\n",
    "        # Read and resize image\n",
    "        full_size_image = cv2.imread(imgdir[i])\n",
    "        x.append(cv2.resize(full_size_image, (WIDTH,HEIGHT), interpolation=cv2.INTER_CUBIC)/255.0) \n",
    "\n",
    "    return x\n",
    "\n",
    "def diag_mat_weights(dimp, type = 'first'):\n",
    "    if type == 'first':\n",
    "        dg = np.zeros((dimp-1, dimp))\n",
    "        for i in range(dimp-1):\n",
    "            dg[i,i] = -1\n",
    "            dg[i,i+1]= 1\n",
    "    elif type == 'second':\n",
    "        dg = np.zeros((dimp-2, dimp))\n",
    "        for i in range(dimp-2):\n",
    "            dg[i,i] = -1\n",
    "            dg[i,i+1]= 2\n",
    "            dg[i,i+2]= -1\n",
    "    else:\n",
    "        pass\n",
    "    return torch.Tensor(dg)\n",
    "    \n",
    "class PRODBSplineLayerMultiFeature(nn.Module):\n",
    "    def __init__(self, input_dim, degree, num_knots, output_dim, num_neurons, bias = True):\n",
    "        super(PRODBSplineLayerMultiFeature, self).__init__()\n",
    "        self.degree = degree\n",
    "        self.num_knots = num_knots\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_neurons = num_neurons\n",
    "        \n",
    "        if input_dim == 2:\n",
    "            self.control_p = nn.Parameter(torch.randn(self.num_knots**2, self.output_dim))\n",
    "        else:\n",
    "            self.control_p = nn.Parameter(torch.randn(self.num_knots, self.num_neurons))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.randn(self.num_neurons))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        self.inter = {}\n",
    "    \n",
    "    def basis_function(self, x, i, k, t):\n",
    "    \n",
    "        # Base case: degree 0 spline\n",
    "        if k == 0:\n",
    "            return ((t[i] <= x) & (x < t[i + 1])).float()\n",
    "    \n",
    "        # Recursive case\n",
    "        denom1 = t[i + k] - t[i]\n",
    "        denom2 = t[i + k + 1] - t[i + 1]\n",
    "    \n",
    "        term1 = 0\n",
    "        if denom1 != 0:\n",
    "            term1 = (x - t[i]) / denom1 * self.basis_function(x, i, k - 1, t)\n",
    "    \n",
    "        term2 = 0\n",
    "        if denom2 != 0:\n",
    "            term2 = (t[i + k + 1] - x) / denom2 * self.basis_function(x, i + 1, k - 1, t)\n",
    "    \n",
    "        return term1 + term2\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, num_features = x.size()\n",
    "        device = x.device\n",
    "        \n",
    "        # Create knot vector\n",
    "        # knots = torch.linspace(0, 1, self.num_knots + self.degree + 1).to(device)\n",
    "        knots = torch.cat([\n",
    "                        torch.zeros(self.degree),               # Add repeated values at the start for clamping\n",
    "                        torch.linspace(0, 1, self.num_knots - self.degree + 1),  # Uniform knot spacing in the middle\n",
    "                        torch.ones(self.degree)                 # Add repeated values at the end for clamping\n",
    "                    ]).to(device)\n",
    "        # Apply B-spline basis functions for each feature\n",
    "        basises = []\n",
    "    \n",
    "        \n",
    "        for feature in range(num_features):\n",
    "            # Calculate B-spline basis functions for this feature\n",
    "            basis = torch.stack([self.basis_function(x[:, feature], i, self.degree, knots) \n",
    "                                 for i in range(self.num_knots)], dim=-1)\n",
    "            basises.append(basis)\n",
    "            \n",
    "        \n",
    "        if num_features == 1:\n",
    "            tout = basises[0] @ self.control_p\n",
    "            self.inter['basic'] = basises[0].T\n",
    "        else:\n",
    "            self.inter['basic'] = torch.reshape(torch.stack(basises, dim = 1), (batch_size, self.num_knots * self.num_neurons)).T\n",
    "            basises = torch.stack(basises)\n",
    "            tout = basises.permute(1,2,0) * self.control_p\n",
    "            tout = tout.sum(dim =1)\n",
    "                \n",
    "        if self.bias is not None:\n",
    "            tout += self.bias        \n",
    "            \n",
    "        return tout\n",
    "        \n",
    "class NormLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NormLayer, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        min_val = torch.min(x, axis = 1).values.reshape(-1,1)\n",
    "        max_val = torch.max(x, axis = 1).values.reshape(-1,1)\n",
    "\n",
    "        x = (x - min_val)/(max_val - min_val)  # Rescale to [0, 1]\n",
    "        return x.detach()\n",
    "        \n",
    "def ECM(model, num_neurons, num_knots, initial_xi = 1, initial_sigma = 1, initial_lambda = 1e-4, L = None):\n",
    "    lambdab = initial_lambda\n",
    "    sigma = initial_sigma\n",
    "    xi = initial_xi\n",
    "\n",
    "    if L == 1:\n",
    "        B = model.inter['ebasic']\n",
    "        By = model.inter['basic']\n",
    "        WB = model.sp1.control_p\n",
    "    else:\n",
    "        B = model.inter['ebasic2']\n",
    "        By = model.inter['basic2']\n",
    "        WB = model.sp2.control_p\n",
    "        \n",
    "    DB = diag_mat_weights(WB.size()[0]).to(device)\n",
    "    size = B.size()[1]\n",
    "    S = DB.T @ DB\n",
    "    Cov_a = (xi**2)* torch.linalg.pinv(S)\n",
    "    Cov_e = torch.eye(size*num_neurons)* sigma\n",
    "    \n",
    "    block_y = torch.reshape(By, (-1,1))\n",
    "    flatB = B.view(num_neurons, num_knots, size)\n",
    "        \n",
    "    sqr_xi= 0\n",
    "    sqr_sig = 0\n",
    "    \n",
    "    for i in range(num_neurons):\n",
    "        Ncov = (Cov_a -(Cov_a @ flatB[i]) @ (torch.linalg.pinv(flatB[i].T @ Cov_a @ flatB[i] + Cov_e[size*i:size*(i+1),size*i:size*(i+1)]) @ flatB[i].T @ Cov_a))\n",
    "        Nmu = (Cov_a @ flatB[i]) @ (torch.linalg.pinv(flatB[i].T @ Cov_a @ flatB[i] + Cov_e[size*i:size*(i+1),size*i:size*(i+1)])) @ By[:,i].reshape(-1,1)\n",
    "        \n",
    "        first_xi = S @ Ncov\n",
    "        second_xi = (Nmu.T @ S @ Nmu)\n",
    "        sqr_xi += torch.trace(first_xi) + second_xi\n",
    "            \n",
    "        first_sig = torch.norm(By[:,i])\n",
    "        second_sig = 2 * (By[:,i] @ flatB[i].T) @ Nmu \n",
    "        third_sig = torch.trace((flatB[i] @ flatB[i].T) @ Ncov)\n",
    "        four_sig = (Nmu.T @ flatB[i] @ flatB[i].T @ Nmu)\n",
    "        \n",
    "        sqr_sig += (first_sig + second_sig + third_sig + four_sig)\n",
    "    \n",
    "    sqr_xi /= num_neurons\n",
    "    sqr_sig /= (num_neurons*size)\n",
    "    \n",
    "    Lambda = sqr_sig/sqr_xi\n",
    "    \n",
    "    return Lambda.item()\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9966f6c2-493c-4777-ab80-510d7e2e107c",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "In this section, we will load the brain tumor MRI Images and resize it to 224x224 pixels and ensure the images are in gray scale for numerical stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2821748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = glob.glob('/Users/a080528/Downloads/BrainTumor/Training/glioma/*.jpg')\n",
    "train2 = glob.glob('/Users/a080528/Downloads/BrainTumor/Training/notumor/*.jpg')\n",
    "test1 = glob.glob('/Users/a080528/Downloads/BrainTumor/Testing/glioma/*.jpg')\n",
    "test2 = glob.glob('/Users/a080528/Downloads/BrainTumor/Testing/notumor/*.jpg')\n",
    "\n",
    "train = [train1, train2]; test = [test1, test2]\n",
    "\n",
    "trainx = []\n",
    "for f in train:\n",
    "    x = proc_brain(f, 224, 224)\n",
    "    trainx.append(x)\n",
    "\n",
    "testx = []\n",
    "for f in test:\n",
    "    x = proc_brain(f, 224, 224)\n",
    "    testx.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c2c19a-cc6b-489d-9f52-3734e1d881df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtraind = np.concatenate((np.array(trainx[0]), np.array(trainx[1])))\n",
    "y_train = np.array([1]*len(trainx[0]))\n",
    "y_train = np.concatenate((y_train, [0]*len(trainx[1])))\n",
    "Xtestd = np.concatenate((np.array(testx[0]), np.array(testx[1])))\n",
    "y_test = np.array([1]*len(testx[0]))\n",
    "y_test = np.concatenate((y_test, [0]*len(testx[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab838770-3743-40ce-9b1b-8fd7575ab25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Training) Number of glioma image: 274 |  Number of non-tumor image: 226 \n",
      " (Testing) Number of glioma image: 172 |  Number of non-tumor image: 128 \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this block, you can customize the number of training size and testing size. According to your setting, we will \n",
    "randomly select the assigned number from image dataset. In this demo, we randomly select 500 images and 300 images\n",
    "from training and testing dataset respectively. Besides, in order to fulfill the requirement of Pytorch, we need to\n",
    "change the data to suitable type.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "trainsize = 500; testsize = 300\n",
    "\n",
    "np.random.seed(123)\n",
    "trainid = np.random.choice(len(Xtraind), trainsize)\n",
    "testid = np.random.choice(len(Xtestd), testsize)\n",
    "\n",
    "print(f\"(Training) Number of glioma image: {Counter(y_train[trainid])[0]} |  Number of non-tumor image: {Counter(y_train[trainid])[1]} \")\n",
    "print(f\" (Testing) Number of glioma image: {Counter(y_test[testid])[0]} |  Number of non-tumor image: {Counter(y_test[testid])[1]} \")\n",
    "\n",
    "X_train = torch.Tensor(Xtraind[trainid]).permute(0, 3, 1, 2); y_train = torch.Tensor(y_train[trainid]).type(torch.LongTensor)\n",
    "X_test = torch.Tensor(Xtestd[testid]).permute(0, 3, 1, 2); y_test = torch.Tensor(y_test[testid]).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ec4c1-0d38-469f-a71d-774afab3424d",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e2b19",
   "metadata": {},
   "source": [
    "## CNDNN-S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abf8374-370b-460b-8884-6c46511663ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ca85f92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNS1(nn.Module):\n",
    "    def __init__(self, input_dim, degree, num_knots, num_neurons, output_dim, bias):\n",
    "        super(DNNS1, self).__init__()\n",
    "        self.num_neurons = num_neurons\n",
    "        self.num_knots = num_knots\n",
    "        self.ln1 = nn.Linear(input_dim, num_neurons)\n",
    "        self.nm1 = NormLayer() \n",
    "        self.sp1 = PRODBSplineLayerMultiFeature(input_dim = 1, degree = degree, num_knots = num_knots, num_neurons = num_neurons, output_dim= output_dim, bias = True)\n",
    "        self.ln2 = nn.Linear(num_neurons, output_dim)\n",
    "        self.inter = {}\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ln1out = self.ln1(x)\n",
    "        ln1out = self.nm1(ln1out)\n",
    "        \n",
    "        device = ln1out.device\n",
    "        batch_size, _ = x.size()\n",
    "        \n",
    "        # # # # # # # # # # # # # #\n",
    "        #         SPLINE 1        #\n",
    "        # # # # # # # # # # # # # #\n",
    "        \n",
    "        sp1out = self.sp1(ln1out)\n",
    "        bslist = self.sp1.inter['basic']\n",
    "        \n",
    "        self.inter['ebasic'] = bslist\n",
    "        self.inter['basic'] = sp1out\n",
    "\n",
    "        ln2out = self.ln2(sp1out)        \n",
    "        return ln2out\n",
    "\n",
    "class TumorClassifier(nn.Module):\n",
    "    def __init__(self, Fin, dg, nk, nm, Fout, bias):\n",
    "        super(TumorClassifier, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.gap = nn.Flatten()\n",
    "        self.classifier = DNNS1(input_dim = Fin, degree = dg, num_knots = nk, num_neurons = nm, output_dim = Fout, bias = True).to(device)\n",
    "        self.sm = nn.Softmax(dim = 1)\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.gap(x)\n",
    "        x = self.classifier(x)\n",
    "        x = self.sm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3644a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model setting:\n",
    "\n",
    "`device`: running the program with cpu or gpu\n",
    "`tmc`: the classifier that equip with DNN-S \n",
    "`nm` : number of neuron in DNN-S\n",
    "`nk` : number of knot in DNN-S\n",
    "`patientc` : (early-stop crierion) If the model didn't improve in n epoch then stop.\n",
    "`patientr` : If the model didn't improve in n epoch then decrease learning rate with specific factor.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# experiment setting\n",
    "Iteration = 10000; bloss_list = []; tor = 1e-5; lr_tor = 1e-6\n",
    "patientc = 10; patientr = 5; tpat = 0; bloss = 9999\n",
    "nm = 100; nk = 15; doutput = 2\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model parameter \n",
    "tmc = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True)\n",
    "learning_r = 1e-2\n",
    "optimizer = torch.optim.Adam(tmc.parameters(), lr=learning_r)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe77a332-a3d3-4c68-978a-3c23fce7a8d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a07ad2-d621-40af-8634-8a143e45361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(Iteration):\n",
    "\n",
    "    # Forward pass: Compute predicted y by passing x to the modelsp\n",
    "    pyb_af = tmc(X_train)\n",
    "    loss = criterion(pyb_af, y_train); bloss_list.append(loss.item())\n",
    "    \n",
    "    if (t > 0) and ((bloss_list[t-1]-bloss_list[t])<tor):        \n",
    "        if (tpat % patientr) == 0:\n",
    "            learning_r *= 0.2 \n",
    "            tpat += 1\n",
    "            #print('Learning rate reduce to ', learning_r)\n",
    "            optimizer = torch.optim.Adam(tmc.parameters(), lr=learning_r)\n",
    "            if learning_r <= lr_tor:\n",
    "                print('Convergence!')\n",
    "                break\n",
    "        elif tpat < patientc:\n",
    "            tpat += 1\n",
    "            pass\n",
    "        else:\n",
    "            print('Convergence!')\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        if loss < bloss:\n",
    "            #torch.save(tmc.state_dict(), './brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk))\n",
    "            bloss = loss.item()\n",
    "            tpat = 0\n",
    "        tpat += 1\n",
    "\n",
    "    if tpat == patientc:\n",
    "        print('Convergence!')\n",
    "        break\n",
    "    \n",
    "    prediction = torch.argmax(pyb_af, axis = 1)\n",
    "    acc = (torch.argmax(pyb_af, axis = 1) == y_train).sum()/len(y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if(t % 10 == 0):\n",
    "        print('| Epoch: ',t+1,'/',str(Iteration),' | Loss: ', np.round(loss.item(), 4),' | Acc: ', acc.item())\n",
    "        if(t % 50 == 0):\n",
    "            with torch.no_grad():\n",
    "                print((torch.argmax(tmc(X_test).detach(), axis = 1) == y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db9048f-3f4a-4a65-a120-338d4bf50bdb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ECM Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a8f42ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the ECM tunning for penalty in each layer\n",
      "Lambda: 0.2357| Training Loss: 0.6829500198364258| Training GCV: 4.268463726475602e-06\n",
      "Lambda: 0.27503| Training Loss: 0.5793099999427795| Training GCV: 3.62062542080821e-06\n",
      "Lambda: 0.27773| Training Loss: 0.7097499966621399| Training GCV: 4.435667051438941e-06\n",
      "Lambda: 0.20232| Training Loss: 0.6283699870109558| Training GCV: 3.927318175556138e-06\n",
      "Lambda: 0.19315| Training Loss: 0.6672599911689758| Training GCV: 4.173381967120804e-06\n",
      "Lambda: 0.1774| Training Loss: 0.6161199808120728| Training GCV: 4.7093672037590295e-06\n",
      "Lambda: 0.17239| Training Loss: 0.6477500200271606| Training GCV: 3.9890310290502384e-06\n",
      "Lambda: 0.16794| Training Loss: 0.6128600239753723| Training GCV: 3.708579697558889e-06\n",
      "Lambda: 0.16491| Training Loss: 0.6821600198745728| Training GCV: 4.254592113284161e-06\n",
      "Lambda: 0.16238| Training Loss: 0.6178699731826782| Training GCV: 3.938550435123034e-06\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "`ECM_epoch`: number of epoch to run the ecm tuning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"Running the ECM tunning for penalty in each layer\")\n",
    "\n",
    "ECM_epoch = 10\n",
    "with torch.no_grad():\n",
    "    eval_model = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "    eval_model.load_state_dict(torch.load('./brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "\n",
    "    WB = eval_model.classifier.sp1.control_p\n",
    "    DB = diag_mat_weights(WB.size()[0], 'second').to(device)\n",
    "    \n",
    "    BestGCV = np.inf\n",
    "    n = X_train.size()[0]\n",
    "    \n",
    "    for i in range(ECM_epoch):\n",
    "        eval_model.train()\n",
    "        MPSy = eval_model(X_train)\n",
    "\n",
    "        # update following layer except for last layer\n",
    "        LambdaB1 = ECM(model = eval_model.classifier, num_neurons = nm, num_knots = nk, L = 1)\n",
    "        \n",
    "        B1 = eval_model.classifier.inter['ebasic']\n",
    "        By1 = eval_model.classifier.inter['basic']\n",
    "        P2 = By1 @ torch.inverse(By1.T @ By1) @ By1.T\n",
    "\n",
    "        \n",
    "        size1 = B1.size()[1]\n",
    "        B1 = B1.view(nk, nm, size1)\n",
    "\n",
    "        NW1 = torch.empty((nk, nm))\n",
    "        NB1 = torch.empty((nm))\n",
    "\n",
    "        \n",
    "        for i in range(nm):\n",
    "            B1y = By1[:,i] - eval_model.classifier.sp1.bias.data[i]\n",
    "            BB1 = B1[:,i].T\n",
    "\n",
    "            # Update the weights and bias\n",
    "            NW1[:, i] = (torch.inverse(BB1.T @ BB1 + (LambdaB1/size1) * (DB.T @ DB)) @ BB1.T @ B1y)\n",
    "            NB1[i] = torch.mean(By1[:,i] - (NW1[:,i] @ BB1.T))\n",
    "            \n",
    "        # update the weight\n",
    "        getattr(eval_model.classifier.sp1, 'control_p').data = NW1; getattr(eval_model.classifier.sp1, 'bias').data = NB1\n",
    "\n",
    "        # update the last layer\n",
    "        WholeB = torch.cat((torch.ones((n,1)), By1), dim = 1)\n",
    "        NLn2W = (torch.inverse(WholeB.T @ WholeB) @ WholeB.T @ MPSy.type(torch.FloatTensor)).T\n",
    "        getattr(eval_model.classifier.ln2, 'bias').data = NLn2W[:,0]; getattr(eval_model.classifier.ln2, 'weight').data = NLn2W[:,1:]\n",
    "        \n",
    "        eval_model.eval()\n",
    "        pred_postecm = eval_model(X_train)\n",
    "        CLoss = criterion(pred_postecm.detach(), y_train)\n",
    "        trainGCV = CLoss/(n-torch.trace(P2))**2\n",
    "        \n",
    "        if trainGCV < BestGCV:\n",
    "            BestLambdaB = LambdaB1\n",
    "            BestGCV = trainGCV\n",
    "            \n",
    "        print(f\"Lambda: {np.round(LambdaB1, 5)}| Training Loss: {np.round(CLoss, 5)}| Training GCV: {trainGCV.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0d2cc9-3170-4ad5-aade-cfaa73cabc68",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### DPS fast tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f20ef1a-c2f0-4e8a-984c-d0d016afc0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "`fast_epoch`: number of epoch to run the fast tuning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "fast_epoch = 201\n",
    "DPS = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "DPS.load_state_dict(torch.load('./brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "lr_ft = 1e-2\n",
    "optimizer = torch.optim.Adam(DPS.parameters(), lr=lr_ft)\n",
    "\n",
    "for t in range(1, fast_epoch):\n",
    "\n",
    "    # Forward pass: Compute predicted y by passing x to the modelsp\n",
    "    pyb_af = DPS(X_train)\n",
    "\n",
    "    WB1 = DPS.classifier.sp1.control_p.data; DB1 = diag_mat_weights(WB1.size()[0]).to(device)\n",
    "\n",
    "    loss = criterion(pyb_af, y_train) + (BestLambdaB/n) * torch.norm(DB1 @ WB1)\n",
    "    bloss_list.append(loss.item())\n",
    "    \n",
    "    prediction = torch.argmax(pyb_af, axis = 1)\n",
    "    acc = (torch.argmax(pyb_af, axis = 1) == y_train).sum()/len(y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if t % 10 == 0:\n",
    "        print('| Epoch: ',t+1,'/',str(Iteration),' | Loss: ', loss.item(),' | Acc: ', np.round(acc.item(), 5))\n",
    "        if t % 100 == 0:\n",
    "            with torch.no_grad():\n",
    "                print((torch.argmax(DPS(X_test).detach(), axis = 1) == y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd8e860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "856f41ac",
   "metadata": {},
   "source": [
    "## CN2DPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05c243a-99fc-49d3-963f-42ca6f942a3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6c657077",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRODBSplineLayerMultiFeature(nn.Module):\n",
    "    def __init__(self, input_dim, degree, num_knots, output_dim, num_neurons, bias = True):\n",
    "        super(PRODBSplineLayerMultiFeature, self).__init__()\n",
    "        self.degree = degree\n",
    "        self.num_knots = num_knots\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_neurons = num_neurons\n",
    "        \n",
    "        if input_dim == 2:\n",
    "            self.control_p = nn.Parameter(torch.randn(self.num_knots**2, self.output_dim))\n",
    "        else:\n",
    "            self.control_p = nn.Parameter(torch.randn(self.num_knots, self.num_neurons))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.randn(self.num_neurons))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        self.inter = {}\n",
    "    \n",
    "    def basis_function(self, x, i, k, t):\n",
    "    \n",
    "        # Base case: degree 0 spline\n",
    "        if k == 0:\n",
    "            return ((t[i] <= x) & (x < t[i + 1])).float()\n",
    "    \n",
    "        # Recursive case\n",
    "        denom1 = t[i + k] - t[i]\n",
    "        denom2 = t[i + k + 1] - t[i + 1]\n",
    "    \n",
    "        term1 = 0\n",
    "        if denom1 != 0:\n",
    "            term1 = (x - t[i]) / denom1 * self.basis_function(x, i, k - 1, t)\n",
    "    \n",
    "        term2 = 0\n",
    "        if denom2 != 0:\n",
    "            term2 = (t[i + k + 1] - x) / denom2 * self.basis_function(x, i + 1, k - 1, t)\n",
    "    \n",
    "        return term1 + term2\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, num_features = x.size()\n",
    "        device = x.device\n",
    "        \n",
    "        # Create knot vector\n",
    "        # knots = torch.linspace(0, 1, self.num_knots + self.degree + 1).to(device)\n",
    "        knots = torch.cat([\n",
    "                        torch.zeros(self.degree),               # Add repeated values at the start for clamping\n",
    "                        torch.linspace(0, 1, self.num_knots - self.degree + 1),  # Uniform knot spacing in the middle\n",
    "                        torch.ones(self.degree)                 # Add repeated values at the end for clamping\n",
    "                    ]).to(device)\n",
    "        # Apply B-spline basis functions for each feature\n",
    "        basises = []\n",
    "    \n",
    "        \n",
    "        for feature in range(num_features):\n",
    "            # Calculate B-spline basis functions for this feature\n",
    "            basis = torch.stack([self.basis_function(x[:, feature], i, self.degree, knots) \n",
    "                                 for i in range(self.num_knots)], dim=-1)\n",
    "            basises.append(basis)\n",
    "            \n",
    "        if num_features == 1:\n",
    "            tout = basises[0] @ self.control_p\n",
    "            self.inter['eachbasic'] = basises[0].T\n",
    "        else:\n",
    "            #self.inter['basic'] = torch.reshape(torch.stack(basises, dim = 1), (batch_size, self.num_knots * self.num_neurons)).T\n",
    "            self.inter['eachbasic'] = torch.reshape(torch.stack(basises, dim = 1), (batch_size, self.num_knots * self.num_neurons)).T\n",
    "            \n",
    "            basises = torch.stack(basises)\n",
    "            tout = basises.permute(1,2,0) * self.control_p\n",
    "            tout = tout.sum(dim =1)\n",
    "                \n",
    "        if self.bias is not None:\n",
    "            tout += self.bias        \n",
    "\n",
    "        self.inter['basicoutput'] = tout\n",
    "        \n",
    "        return tout\n",
    "        \n",
    "class DNNS2(nn.Module):\n",
    "    def __init__(self, input_dim, degree, num_knots, num_neurons, output_dim, bias):\n",
    "        super(DNNS2, self).__init__()\n",
    "        self.num_neurons = num_neurons\n",
    "        self.num_knots = num_knots\n",
    "        self.ln1 = nn.Linear(input_dim, num_neurons)\n",
    "        self.nm1 = NormLayer() \n",
    "        self.sp1 = PRODBSplineLayerMultiFeature(input_dim = 1, degree = degree, num_knots = num_knots, num_neurons = num_neurons, output_dim= output_dim, bias = True)\n",
    "        self.nm2 = NormLayer() \n",
    "        self.sp2 = PRODBSplineLayerMultiFeature(input_dim = 1, degree = degree, num_knots = num_knots, num_neurons = num_neurons, output_dim= output_dim, bias = True)\n",
    "        self.ln2 = nn.Linear(num_neurons, output_dim)\n",
    "        self.inter = {}\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ln1out = self.ln1(x)\n",
    "        ln1out = self.nm1(ln1out)\n",
    "        \n",
    "        device = ln1out.device\n",
    "        batch_size, _ = x.size()\n",
    "        \n",
    "        # # # # # # # # # # # # # #\n",
    "        #         SPLINE          #\n",
    "        # # # # # # # # # # # # # #\n",
    "        \n",
    "        sp1out = self.sp1(ln1out)\n",
    "        sp1out = self.nm2(sp1out)\n",
    "\n",
    "        # # # # # # # # # # # # # #\n",
    "        #         SPLINE 2        #\n",
    "        # # # # # # # # # # # # # #\n",
    "        \n",
    "        sp2out = self.sp2(sp1out)\n",
    "        ln2out = self.ln2(sp2out)\n",
    "        \n",
    "        return ln2out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "5cdfa154",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TumorClassifier(nn.Module):\n",
    "    def __init__(self, Fin, dg, nk, nm, Fout, bias):\n",
    "        super(TumorClassifier, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.gap = nn.Flatten()\n",
    "        self.classifier = DNNS2(input_dim = 32*56*56, degree = dg, num_knots = nk, num_neurons = nm, output_dim = Fout, bias = True).to(device)\n",
    "        self.sm = nn.Softmax(dim = 1)\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.gap(x)\n",
    "        x = self.classifier(x)\n",
    "        x = self.sm(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "95e298a8-e59c-4e6f-a128-97f89518f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\"\"\"\n",
    "Model setting:\n",
    "\n",
    "`device`: running the program with cpu or gpu\n",
    "`tmc`: the classifier that equip with DNN-S \n",
    "`nm` : number of neuron in DNN-S\n",
    "`nk` : number of knot in DNN-S\n",
    "`patientc` : (early-stop crierion) If the model didn't improve in n epoch then stop.\n",
    "`patientr` : If the model didn't improve in n epoch then decrease learning rate with specific factor.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# experiment setting\n",
    "Iteration = 10000; bloss_list = []; tor = 1e-5; lr_tor = 1e-6\n",
    "patientc = 10; patientr = 5; tpat = 0; bloss = 9999\n",
    "nm = 100; nk = 15; doutput = 2\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model parameter \n",
    "tmc = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True)\n",
    "learning_r = 1e-2\n",
    "optimizer = torch.optim.Adam(tmc.parameters(), lr=learning_r)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898a94e5-1957-4500-8f25-ab7c80163a56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3b8d95b3-4114-4843-868c-f0fb71da6b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:  1 / 100  | Loss:  0.6802  | Acc:  0.593999981880188\n",
      "tensor(0.5733)\n",
      "| Epoch:  11 / 100  | Loss:  0.6035  | Acc:  0.722000002861023\n",
      "| Epoch:  21 / 100  | Loss:  0.5478  | Acc:  0.7919999957084656\n",
      "| Epoch:  31 / 100  | Loss:  0.5064  | Acc:  0.8199999928474426\n",
      "| Epoch:  41 / 100  | Loss:  0.4776  | Acc:  0.8560000061988831\n",
      "| Epoch:  51 / 100  | Loss:  0.4547  | Acc:  0.8899999856948853\n",
      "tensor(0.7667)\n",
      "| Epoch:  61 / 100  | Loss:  0.4357  | Acc:  0.8939999938011169\n",
      "| Epoch:  71 / 100  | Loss:  0.4198  | Acc:  0.9139999747276306\n",
      "| Epoch:  81 / 100  | Loss:  0.4061  | Acc:  0.9259999990463257\n",
      "| Epoch:  91 / 100  | Loss:  0.3934  | Acc:  0.9419999718666077\n"
     ]
    }
   ],
   "source": [
    "for t in range(Iteration):\n",
    "\n",
    "    # Forward pass: Compute predicted y by passing x to the modelsp\n",
    "    pyb_af = tmc(X_train)\n",
    "    loss = criterion(pyb_af, y_train); bloss_list.append(loss.item())\n",
    "    \n",
    "    if (t > 0) and ((bloss_list[t-1]-bloss_list[t])<tor):        \n",
    "        if (tpat % patientr) == 0:\n",
    "            learning_r *= 0.2 \n",
    "            tpat += 1\n",
    "            #print('Learning rate reduce to ', learning_r)\n",
    "            optimizer = torch.optim.Adam(tmc.parameters(), lr=learning_r)\n",
    "            if learning_r <= lr_tor:\n",
    "                print('Convergence!')\n",
    "                break\n",
    "        elif tpat < patientc:\n",
    "            tpat += 1\n",
    "            pass\n",
    "        else:\n",
    "            print('Convergence!')\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        if loss < bloss:\n",
    "            #torch.save(tmc.state_dict(), './brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk))\n",
    "            bloss = loss.item()\n",
    "            tpat = 0\n",
    "        tpat += 1\n",
    "\n",
    "    if tpat == patientc:\n",
    "        print('Convergence!')\n",
    "        break\n",
    "    \n",
    "    prediction = torch.argmax(pyb_af, axis = 1)\n",
    "    acc = (torch.argmax(pyb_af, axis = 1) == y_train).sum()/len(y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if(t % 10 == 0):\n",
    "        print('| Epoch: ',t+1,'/',str(Iteration),' | Loss: ', np.round(loss.item(), 4),' | Acc: ', acc.item())\n",
    "        if(t % 100 == 0):\n",
    "            with torch.no_grad():\n",
    "                print((torch.argmax(tmc(X_test).detach(), axis = 1) == y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "225c6bee-4b98-451f-8491-a49f4bba31d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    eval_model = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "    eval_model.load_state_dict(torch.load('./2brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "    pred_postecm = eval_model(X_train)\n",
    "    CLoss = criterion(pred_postecm.detach(), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e51c0-2f99-4ef6-ba48-03f4d59b06d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ECM Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ae012a20-9b3f-4152-846f-c7d04b52301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ECM(model, num_neurons, num_knots, initial_xi = 1, initial_sigma = 1, initial_lambda = 1e-4):\n",
    "    lambdab = initial_lambda\n",
    "    sigma = initial_sigma\n",
    "    xi = initial_xi\n",
    "\n",
    "    B = model.inter['eachbasic']\n",
    "    By = model.inter['basicoutput']\n",
    "    WB = model.control_p\n",
    "        \n",
    "    DB = diag_mat_weights(WB.size()[0]).to(device)\n",
    "    size = B.size()[1]\n",
    "    S = DB.T @ DB\n",
    "    Cov_a = (xi**2)* torch.linalg.pinv(S)\n",
    "    Cov_e = torch.eye(size*num_neurons)* sigma\n",
    "    \n",
    "    block_y = torch.reshape(By, (-1,1))\n",
    "    flatB = B.view(num_neurons, num_knots, size)\n",
    "        \n",
    "    sqr_xi= 0\n",
    "    sqr_sig = 0\n",
    "    \n",
    "    for i in range(num_neurons):\n",
    "        Ncov = (Cov_a -(Cov_a @ flatB[i]) @ (torch.linalg.pinv(flatB[i].T @ Cov_a @ flatB[i] + Cov_e[size*i:size*(i+1),size*i:size*(i+1)]) @ flatB[i].T @ Cov_a))\n",
    "        Nmu = (Cov_a @ flatB[i]) @ (torch.linalg.pinv(flatB[i].T @ Cov_a @ flatB[i] + Cov_e[size*i:size*(i+1),size*i:size*(i+1)])) @ By[:,i].reshape(-1,1)\n",
    "        \n",
    "        first_xi = S @ Ncov\n",
    "        second_xi = (Nmu.T @ S @ Nmu)\n",
    "        sqr_xi += torch.trace(first_xi) + second_xi\n",
    "            \n",
    "        first_sig = torch.norm(By[:,i])\n",
    "        second_sig = 2 * (By[:,i] @ flatB[i].T) @ Nmu \n",
    "        third_sig = torch.trace((flatB[i] @ flatB[i].T) @ Ncov)\n",
    "        four_sig = (Nmu.T @ flatB[i] @ flatB[i].T @ Nmu)\n",
    "        \n",
    "        sqr_sig += (first_sig + second_sig + third_sig + four_sig)\n",
    "    \n",
    "    sqr_xi /= num_neurons\n",
    "    sqr_sig /= (num_neurons*size)\n",
    "    \n",
    "    Lambda = sqr_sig/sqr_xi\n",
    "    \n",
    "    return Lambda.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "eda1c8f3-fd95-40e3-9816-d4edac44456f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the ECM tunning for penalty in each layer\n",
      "Lambda: [0.30183088779449463, 0.30312493443489075]| Training Loss: 0.7657999992370605| Training GCV: 4.786255885846913e-06\n",
      "Lambda: [0.973455011844635, 0.6522708535194397]| Training Loss: 0.8041099905967712| Training GCV: 4.120976882404648e-06\n",
      "Lambda: [1.3706945180892944, 0.3747212588787079]| Training Loss: 0.7974600195884705| Training GCV: 5.1150018407497555e-06\n",
      "Lambda: [1.8239096403121948, 0.3827195465564728]| Training Loss: 0.8612599968910217| Training GCV: 4.769452061736956e-06\n",
      "Lambda: [1.5904974937438965, 1.7096126079559326]| Training Loss: 0.7672600150108337| Training GCV: 3.7891347801632946e-06\n",
      "Lambda: [1.670275092124939, 1.7180237770080566]| Training Loss: 0.7532600164413452| Training GCV: 3.5555015074351104e-06\n",
      "Lambda: [1.777961254119873, 0.859359860420227]| Training Loss: 0.907260000705719| Training GCV: 4.15523027186282e-06\n",
      "Lambda: [1.9107773303985596, 1.430779218673706]| Training Loss: 0.7932599782943726| Training GCV: 3.4246222639922053e-06\n",
      "Lambda: [1.9577510356903076, 2.0410945415496826]| Training Loss: 0.8152599930763245| Training GCV: 3.541840897014481e-06\n",
      "Lambda: [1.9773733615875244, 1.1929782629013062]| Training Loss: 0.7972599864006042| Training GCV: 3.7175316265347647e-06\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "`ECM_epoch`: number of epoch to run the ecm tuning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "LoP = 2\n",
    "PSname = ['sp'+str(i+1) for i in range(LoP)]\n",
    "ECM_epoch = 10\n",
    "\n",
    "print(\"Running the ECM tunning for penalty in each layer\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    eval_model = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "    eval_model.load_state_dict(torch.load('./2brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "\n",
    "    BestGCV = np.inf\n",
    "    n = X_train.size()[0]\n",
    "    \n",
    "    for i in range(ECM_epoch):\n",
    "        eval_model.train()\n",
    "        MPSy = eval_model(X_train)\n",
    "    \n",
    "        # update following layer except for last layer\n",
    "        LambdaL = []\n",
    "        for layer in PSname:\n",
    "            splayer = getattr(eval_model.classifier, layer)\n",
    "            WB = getattr(splayer, 'control_p')\n",
    "            DB = diag_mat_weights(WB.size()[0], 'second').to(device)\n",
    "            LambdaB = ECM(model = getattr(eval_model.classifier, layer), num_neurons = nm, num_knots = nk)\n",
    "            LambdaL.append(LambdaB)\n",
    "            \n",
    "            B1 = getattr(eval_model.classifier, layer).inter['eachbasic']\n",
    "            By1 = getattr(eval_model.classifier, layer).inter['basicoutput']\n",
    "            P2 = By1 @ torch.inverse(By1.T @ By1) @ By1.T\n",
    "    \n",
    "            size1 = B1.size()[1]\n",
    "            B1 = B1.view(nk, nm, size1)\n",
    "    \n",
    "            NW1 = torch.empty((nk, nm))\n",
    "            NB1 = torch.empty((nm))\n",
    "    \n",
    "        \n",
    "            for i in range(nm):\n",
    "                B1y = By1[:,i] - getattr(eval_model.classifier, layer).bias.data[i]\n",
    "                BB1 = B1[:,i].T\n",
    "        \n",
    "                # Update the weights and bias\n",
    "                NW1[:, i] = (torch.inverse(BB1.T @ BB1 + (LambdaB/size1) * (DB.T @ DB)) @ BB1.T @ B1y)\n",
    "                NB1[i] = torch.mean(By1[:,i] - (NW1[:,i] @ BB1.T))\n",
    "                \n",
    "            # update the weight\n",
    "            getattr(splayer, 'control_p').data = NW1; getattr(splayer, 'bias').data = NB1\n",
    "    \n",
    "        # update the last layer\n",
    "        WholeB = torch.cat((torch.ones((n,1)), By1), dim = 1)\n",
    "        NLn2W = (torch.inverse(WholeB.T @ WholeB) @ WholeB.T @ MPSy.type(torch.FloatTensor)).T\n",
    "        \n",
    "        getattr(eval_model.classifier.ln2, 'bias').data = NLn2W[:,0]; getattr(eval_model.classifier.ln2, 'weight').data = NLn2W[:,1:]\n",
    "        \n",
    "        eval_model.eval()\n",
    "        pred_postecm = eval_model(X_train)\n",
    "        CLoss = criterion(pred_postecm.detach(), y_train)\n",
    "        trainGCV = CLoss/(n-torch.trace(P2))**2\n",
    "        \n",
    "        if trainGCV < BestGCV:\n",
    "            BestLambdaB = LambdaB1\n",
    "            BestGCV = trainGCV\n",
    "            \n",
    "        print(f\"Lambda: {LambdaL}| Training Loss: {np.round(CLoss, 5)}| Training GCV: {trainGCV.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d6556-afd1-41ac-8a91-9730eae7dd61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2DPS Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a9449ea7-7a9c-4ad4-8659-94451e6fc730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "`fast_epoch`: number of epoch to run the fast tuning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "fast_epoch = 201\n",
    "D2PS = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "D2PS.load_state_dict(torch.load('./2brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "lr_ft = 1e-2\n",
    "optimizer = torch.optim.Adam(D2PS.parameters(), lr=lr_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72b6da-e9b1-40dd-a842-5716c2d02a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(1, fast_epoch):\n",
    "\n",
    "    # Forward pass: Compute predicted y by passing x to the modelsp\n",
    "    pyb_af = D2PS(X_train)\n",
    "    loss = criterion(pyb_af, y_train)\n",
    "    \n",
    "    for l in range(len(PSname)):\n",
    "        WB = getattr(D2PS.classifier, PSname[l]).control_p.data; DB = diag_mat_weights(WB.size()[0]).to(device)\n",
    "        loss += (LambdaL[l]/n) * torch.norm(DB @ WB)\n",
    "            \n",
    "    prediction = torch.argmax(pyb_af, axis = 1)\n",
    "    acc = (torch.argmax(pyb_af, axis = 1) == y_train).sum()/len(y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if t % 10 == 0:\n",
    "        print('| Epoch: ',t+1,'/',str(Iteration),' | Loss: ', loss.item(),' | Acc: ', np.round(acc.item(), 5))\n",
    "        if t % 100 == 0:\n",
    "            with torch.no_grad():\n",
    "                print((torch.argmax(D2PS(X_test).detach(), axis = 1) == y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd468e2a-5be2-4a58-a89e-464add088fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07b9d3f-6c96-455e-a47f-9d373b800622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09fe58a9-627d-49ec-b78f-1cba407f3c1a",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "085f84e6-b87e-44e1-88b9-0ea98c59e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "train_kwargs = {'batch_size': 32}\n",
    "test_kwargs = {'batch_size': 32}\n",
    "\n",
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                   transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56cfa902-381b-467a-ba59-46ebdb7df0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    print(batch_idx, target[0])\n",
    "    plt.imshow(data[0,0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ccfc2c-3425-404c-b178-6ad679016ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
