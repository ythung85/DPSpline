{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d78638a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import glob\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6fe4a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_brain(imgdir, w, h):\n",
    "\n",
    "    WIDTH, HEIGHT = w, h\n",
    "    \n",
    "    x = []\n",
    "    for i in range(len(imgdir)):\n",
    "        # Read and resize image\n",
    "        full_size_image = cv2.imread(imgdir[i])\n",
    "        x.append(cv2.resize(full_size_image, (WIDTH,HEIGHT), interpolation=cv2.INTER_CUBIC)/255.0) \n",
    "\n",
    "    return x\n",
    "\n",
    "def diag_mat_weights(dimp, type = 'first'):\n",
    "    if type == 'first':\n",
    "        dg = np.zeros((dimp-1, dimp))\n",
    "        for i in range(dimp-1):\n",
    "            dg[i,i] = -1\n",
    "            dg[i,i+1]= 1\n",
    "    elif type == 'second':\n",
    "        dg = np.zeros((dimp-2, dimp))\n",
    "        for i in range(dimp-2):\n",
    "            dg[i,i] = -1\n",
    "            dg[i,i+1]= 2\n",
    "            dg[i,i+2]= -1\n",
    "    else:\n",
    "        pass\n",
    "    return torch.Tensor(dg)\n",
    "    \n",
    "class PRODBSplineLayerMultiFeature(nn.Module):\n",
    "    def __init__(self, input_dim, degree, num_knots, output_dim, num_neurons, bias = True):\n",
    "        super(PRODBSplineLayerMultiFeature, self).__init__()\n",
    "        self.degree = degree\n",
    "        self.num_knots = num_knots\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_neurons = num_neurons\n",
    "        \n",
    "        if input_dim == 2:\n",
    "            self.control_p = nn.Parameter(torch.randn(self.num_knots**2, self.output_dim))\n",
    "        else:\n",
    "            self.control_p = nn.Parameter(torch.randn(self.num_knots, self.num_neurons))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.randn(self.num_neurons))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        self.inter = {}\n",
    "    \n",
    "    def basis_function(self, x, i, k, t):\n",
    "    \n",
    "        # Base case: degree 0 spline\n",
    "        if k == 0:\n",
    "            return ((t[i] <= x) & (x < t[i + 1])).float()\n",
    "    \n",
    "        # Recursive case\n",
    "        denom1 = t[i + k] - t[i]\n",
    "        denom2 = t[i + k + 1] - t[i + 1]\n",
    "    \n",
    "        term1 = 0\n",
    "        if denom1 != 0:\n",
    "            term1 = (x - t[i]) / denom1 * self.basis_function(x, i, k - 1, t)\n",
    "    \n",
    "        term2 = 0\n",
    "        if denom2 != 0:\n",
    "            term2 = (t[i + k + 1] - x) / denom2 * self.basis_function(x, i + 1, k - 1, t)\n",
    "    \n",
    "        return term1 + term2\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, num_features = x.size()\n",
    "        device = x.device\n",
    "        \n",
    "        # Create knot vector\n",
    "        # knots = torch.linspace(0, 1, self.num_knots + self.degree + 1).to(device)\n",
    "        knots = torch.cat([\n",
    "                        torch.zeros(self.degree),               # Add repeated values at the start for clamping\n",
    "                        torch.linspace(0, 1, self.num_knots - self.degree + 1),  # Uniform knot spacing in the middle\n",
    "                        torch.ones(self.degree)                 # Add repeated values at the end for clamping\n",
    "                    ]).to(device)\n",
    "        # Apply B-spline basis functions for each feature\n",
    "        basises = []\n",
    "    \n",
    "        \n",
    "        for feature in range(num_features):\n",
    "            # Calculate B-spline basis functions for this feature\n",
    "            basis = torch.stack([self.basis_function(x[:, feature], i, self.degree, knots) \n",
    "                                 for i in range(self.num_knots)], dim=-1)\n",
    "            basises.append(basis)\n",
    "            \n",
    "        \n",
    "        if num_features == 1:\n",
    "            tout = basises[0] @ self.control_p\n",
    "            self.inter['basic'] = basises[0].T\n",
    "        else:\n",
    "            self.inter['basic'] = torch.reshape(torch.stack(basises, dim = 1), (batch_size, self.num_knots * self.num_neurons)).T\n",
    "            basises = torch.stack(basises)\n",
    "            tout = basises.permute(1,2,0) * self.control_p\n",
    "            tout = tout.sum(dim =1)\n",
    "                \n",
    "        if self.bias is not None:\n",
    "            tout += self.bias        \n",
    "            \n",
    "        return tout\n",
    "        \n",
    "class NormLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NormLayer, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        min_val = torch.min(x, axis = 1).values.reshape(-1,1)\n",
    "        max_val = torch.max(x, axis = 1).values.reshape(-1,1)\n",
    "\n",
    "        x = (x - min_val)/(max_val - min_val)  # Rescale to [0, 1]\n",
    "        return x.detach()\n",
    "        \n",
    "def ECM(model, num_neurons, num_knots, initial_xi = 1, initial_sigma = 1, initial_lambda = 1e-4, L = None):\n",
    "    lambdab = initial_lambda\n",
    "    sigma = initial_sigma\n",
    "    xi = initial_xi\n",
    "\n",
    "    if L == 1:\n",
    "        B = model.inter['ebasic']\n",
    "        By = model.inter['basic']\n",
    "        WB = model.sp1.control_p\n",
    "    else:\n",
    "        B = model.inter['ebasic2']\n",
    "        By = model.inter['basic2']\n",
    "        WB = model.sp2.control_p\n",
    "        \n",
    "    DB = diag_mat_weights(WB.size()[0]).to(device)\n",
    "    size = B.size()[1]\n",
    "    S = DB.T @ DB\n",
    "    Cov_a = (xi**2)* torch.linalg.pinv(S)\n",
    "    Cov_e = torch.eye(size*num_neurons)* sigma\n",
    "    \n",
    "    block_y = torch.reshape(By, (-1,1))\n",
    "    flatB = B.view(num_neurons, num_knots, size)\n",
    "        \n",
    "    sqr_xi= 0\n",
    "    sqr_sig = 0\n",
    "    \n",
    "    for i in range(num_neurons):\n",
    "        Ncov = (Cov_a -(Cov_a @ flatB[i]) @ (torch.linalg.pinv(flatB[i].T @ Cov_a @ flatB[i] + Cov_e[size*i:size*(i+1),size*i:size*(i+1)]) @ flatB[i].T @ Cov_a))\n",
    "        Nmu = (Cov_a @ flatB[i]) @ (torch.linalg.pinv(flatB[i].T @ Cov_a @ flatB[i] + Cov_e[size*i:size*(i+1),size*i:size*(i+1)])) @ By[:,i].reshape(-1,1)\n",
    "        \n",
    "        first_xi = S @ Ncov\n",
    "        second_xi = (Nmu.T @ S @ Nmu)\n",
    "        sqr_xi += torch.trace(first_xi) + second_xi\n",
    "            \n",
    "        first_sig = torch.norm(By[:,i])\n",
    "        second_sig = 2 * (By[:,i] @ flatB[i].T) @ Nmu \n",
    "        third_sig = torch.trace((flatB[i] @ flatB[i].T) @ Ncov)\n",
    "        four_sig = (Nmu.T @ flatB[i] @ flatB[i].T @ Nmu)\n",
    "        \n",
    "        sqr_sig += (first_sig + second_sig + third_sig + four_sig)\n",
    "    \n",
    "    sqr_xi /= num_neurons\n",
    "    sqr_sig /= (num_neurons*size)\n",
    "    \n",
    "    Lambda = sqr_sig/sqr_xi\n",
    "    \n",
    "    return Lambda.item()\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9966f6c2-493c-4777-ab80-510d7e2e107c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "In this section, we will load the brain tumor MRI Images and resize it to 224x224 pixels and ensure the images are in gray scale for numerical stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2821748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = glob.glob('/Users/a080528/Downloads/BrainTumor/Training/glioma/*.jpg')\n",
    "train2 = glob.glob('/Users/a080528/Downloads/BrainTumor/Training/notumor/*.jpg')\n",
    "test1 = glob.glob('/Users/a080528/Downloads/BrainTumor/Testing/glioma/*.jpg')\n",
    "test2 = glob.glob('/Users/a080528/Downloads/BrainTumor/Testing/notumor/*.jpg')\n",
    "\n",
    "train = [train1, train2]; test = [test1, test2]\n",
    "\n",
    "trainx = []\n",
    "for f in train:\n",
    "    x = proc_brain(f, 224, 224)\n",
    "    trainx.append(x)\n",
    "\n",
    "testx = []\n",
    "for f in test:\n",
    "    x = proc_brain(f, 224, 224)\n",
    "    testx.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92c2c19a-cc6b-489d-9f52-3734e1d881df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtraind = np.concatenate((np.array(trainx[0]), np.array(trainx[1])))\n",
    "y_train = np.array([1]*len(trainx[0]))\n",
    "y_train = np.concatenate((y_train, [0]*len(trainx[1])))\n",
    "Xtestd = np.concatenate((np.array(testx[0]), np.array(testx[1])))\n",
    "y_test = np.array([1]*len(testx[0]))\n",
    "y_test = np.concatenate((y_test, [0]*len(testx[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab838770-3743-40ce-9b1b-8fd7575ab25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Training) Number of glioma image: 274 |  Number of non-tumor image: 226 \n",
      " (Testing) Number of glioma image: 172 |  Number of non-tumor image: 128 \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this block, you can customize the number of training size and testing size. According to your setting, we will \n",
    "randomly select the assigned number from image dataset. In this demo, we randomly select 500 images and 300 images\n",
    "from training and testing dataset respectively. Besides, in order to fulfill the requirement of Pytorch, we need to\n",
    "change the data to suitable type.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "trainsize = 500; testsize = 300\n",
    "\n",
    "np.random.seed(123)\n",
    "trainid = np.random.choice(len(Xtraind), trainsize)\n",
    "testid = np.random.choice(len(Xtestd), testsize)\n",
    "\n",
    "print(f\"(Training) Number of glioma image: {Counter(y_train[trainid])[0]} |  Number of non-tumor image: {Counter(y_train[trainid])[1]} \")\n",
    "print(f\" (Testing) Number of glioma image: {Counter(y_test[testid])[0]} |  Number of non-tumor image: {Counter(y_test[testid])[1]} \")\n",
    "\n",
    "X_train = torch.Tensor(Xtraind[trainid]).permute(0, 3, 1, 2); y_train = torch.Tensor(y_train[trainid]).type(torch.LongTensor)\n",
    "X_test = torch.Tensor(Xtestd[testid]).permute(0, 3, 1, 2); y_test = torch.Tensor(y_test[testid]).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ec4c1-0d38-469f-a71d-774afab3424d",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e2b19",
   "metadata": {},
   "source": [
    "## CNDNN-S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abf8374-370b-460b-8884-6c46511663ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ca85f92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNS1(nn.Module):\n",
    "    def __init__(self, input_dim, degree, num_knots, num_neurons, output_dim, bias):\n",
    "        super(DNNS1, self).__init__()\n",
    "        self.num_neurons = num_neurons\n",
    "        self.num_knots = num_knots\n",
    "        self.ln1 = nn.Linear(input_dim, num_neurons)\n",
    "        self.nm1 = NormLayer() \n",
    "        self.sp1 = PRODBSplineLayerMultiFeature(input_dim = 1, degree = degree, num_knots = num_knots, num_neurons = num_neurons, output_dim= output_dim, bias = True)\n",
    "        self.ln2 = nn.Linear(num_neurons, output_dim)\n",
    "        self.inter = {}\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ln1out = self.ln1(x)\n",
    "        ln1out = self.nm1(ln1out)\n",
    "        \n",
    "        device = ln1out.device\n",
    "        batch_size, _ = x.size()\n",
    "        \n",
    "        # # # # # # # # # # # # # #\n",
    "        #         SPLINE 1        #\n",
    "        # # # # # # # # # # # # # #\n",
    "        \n",
    "        sp1out = self.sp1(ln1out)\n",
    "        bslist = self.sp1.inter['basic']\n",
    "        \n",
    "        self.inter['ebasic'] = bslist\n",
    "        self.inter['basic'] = sp1out\n",
    "\n",
    "        ln2out = self.ln2(sp1out)        \n",
    "        return ln2out\n",
    "\n",
    "class TumorClassifier(nn.Module):\n",
    "    def __init__(self, Fin, dg, nk, nm, Fout, bias):\n",
    "        super(TumorClassifier, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.gap = nn.Flatten()\n",
    "        self.classifier = DNNS1(input_dim = Fin, degree = dg, num_knots = nk, num_neurons = nm, output_dim = Fout, bias = True).to(device)\n",
    "        self.sm = nn.Softmax(dim = 1)\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.gap(x)\n",
    "        x = self.classifier(x)\n",
    "        x = self.sm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3644a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model setting:\n",
    "\n",
    "`device`: running the program with cpu or gpu\n",
    "`tmc`: the classifier that equip with DNN-S \n",
    "`nm` : number of neuron in DNN-S\n",
    "`nk` : number of knot in DNN-S\n",
    "`patientc` : (early-stop crierion) If the model didn't improve in n epoch then stop.\n",
    "`patientr` : If the model didn't improve in n epoch then decrease learning rate with specific factor.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# experiment setting\n",
    "Iteration = 10000; bloss_list = []; tor = 1e-5; lr_tor = 1e-6\n",
    "patientc = 10; patientr = 5; tpat = 0; bloss = 9999\n",
    "nm = 100; nk = 15; doutput = 2\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model parameter \n",
    "tmc = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True)\n",
    "learning_r = 1e-2\n",
    "optimizer = torch.optim.Adam(tmc.parameters(), lr=learning_r)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe77a332-a3d3-4c68-978a-3c23fce7a8d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a07ad2-d621-40af-8634-8a143e45361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(Iteration):\n",
    "\n",
    "    # Forward pass: Compute predicted y by passing x to the modelsp\n",
    "    pyb_af = tmc(X_train)\n",
    "    loss = criterion(pyb_af, y_train); bloss_list.append(loss.item())\n",
    "    \n",
    "    if (t > 0) and ((bloss_list[t-1]-bloss_list[t])<tor):        \n",
    "        if (tpat % patientr) == 0:\n",
    "            learning_r *= 0.2 \n",
    "            tpat += 1\n",
    "            #print('Learning rate reduce to ', learning_r)\n",
    "            optimizer = torch.optim.Adam(tmc.parameters(), lr=learning_r)\n",
    "            if learning_r <= lr_tor:\n",
    "                print('Convergence!')\n",
    "                break\n",
    "        elif tpat < patientc:\n",
    "            tpat += 1\n",
    "            pass\n",
    "        else:\n",
    "            print('Convergence!')\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        if loss < bloss:\n",
    "            #torch.save(tmc.state_dict(), './brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk))\n",
    "            bloss = loss.item()\n",
    "            tpat = 0\n",
    "        tpat += 1\n",
    "\n",
    "    if tpat == patientc:\n",
    "        print('Convergence!')\n",
    "        break\n",
    "    \n",
    "    prediction = torch.argmax(pyb_af, axis = 1)\n",
    "    acc = (torch.argmax(pyb_af, axis = 1) == y_train).sum()/len(y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if(t % 10 == 0):\n",
    "        print('| Epoch: ',t+1,'/',str(Iteration),' | Loss: ', np.round(loss.item(), 4),' | Acc: ', acc.item())\n",
    "        if(t % 50 == 0):\n",
    "            with torch.no_grad():\n",
    "                print((torch.argmax(tmc(X_test).detach(), axis = 1) == y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db9048f-3f4a-4a65-a120-338d4bf50bdb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ECM Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a8f42ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the ECM tunning for penalty in each layer\n",
      "Lambda: 0.2357| Training Loss: 0.6829500198364258| Training GCV: 4.268463726475602e-06\n",
      "Lambda: 0.27503| Training Loss: 0.5793099999427795| Training GCV: 3.62062542080821e-06\n",
      "Lambda: 0.27773| Training Loss: 0.7097499966621399| Training GCV: 4.435667051438941e-06\n",
      "Lambda: 0.20232| Training Loss: 0.6283699870109558| Training GCV: 3.927318175556138e-06\n",
      "Lambda: 0.19315| Training Loss: 0.6672599911689758| Training GCV: 4.173381967120804e-06\n",
      "Lambda: 0.1774| Training Loss: 0.6161199808120728| Training GCV: 4.7093672037590295e-06\n",
      "Lambda: 0.17239| Training Loss: 0.6477500200271606| Training GCV: 3.9890310290502384e-06\n",
      "Lambda: 0.16794| Training Loss: 0.6128600239753723| Training GCV: 3.708579697558889e-06\n",
      "Lambda: 0.16491| Training Loss: 0.6821600198745728| Training GCV: 4.254592113284161e-06\n",
      "Lambda: 0.16238| Training Loss: 0.6178699731826782| Training GCV: 3.938550435123034e-06\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "`ECM_epoch`: number of epoch to run the ecm tuning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"Running the ECM tunning for penalty in each layer\")\n",
    "\n",
    "ECM_epoch = 10\n",
    "with torch.no_grad():\n",
    "    eval_model = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "    eval_model.load_state_dict(torch.load('./brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "\n",
    "    WB = eval_model.classifier.sp1.control_p\n",
    "    DB = diag_mat_weights(WB.size()[0], 'second').to(device)\n",
    "    \n",
    "    BestGCV = np.inf\n",
    "    n = X_train.size()[0]\n",
    "    \n",
    "    for i in range(ECM_epoch):\n",
    "        eval_model.train()\n",
    "        MPSy = eval_model(X_train)\n",
    "\n",
    "        # update following layer except for last layer\n",
    "        LambdaB1 = ECM(model = eval_model.classifier, num_neurons = nm, num_knots = nk, L = 1)\n",
    "        \n",
    "        B1 = eval_model.classifier.inter['ebasic']\n",
    "        By1 = eval_model.classifier.inter['basic']\n",
    "        P2 = By1 @ torch.inverse(By1.T @ By1) @ By1.T\n",
    "\n",
    "        \n",
    "        size1 = B1.size()[1]\n",
    "        B1 = B1.view(nk, nm, size1)\n",
    "\n",
    "        NW1 = torch.empty((nk, nm))\n",
    "        NB1 = torch.empty((nm))\n",
    "\n",
    "        \n",
    "        for i in range(nm):\n",
    "            B1y = By1[:,i] - eval_model.classifier.sp1.bias.data[i]\n",
    "            BB1 = B1[:,i].T\n",
    "\n",
    "            # Update the weights and bias\n",
    "            NW1[:, i] = (torch.inverse(BB1.T @ BB1 + (LambdaB1/size1) * (DB.T @ DB)) @ BB1.T @ B1y)\n",
    "            NB1[i] = torch.mean(By1[:,i] - (NW1[:,i] @ BB1.T))\n",
    "            \n",
    "        # update the weight\n",
    "        getattr(eval_model.classifier.sp1, 'control_p').data = NW1; getattr(eval_model.classifier.sp1, 'bias').data = NB1\n",
    "\n",
    "        # update the last layer\n",
    "        WholeB = torch.cat((torch.ones((n,1)), By1), dim = 1)\n",
    "        NLn2W = (torch.inverse(WholeB.T @ WholeB) @ WholeB.T @ MPSy.type(torch.FloatTensor)).T\n",
    "        getattr(eval_model.classifier.ln2, 'bias').data = NLn2W[:,0]; getattr(eval_model.classifier.ln2, 'weight').data = NLn2W[:,1:]\n",
    "        \n",
    "        eval_model.eval()\n",
    "        pred_postecm = eval_model(X_train)\n",
    "        CLoss = criterion(pred_postecm.detach(), y_train)\n",
    "        trainGCV = CLoss/(n-torch.trace(P2))**2\n",
    "        \n",
    "        if trainGCV < BestGCV:\n",
    "            BestLambdaB = LambdaB1\n",
    "            BestGCV = trainGCV\n",
    "            \n",
    "        print(f\"Lambda: {np.round(LambdaB1, 5)}| Training Loss: {np.round(CLoss, 5)}| Training GCV: {trainGCV.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0d2cc9-3170-4ad5-aade-cfaa73cabc68",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### DPS fast tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f20ef1a-c2f0-4e8a-984c-d0d016afc0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "`fast_epoch`: number of epoch to run the fast tuning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "fast_epoch = 201\n",
    "DPS = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "DPS.load_state_dict(torch.load('./brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "lr_ft = 1e-2\n",
    "optimizer = torch.optim.Adam(DPS.parameters(), lr=lr_ft)\n",
    "\n",
    "for t in range(1, fast_epoch):\n",
    "\n",
    "    # Forward pass: Compute predicted y by passing x to the modelsp\n",
    "    pyb_af = DPS(X_train)\n",
    "\n",
    "    WB1 = DPS.classifier.sp1.control_p.data; DB1 = diag_mat_weights(WB1.size()[0]).to(device)\n",
    "\n",
    "    loss = criterion(pyb_af, y_train) + (BestLambdaB/n) * torch.norm(DB1 @ WB1)\n",
    "    bloss_list.append(loss.item())\n",
    "    \n",
    "    prediction = torch.argmax(pyb_af, axis = 1)\n",
    "    acc = (torch.argmax(pyb_af, axis = 1) == y_train).sum()/len(y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if t % 10 == 0:\n",
    "        print('| Epoch: ',t+1,'/',str(Iteration),' | Loss: ', loss.item(),' | Acc: ', np.round(acc.item(), 5))\n",
    "        if t % 100 == 0:\n",
    "            with torch.no_grad():\n",
    "                print((torch.argmax(DPS(X_test).detach(), axis = 1) == y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd8e860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "856f41ac",
   "metadata": {},
   "source": [
    "## CN2DPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05c243a-99fc-49d3-963f-42ca6f942a3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6c657077",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRODBSplineLayerMultiFeature(nn.Module):\n",
    "    def __init__(self, input_dim, degree, num_knots, output_dim, num_neurons, bias = True):\n",
    "        super(PRODBSplineLayerMultiFeature, self).__init__()\n",
    "        self.degree = degree\n",
    "        self.num_knots = num_knots\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_neurons = num_neurons\n",
    "        \n",
    "        if input_dim == 2:\n",
    "            self.control_p = nn.Parameter(torch.randn(self.num_knots**2, self.output_dim))\n",
    "        else:\n",
    "            self.control_p = nn.Parameter(torch.randn(self.num_knots, self.num_neurons))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.randn(self.num_neurons))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        self.inter = {}\n",
    "    \n",
    "    def basis_function(self, x, i, k, t):\n",
    "    \n",
    "        # Base case: degree 0 spline\n",
    "        if k == 0:\n",
    "            return ((t[i] <= x) & (x < t[i + 1])).float()\n",
    "    \n",
    "        # Recursive case\n",
    "        denom1 = t[i + k] - t[i]\n",
    "        denom2 = t[i + k + 1] - t[i + 1]\n",
    "    \n",
    "        term1 = 0\n",
    "        if denom1 != 0:\n",
    "            term1 = (x - t[i]) / denom1 * self.basis_function(x, i, k - 1, t)\n",
    "    \n",
    "        term2 = 0\n",
    "        if denom2 != 0:\n",
    "            term2 = (t[i + k + 1] - x) / denom2 * self.basis_function(x, i + 1, k - 1, t)\n",
    "    \n",
    "        return term1 + term2\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, num_features = x.size()\n",
    "        device = x.device\n",
    "        \n",
    "        # Create knot vector\n",
    "        # knots = torch.linspace(0, 1, self.num_knots + self.degree + 1).to(device)\n",
    "        knots = torch.cat([\n",
    "                        torch.zeros(self.degree),               # Add repeated values at the start for clamping\n",
    "                        torch.linspace(0, 1, self.num_knots - self.degree + 1),  # Uniform knot spacing in the middle\n",
    "                        torch.ones(self.degree)                 # Add repeated values at the end for clamping\n",
    "                    ]).to(device)\n",
    "        # Apply B-spline basis functions for each feature\n",
    "        basises = []\n",
    "    \n",
    "        \n",
    "        for feature in range(num_features):\n",
    "            # Calculate B-spline basis functions for this feature\n",
    "            basis = torch.stack([self.basis_function(x[:, feature], i, self.degree, knots) \n",
    "                                 for i in range(self.num_knots)], dim=-1)\n",
    "            basises.append(basis)\n",
    "            \n",
    "        if num_features == 1:\n",
    "            tout = basises[0] @ self.control_p\n",
    "            self.inter['eachbasic'] = basises[0].T\n",
    "        else:\n",
    "            #self.inter['basic'] = torch.reshape(torch.stack(basises, dim = 1), (batch_size, self.num_knots * self.num_neurons)).T\n",
    "            self.inter['eachbasic'] = torch.reshape(torch.stack(basises, dim = 1), (batch_size, self.num_knots * self.num_neurons)).T\n",
    "            \n",
    "            basises = torch.stack(basises)\n",
    "            tout = basises.permute(1,2,0) * self.control_p\n",
    "            tout = tout.sum(dim =1)\n",
    "                \n",
    "        if self.bias is not None:\n",
    "            tout += self.bias        \n",
    "\n",
    "        self.inter['basicoutput'] = tout\n",
    "        \n",
    "        return tout\n",
    "        \n",
    "class DNNS2(nn.Module):\n",
    "    def __init__(self, input_dim, degree, num_knots, num_neurons, output_dim, bias):\n",
    "        super(DNNS2, self).__init__()\n",
    "        self.num_neurons = num_neurons\n",
    "        self.num_knots = num_knots\n",
    "        self.ln1 = nn.Linear(input_dim, num_neurons)\n",
    "        self.nm1 = NormLayer() \n",
    "        self.sp1 = PRODBSplineLayerMultiFeature(input_dim = 1, degree = degree, num_knots = num_knots, num_neurons = num_neurons, output_dim= output_dim, bias = True)\n",
    "        self.nm2 = NormLayer() \n",
    "        self.sp2 = PRODBSplineLayerMultiFeature(input_dim = 1, degree = degree, num_knots = num_knots, num_neurons = num_neurons, output_dim= output_dim, bias = True)\n",
    "        self.ln2 = nn.Linear(num_neurons, output_dim)\n",
    "        self.inter = {}\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ln1out = self.ln1(x)\n",
    "        ln1out = self.nm1(ln1out)\n",
    "        \n",
    "        device = ln1out.device\n",
    "        batch_size, _ = x.size()\n",
    "        \n",
    "        # # # # # # # # # # # # # #\n",
    "        #         SPLINE          #\n",
    "        # # # # # # # # # # # # # #\n",
    "        \n",
    "        sp1out = self.sp1(ln1out)\n",
    "        sp1out = self.nm2(sp1out)\n",
    "\n",
    "        # # # # # # # # # # # # # #\n",
    "        #         SPLINE 2        #\n",
    "        # # # # # # # # # # # # # #\n",
    "        \n",
    "        sp2out = self.sp2(sp1out)\n",
    "        ln2out = self.ln2(sp2out)\n",
    "        \n",
    "        return ln2out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "5cdfa154",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TumorClassifier(nn.Module):\n",
    "    def __init__(self, Fin, dg, nk, nm, Fout, bias):\n",
    "        super(TumorClassifier, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.gap = nn.Flatten()\n",
    "        self.classifier = DNNS2(input_dim = 32*56*56, degree = dg, num_knots = nk, num_neurons = nm, output_dim = Fout, bias = True).to(device)\n",
    "        self.sm = nn.Softmax(dim = 1)\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.gap(x)\n",
    "        x = self.classifier(x)\n",
    "        x = self.sm(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "95e298a8-e59c-4e6f-a128-97f89518f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\"\"\"\n",
    "Model setting:\n",
    "\n",
    "`device`: running the program with cpu or gpu\n",
    "`tmc`: the classifier that equip with DNN-S \n",
    "`nm` : number of neuron in DNN-S\n",
    "`nk` : number of knot in DNN-S\n",
    "`patientc` : (early-stop crierion) If the model didn't improve in n epoch then stop.\n",
    "`patientr` : If the model didn't improve in n epoch then decrease learning rate with specific factor.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# experiment setting\n",
    "Iteration = 10000; bloss_list = []; tor = 1e-5; lr_tor = 1e-6\n",
    "patientc = 10; patientr = 5; tpat = 0; bloss = 9999\n",
    "nm = 100; nk = 15; doutput = 2\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model parameter \n",
    "tmc = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True)\n",
    "learning_r = 1e-2\n",
    "optimizer = torch.optim.Adam(tmc.parameters(), lr=learning_r)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898a94e5-1957-4500-8f25-ab7c80163a56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3b8d95b3-4114-4843-868c-f0fb71da6b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:  1 / 100  | Loss:  0.6802  | Acc:  0.593999981880188\n",
      "tensor(0.5733)\n",
      "| Epoch:  11 / 100  | Loss:  0.6035  | Acc:  0.722000002861023\n",
      "| Epoch:  21 / 100  | Loss:  0.5478  | Acc:  0.7919999957084656\n",
      "| Epoch:  31 / 100  | Loss:  0.5064  | Acc:  0.8199999928474426\n",
      "| Epoch:  41 / 100  | Loss:  0.4776  | Acc:  0.8560000061988831\n",
      "| Epoch:  51 / 100  | Loss:  0.4547  | Acc:  0.8899999856948853\n",
      "tensor(0.7667)\n",
      "| Epoch:  61 / 100  | Loss:  0.4357  | Acc:  0.8939999938011169\n",
      "| Epoch:  71 / 100  | Loss:  0.4198  | Acc:  0.9139999747276306\n",
      "| Epoch:  81 / 100  | Loss:  0.4061  | Acc:  0.9259999990463257\n",
      "| Epoch:  91 / 100  | Loss:  0.3934  | Acc:  0.9419999718666077\n"
     ]
    }
   ],
   "source": [
    "for t in range(Iteration):\n",
    "\n",
    "    # Forward pass: Compute predicted y by passing x to the modelsp\n",
    "    pyb_af = tmc(X_train)\n",
    "    loss = criterion(pyb_af, y_train); bloss_list.append(loss.item())\n",
    "    \n",
    "    if (t > 0) and ((bloss_list[t-1]-bloss_list[t])<tor):        \n",
    "        if (tpat % patientr) == 0:\n",
    "            learning_r *= 0.2 \n",
    "            tpat += 1\n",
    "            #print('Learning rate reduce to ', learning_r)\n",
    "            optimizer = torch.optim.Adam(tmc.parameters(), lr=learning_r)\n",
    "            if learning_r <= lr_tor:\n",
    "                print('Convergence!')\n",
    "                break\n",
    "        elif tpat < patientc:\n",
    "            tpat += 1\n",
    "            pass\n",
    "        else:\n",
    "            print('Convergence!')\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        if loss < bloss:\n",
    "            #torch.save(tmc.state_dict(), './brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk))\n",
    "            bloss = loss.item()\n",
    "            tpat = 0\n",
    "        tpat += 1\n",
    "\n",
    "    if tpat == patientc:\n",
    "        print('Convergence!')\n",
    "        break\n",
    "    \n",
    "    prediction = torch.argmax(pyb_af, axis = 1)\n",
    "    acc = (torch.argmax(pyb_af, axis = 1) == y_train).sum()/len(y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if(t % 10 == 0):\n",
    "        print('| Epoch: ',t+1,'/',str(Iteration),' | Loss: ', np.round(loss.item(), 4),' | Acc: ', acc.item())\n",
    "        if(t % 100 == 0):\n",
    "            with torch.no_grad():\n",
    "                print((torch.argmax(tmc(X_test).detach(), axis = 1) == y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "225c6bee-4b98-451f-8491-a49f4bba31d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    eval_model = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "    eval_model.load_state_dict(torch.load('./2brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "    pred_postecm = eval_model(X_train)\n",
    "    CLoss = criterion(pred_postecm.detach(), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e51c0-2f99-4ef6-ba48-03f4d59b06d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ECM Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ae012a20-9b3f-4152-846f-c7d04b52301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ECM(model, num_neurons, num_knots, initial_xi = 1, initial_sigma = 1, initial_lambda = 1e-4):\n",
    "    lambdab = initial_lambda\n",
    "    sigma = initial_sigma\n",
    "    xi = initial_xi\n",
    "\n",
    "    B = model.inter['eachbasic']\n",
    "    By = model.inter['basicoutput']\n",
    "    WB = model.control_p\n",
    "        \n",
    "    DB = diag_mat_weights(WB.size()[0]).to(device)\n",
    "    size = B.size()[1]\n",
    "    S = DB.T @ DB\n",
    "    Cov_a = (xi**2)* torch.linalg.pinv(S)\n",
    "    Cov_e = torch.eye(size*num_neurons)* sigma\n",
    "    \n",
    "    block_y = torch.reshape(By, (-1,1))\n",
    "    flatB = B.view(num_neurons, num_knots, size)\n",
    "        \n",
    "    sqr_xi= 0\n",
    "    sqr_sig = 0\n",
    "    \n",
    "    for i in range(num_neurons):\n",
    "        Ncov = (Cov_a -(Cov_a @ flatB[i]) @ (torch.linalg.pinv(flatB[i].T @ Cov_a @ flatB[i] + Cov_e[size*i:size*(i+1),size*i:size*(i+1)]) @ flatB[i].T @ Cov_a))\n",
    "        Nmu = (Cov_a @ flatB[i]) @ (torch.linalg.pinv(flatB[i].T @ Cov_a @ flatB[i] + Cov_e[size*i:size*(i+1),size*i:size*(i+1)])) @ By[:,i].reshape(-1,1)\n",
    "        \n",
    "        first_xi = S @ Ncov\n",
    "        second_xi = (Nmu.T @ S @ Nmu)\n",
    "        sqr_xi += torch.trace(first_xi) + second_xi\n",
    "            \n",
    "        first_sig = torch.norm(By[:,i])\n",
    "        second_sig = 2 * (By[:,i] @ flatB[i].T) @ Nmu \n",
    "        third_sig = torch.trace((flatB[i] @ flatB[i].T) @ Ncov)\n",
    "        four_sig = (Nmu.T @ flatB[i] @ flatB[i].T @ Nmu)\n",
    "        \n",
    "        sqr_sig += (first_sig + second_sig + third_sig + four_sig)\n",
    "    \n",
    "    sqr_xi /= num_neurons\n",
    "    sqr_sig /= (num_neurons*size)\n",
    "    \n",
    "    Lambda = sqr_sig/sqr_xi\n",
    "    \n",
    "    return Lambda.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "eda1c8f3-fd95-40e3-9816-d4edac44456f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the ECM tunning for penalty in each layer\n",
      "Lambda: [0.30183088779449463, 0.30312493443489075]| Training Loss: 0.7657999992370605| Training GCV: 4.786255885846913e-06\n",
      "Lambda: [0.973455011844635, 0.6522708535194397]| Training Loss: 0.8041099905967712| Training GCV: 4.120976882404648e-06\n",
      "Lambda: [1.3706945180892944, 0.3747212588787079]| Training Loss: 0.7974600195884705| Training GCV: 5.1150018407497555e-06\n",
      "Lambda: [1.8239096403121948, 0.3827195465564728]| Training Loss: 0.8612599968910217| Training GCV: 4.769452061736956e-06\n",
      "Lambda: [1.5904974937438965, 1.7096126079559326]| Training Loss: 0.7672600150108337| Training GCV: 3.7891347801632946e-06\n",
      "Lambda: [1.670275092124939, 1.7180237770080566]| Training Loss: 0.7532600164413452| Training GCV: 3.5555015074351104e-06\n",
      "Lambda: [1.777961254119873, 0.859359860420227]| Training Loss: 0.907260000705719| Training GCV: 4.15523027186282e-06\n",
      "Lambda: [1.9107773303985596, 1.430779218673706]| Training Loss: 0.7932599782943726| Training GCV: 3.4246222639922053e-06\n",
      "Lambda: [1.9577510356903076, 2.0410945415496826]| Training Loss: 0.8152599930763245| Training GCV: 3.541840897014481e-06\n",
      "Lambda: [1.9773733615875244, 1.1929782629013062]| Training Loss: 0.7972599864006042| Training GCV: 3.7175316265347647e-06\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "`ECM_epoch`: number of epoch to run the ecm tuning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "LoP = 2\n",
    "PSname = ['sp'+str(i+1) for i in range(LoP)]\n",
    "ECM_epoch = 10\n",
    "\n",
    "print(\"Running the ECM tunning for penalty in each layer\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    eval_model = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "    eval_model.load_state_dict(torch.load('./2brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "\n",
    "    BestGCV = np.inf\n",
    "    n = X_train.size()[0]\n",
    "    \n",
    "    for i in range(ECM_epoch):\n",
    "        eval_model.train()\n",
    "        MPSy = eval_model(X_train)\n",
    "    \n",
    "        # update following layer except for last layer\n",
    "        LambdaL = []\n",
    "        for layer in PSname:\n",
    "            splayer = getattr(eval_model.classifier, layer)\n",
    "            WB = getattr(splayer, 'control_p')\n",
    "            DB = diag_mat_weights(WB.size()[0], 'second').to(device)\n",
    "            LambdaB = ECM(model = getattr(eval_model.classifier, layer), num_neurons = nm, num_knots = nk)\n",
    "            LambdaL.append(LambdaB)\n",
    "            \n",
    "            B1 = getattr(eval_model.classifier, layer).inter['eachbasic']\n",
    "            By1 = getattr(eval_model.classifier, layer).inter['basicoutput']\n",
    "            P2 = By1 @ torch.inverse(By1.T @ By1) @ By1.T\n",
    "    \n",
    "            size1 = B1.size()[1]\n",
    "            B1 = B1.view(nk, nm, size1)\n",
    "    \n",
    "            NW1 = torch.empty((nk, nm))\n",
    "            NB1 = torch.empty((nm))\n",
    "    \n",
    "        \n",
    "            for i in range(nm):\n",
    "                B1y = By1[:,i] - getattr(eval_model.classifier, layer).bias.data[i]\n",
    "                BB1 = B1[:,i].T\n",
    "        \n",
    "                # Update the weights and bias\n",
    "                NW1[:, i] = (torch.inverse(BB1.T @ BB1 + (LambdaB/size1) * (DB.T @ DB)) @ BB1.T @ B1y)\n",
    "                NB1[i] = torch.mean(By1[:,i] - (NW1[:,i] @ BB1.T))\n",
    "                \n",
    "            # update the weight\n",
    "            getattr(splayer, 'control_p').data = NW1; getattr(splayer, 'bias').data = NB1\n",
    "    \n",
    "        # update the last layer\n",
    "        WholeB = torch.cat((torch.ones((n,1)), By1), dim = 1)\n",
    "        NLn2W = (torch.inverse(WholeB.T @ WholeB) @ WholeB.T @ MPSy.type(torch.FloatTensor)).T\n",
    "        \n",
    "        getattr(eval_model.classifier.ln2, 'bias').data = NLn2W[:,0]; getattr(eval_model.classifier.ln2, 'weight').data = NLn2W[:,1:]\n",
    "        \n",
    "        eval_model.eval()\n",
    "        pred_postecm = eval_model(X_train)\n",
    "        CLoss = criterion(pred_postecm.detach(), y_train)\n",
    "        trainGCV = CLoss/(n-torch.trace(P2))**2\n",
    "        \n",
    "        if trainGCV < BestGCV:\n",
    "            BestLambdaB = LambdaB1\n",
    "            BestGCV = trainGCV\n",
    "            \n",
    "        print(f\"Lambda: {LambdaL}| Training Loss: {np.round(CLoss, 5)}| Training GCV: {trainGCV.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d6556-afd1-41ac-8a91-9730eae7dd61",
   "metadata": {},
   "source": [
    "### 2DPS Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a9449ea7-7a9c-4ad4-8659-94451e6fc730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "`fast_epoch`: number of epoch to run the fast tuning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "fast_epoch = 201\n",
    "D2PS = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "D2PS.load_state_dict(torch.load('./2brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "lr_ft = 1e-2\n",
    "optimizer = torch.optim.Adam(D2PS.parameters(), lr=lr_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72b6da-e9b1-40dd-a842-5716c2d02a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(1, fast_epoch):\n",
    "\n",
    "    # Forward pass: Compute predicted y by passing x to the modelsp\n",
    "    pyb_af = D2PS(X_train)\n",
    "    loss = criterion(pyb_af, y_train)\n",
    "    \n",
    "    for l in range(len(PSname)):\n",
    "        WB = getattr(D2PS.classifier, PSname[l]).control_p.data; DB = diag_mat_weights(WB.size()[0]).to(device)\n",
    "        loss += (LambdaL[l]/n) * torch.norm(DB @ WB)\n",
    "            \n",
    "    prediction = torch.argmax(pyb_af, axis = 1)\n",
    "    acc = (torch.argmax(pyb_af, axis = 1) == y_train).sum()/len(y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if t % 10 == 0:\n",
    "        print('| Epoch: ',t+1,'/',str(Iteration),' | Loss: ', loss.item(),' | Acc: ', np.round(acc.item(), 5))\n",
    "        if t % 100 == 0:\n",
    "            with torch.no_grad():\n",
    "                print((torch.argmax(D2PS(X_test).detach(), axis = 1) == y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "340ce3e2-726e-4edc-8b0d-af17fec1000e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.9773733615875244, 1.1929782629013062]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4469282b-c8bd-4c97-a280-a02900722395",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Testing early-stop and decay lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "edfbcd01-da6a-40da-91c2-e75f333270e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:  1 / 10000  | Loss:  0.6334\n",
      "| Epoch:  2 / 10000  | Loss:  0.4917\n",
      "| Epoch:  3 / 10000  | Loss:  0.454\n",
      "| Epoch:  4 / 10000  | Loss:  0.4373\n",
      "| Epoch:  5 / 10000  | Loss:  0.424\n",
      "| Epoch:  6 / 10000  | Loss:  0.423\n",
      "| Epoch:  7 / 10000  | Loss:  0.4155\n",
      "| Epoch:  8 / 10000  | Loss:  0.404\n",
      "| Epoch:  9 / 10000  | Loss:  0.4032\n",
      "| Epoch:  10 / 10000  | Loss:  0.3994\n",
      "training result:  0.9300000071525574\n",
      "testing result:  0.8500000238418579\n",
      "| Epoch:  11 / 10000  | Loss:  0.3926\n",
      "| Epoch:  12 / 10000  | Loss:  0.3936\n",
      "| Epoch:  13 / 10000  | Loss:  0.3872\n",
      "| Epoch:  14 / 10000  | Loss:  0.3904\n",
      "| Epoch:  15 / 10000  | Loss:  0.3818\n",
      "| Epoch:  16 / 10000  | Loss:  0.3768\n",
      "| Epoch:  17 / 10000  | Loss:  0.3742\n",
      "| Epoch:  18 / 10000  | Loss:  0.3706\n",
      "| Epoch:  19 / 10000  | Loss:  0.3773\n",
      "| Epoch:  20 / 10000  | Loss:  0.3682\n",
      "training result:  0.9599999785423279\n",
      "testing result:  0.8799999952316284\n",
      "| Epoch:  21 / 10000  | Loss:  0.3663\n",
      "| Epoch:  22 / 10000  | Loss:  0.3691\n",
      "| Epoch:  23 / 10000  | Loss:  0.3635\n",
      "| Epoch:  24 / 10000  | Loss:  0.3618\n",
      "| Epoch:  25 / 10000  | Loss:  0.3632\n",
      "| Epoch:  26 / 10000  | Loss:  0.366\n",
      "| Epoch:  27 / 10000  | Loss:  0.3607\n",
      "| Epoch:  28 / 10000  | Loss:  0.3587\n",
      "| Epoch:  29 / 10000  | Loss:  0.3556\n",
      "| Epoch:  30 / 10000  | Loss:  0.3595\n",
      "training result:  0.9520000219345093\n",
      "testing result:  0.8899999856948853\n",
      "| Epoch:  31 / 10000  | Loss:  0.3606\n",
      "| Epoch:  32 / 10000  | Loss:  0.3552\n",
      "| Epoch:  33 / 10000  | Loss:  0.3535\n",
      "| Epoch:  34 / 10000  | Loss:  0.3533\n",
      "| Epoch:  35 / 10000  | Loss:  0.3513\n",
      "| Epoch:  36 / 10000  | Loss:  0.3587\n",
      "| Epoch:  37 / 10000  | Loss:  0.3533\n",
      "| Epoch:  38 / 10000  | Loss:  0.3524\n",
      "| Epoch:  39 / 10000  | Loss:  0.3541\n",
      "| Epoch:  40 / 10000  | Loss:  0.3504\n",
      "training result:  0.972000002861023\n",
      "testing result:  0.8949999809265137\n",
      "| Epoch:  41 / 10000  | Loss:  0.3486\n",
      "| Epoch:  42 / 10000  | Loss:  0.3491\n",
      "| Epoch:  43 / 10000  | Loss:  0.3483\n",
      "| Epoch:  44 / 10000  | Loss:  0.3477\n",
      "| Epoch:  45 / 10000  | Loss:  0.3497\n",
      "| Epoch:  46 / 10000  | Loss:  0.349\n",
      "| Epoch:  47 / 10000  | Loss:  0.3493\n",
      "| Epoch:  48 / 10000  | Loss:  0.3475\n",
      "| Epoch:  49 / 10000  | Loss:  0.3473\n",
      "| Epoch:  50 / 10000  | Loss:  0.3478\n",
      "training result:  0.972000002861023\n",
      "testing result:  0.8949999809265137\n",
      "| Epoch:  51 / 10000  | Loss:  0.3481\n",
      "| Epoch:  52 / 10000  | Loss:  0.3497\n",
      "| Epoch:  53 / 10000  | Loss:  0.348\n",
      "| Epoch:  54 / 10000  | Loss:  0.3484\n",
      "| Epoch:  55 / 10000  | Loss:  0.3482\n",
      "| Epoch:  56 / 10000  | Loss:  0.3471\n",
      "| Epoch:  57 / 10000  | Loss:  0.3493\n",
      "| Epoch:  58 / 10000  | Loss:  0.3491\n",
      "| Epoch:  59 / 10000  | Loss:  0.3467\n",
      "| Epoch:  60 / 10000  | Loss:  0.3502\n",
      "training result:  0.9739999771118164\n",
      "testing result:  0.8949999809265137\n",
      "| Epoch:  61 / 10000  | Loss:  0.3473\n",
      "| Epoch:  62 / 10000  | Loss:  0.3467\n",
      "| Epoch:  63 / 10000  | Loss:  0.3468\n",
      "| Epoch:  64 / 10000  | Loss:  0.3477\n",
      "| Epoch:  65 / 10000  | Loss:  0.3468\n",
      "| Epoch:  66 / 10000  | Loss:  0.3469\n",
      "| Epoch:  67 / 10000  | Loss:  0.3467\n",
      "| Epoch:  68 / 10000  | Loss:  0.3466\n",
      "| Epoch:  69 / 10000  | Loss:  0.3479\n",
      "| Epoch:  70 / 10000  | Loss:  0.3493\n",
      "training result:  0.9739999771118164\n",
      "testing result:  0.8949999809265137\n",
      "| Epoch:  71 / 10000  | Loss:  0.348\n",
      "| Epoch:  72 / 10000  | Loss:  0.3477\n",
      "| Epoch:  73 / 10000  | Loss:  0.3469\n",
      "| Epoch:  74 / 10000  | Loss:  0.3483\n",
      "| Epoch:  75 / 10000  | Loss:  0.3478\n",
      "| Epoch:  76 / 10000  | Loss:  0.3478\n",
      "| Epoch:  77 / 10000  | Loss:  0.3467\n",
      "| Epoch:  78 / 10000  | Loss:  0.3465\n",
      "| Epoch:  79 / 10000  | Loss:  0.3469\n",
      "| Epoch:  80 / 10000  | Loss:  0.3465\n",
      "training result:  0.9739999771118164\n",
      "testing result:  0.8949999809265137\n",
      "| Epoch:  81 / 10000  | Loss:  0.3493\n",
      "| Epoch:  82 / 10000  | Loss:  0.3488\n",
      "| Epoch:  83 / 10000  | Loss:  0.3501\n",
      "| Epoch:  84 / 10000  | Loss:  0.3469\n",
      "| Epoch:  85 / 10000  | Loss:  0.3467\n",
      "| Epoch:  86 / 10000  | Loss:  0.347\n",
      "| Epoch:  87 / 10000  | Loss:  0.3467\n",
      "| Epoch:  88 / 10000  | Loss:  0.3477\n",
      "| Epoch:  89 / 10000  | Loss:  0.3491\n",
      "Early Stop at Epoch:  90\n",
      "Saving the best model ...\n"
     ]
    }
   ],
   "source": [
    "nk = 15; nm = 100; doutput = 2\n",
    "tmc = TumorClassifier(Fin = 64, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True)\n",
    "\n",
    "learning_r = 1e-2\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(tmc.parameters(), lr=learning_r)\n",
    "Iteration = 10000; tor = 1e-5; bloss = 9999\n",
    "\n",
    "early_stopper = EarlyStopper(patience=10, min_delta=tor)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.2)\n",
    "\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for t in range(1, Iteration+1):\n",
    "\n",
    "    tmc.train()\n",
    "    train_loss = 0\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        # Forward pass\n",
    "        outputs = tmc(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    tmc.eval()\n",
    "        \n",
    "    if train_loss < bloss:\n",
    "        best_model = tmc.state_dict()\n",
    "        bloss = train_loss\n",
    "\n",
    "    scheduler.step(train_loss)\n",
    "    \n",
    "    if early_stopper.early_stop(train_loss):   \n",
    "        print('Early Stop at Epoch: ', t)\n",
    "        break    \n",
    "\n",
    "    print('| Epoch: ',t,'/',str(Iteration),' | Loss: ', np.round(train_loss/len(dataloader), 4))\n",
    "\n",
    "    if t % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            print('training result: ', ((torch.argmax(tmc(X_train).detach(), axis = 1) == y_train).sum()/len(y_train)).item())\n",
    "            print('testing result: ', ((torch.argmax(tmc(X_test).detach(), axis = 1) == y_test).sum()/len(y_test)).item())\n",
    "\n",
    "print('Saving the best model ...')\n",
    "torch.save(best_model, './Brain2MBS'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "632e3463-ab6f-4bf9-bebd-4af07b3d448d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9740)\n",
      "tensor(0.8950)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    eval_model = TumorClassifier(Fin = 64, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "    eval_model.load_state_dict(torch.load('./Brain2MBS'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "    print((torch.argmax(eval_model(X_train).detach(), axis = 1) == y_train).sum()/len(y_train))\n",
    "    print((torch.argmax(eval_model(X_test).detach(), axis = 1) == y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c16979b-e7c2-4821-87db-d7e6ff686f9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9a4ced5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:  1 / 10000  | Loss:  0.705  | Acc:  0.5460000038146973  | tAcc:  0.5666666626930237\n",
      "| Epoch:  11 / 10000  | Loss:  0.6469  | Acc:  0.6380000114440918  | tAcc:  0.5799999833106995\n",
      "| Epoch:  21 / 10000  | Loss:  0.5948  | Acc:  0.75  | tAcc:  0.6466666460037231\n",
      "| Epoch:  31 / 10000  | Loss:  0.5479  | Acc:  0.7820000052452087  | tAcc:  0.653333306312561\n",
      "| Epoch:  41 / 10000  | Loss:  0.5078  | Acc:  0.8140000104904175  | tAcc:  0.6933333277702332\n",
      "| Epoch:  51 / 10000  | Loss:  0.4748  | Acc:  0.8579999804496765  | tAcc:  0.7166666388511658\n",
      "| Epoch:  61 / 10000  | Loss:  0.4481  | Acc:  0.8859999775886536  | tAcc:  0.7366666793823242\n",
      "| Epoch:  71 / 10000  | Loss:  0.4266  | Acc:  0.9039999842643738  | tAcc:  0.7333333492279053\n",
      "| Epoch:  81 / 10000  | Loss:  0.4088  | Acc:  0.9259999990463257  | tAcc:  0.7433333396911621\n",
      "| Epoch:  91 / 10000  | Loss:  0.3935  | Acc:  0.9399999976158142  | tAcc:  0.7566666603088379\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[192], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m patientc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m; patientr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m; tpat \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m; bloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9999\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Iteration):\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Forward pass: Compute predicted y by passing x to the modelsp\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     pyb_af \u001b[38;5;241m=\u001b[39m \u001b[43mtmc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(pyb_af, y_train); bloss_list\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (t \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m ((bloss_list[t\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mbloss_list[t])\u001b[38;5;241m<\u001b[39mtor):        \n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[190], line 24\u001b[0m, in \u001b[0;36mTumorClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 24\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgap(x)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m#x = self.ln1(x)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m#x = self.drop1(x)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nk = 100; nm = 15; doutput = 2\n",
    "tmc = TumorClassifier(Fin = 50, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True)\n",
    "\n",
    "learning_r = 1e-2\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(tmc.parameters(), lr=learning_r)\n",
    "Iteration = 10000; bloss_list = []; tor = 1e-5; lr_tor = 1e-6\n",
    "patientc = 10; patientr = 5; tpat = 0; bloss = 9999\n",
    "\n",
    "for t in range(Iteration):\n",
    "\n",
    "    # Forward pass: Compute predicted y by passing x to the modelsp\n",
    "    pyb_af = tmc(X_train)\n",
    "    loss = criterion(pyb_af, y_train); bloss_list.append(loss.item())\n",
    "    \n",
    "    if (t > 0) and ((bloss_list[t-1]-bloss_list[t])<tor):        \n",
    "        if (tpat!= 0) and (tpat % patientr) == 0:\n",
    "            learning_r *= 0.2 \n",
    "            tpat += 1\n",
    "            #print('Learning rate reduce to ', learning_r)\n",
    "            optimizer = torch.optim.Adam(tmc.parameters(), lr=learning_r)\n",
    "            if learning_r <= lr_tor:\n",
    "                print('Convergence!')\n",
    "                break\n",
    "        elif tpat < patientc:\n",
    "            tpat += 1\n",
    "            pass\n",
    "        else:\n",
    "            print('Convergence!')\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        if loss < bloss:\n",
    "            #print('Current loss: ', loss.item(), ' | , previous best loss: ', bloss, ' | saving best model ...')\n",
    "            #torch.save(tmc.state_dict(), './Brain2MBS'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk))\n",
    "            bloss = loss.item()\n",
    "            tpat = 0\n",
    "        else:\n",
    "            tpat += 1\n",
    "        #tpat += 1\n",
    "\n",
    "    if tpat == patientc:\n",
    "        print('Convergence!')\n",
    "        with torch.no_grad():\n",
    "            eval_model = TumorClassifier(Fin = 64, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "            eval_model.load_state_dict(torch.load('./Brain2MBS'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "            print((torch.argmax(eval_model(X_test).detach(), axis = 1) == y_test).sum()/len(y_test))\n",
    "        break\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if t % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            prediction = torch.argmax(pyb_af, axis = 1)\n",
    "            acc = (torch.argmax(pyb_af, axis = 1) == y_train).sum()/len(y_train)\n",
    "            testacc = (torch.argmax(tmc(X_test).detach(), axis = 1) == y_test).sum()/len(y_test)\n",
    "            \n",
    "            print('| Epoch: ',t+1,'/',str(Iteration),' | Loss: ', np.round(loss.item(), 4),' | Acc: ', acc.item(),' | tAcc: ', testacc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "844bcb18-22f0-43b3-9204-c3b734091b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7133)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    eval_model = TumorClassifier(Fin = 64, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "    eval_model.load_state_dict(torch.load('./Brain2MBS'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "    print((torch.argmax(eval_model(X_test).detach(), axis = 1) == y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dd058f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Before adding penalty ... \n",
      "------------------------------------------\n",
      "After adding penalty ... \n",
      "Lambda:  0.04902  and  0.06129 | Training Loss:  0.3744  | GCV:  0.0\n",
      "Lambda:  0.04903  and  0.0613 | Training Loss:  0.3744  | GCV:  0.0\n",
      "Lambda:  0.04903  and  0.0613 | Training Loss:  0.3744  | GCV:  0.0\n",
      "Lambda:  0.04903  and  0.06131 | Training Loss:  0.3744  | GCV:  0.0\n",
      "Lambda:  0.04903  and  0.06132 | Training Loss:  0.3744  | GCV:  0.0\n",
      "Lambda:  0.04904  and  0.06133 | Training Loss:  0.37441  | GCV:  0.0\n",
      "Lambda:  0.04904  and  0.06134 | Training Loss:  0.37441  | GCV:  0.0\n",
      "Lambda:  0.04904  and  0.06134 | Training Loss:  0.37441  | GCV:  0.0\n",
      "Lambda:  0.04904  and  0.06135 | Training Loss:  0.37441  | GCV:  0.0\n",
      "Lambda:  0.04905  and  0.06136 | Training Loss:  0.37441  | GCV:  0.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print('------------------------------------------')\n",
    "    print('Before adding penalty ... ')\n",
    "    eval_model = TumorClassifier(Fin = 64, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "    eval_model.load_state_dict(torch.load('./Brain2MBS'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "    \n",
    "    #eval_model = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "    #eval_model.load_state_dict(torch.load('./2brainimg'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "    print('------------------------------------------')\n",
    "    print('After adding penalty ... ')\n",
    "\n",
    "    n = X_train.size()[0]\n",
    "    WB = eval_model.classifier.sp1.control_p\n",
    "    DB = diag_mat_weights(WB.size()[0], 'second').to(device)\n",
    "    Bestloss = 9999\n",
    "    \n",
    "    for i in range(10):\n",
    "        MPSy = eval_model(X_train)\n",
    "        LambdaB1 = ECM(model = eval_model.classifier, num_neurons = nm, num_knots = nk, L = 1)\n",
    "        LambdaB2 = ECM(model = eval_model.classifier, num_neurons = nm, num_knots = nk, L = 2)\n",
    "        \n",
    "        B1 = eval_model.classifier.inter['ebasic']\n",
    "        B2 = eval_model.classifier.inter['ebasic2']\n",
    "        P2 = (torch.linalg.pinv(B2.T @ B2) @ B2.T @ B2)\n",
    "        \n",
    "        By1 = eval_model.classifier.inter['basic']\n",
    "        By2 = eval_model.classifier.inter['basic2']\n",
    "        \n",
    "        size1 = B1.size()[1]\n",
    "        size2 = B2.size()[1]\n",
    "\n",
    "        B1 = B1.view(nm, nk, size1)\n",
    "        B2 = B2.view(nm, nk, size2)\n",
    "\n",
    "        NW1 = torch.empty((nk, nm))\n",
    "        NW2 = torch.empty((nk, nm))\n",
    "        NB1 = torch.empty((nm))\n",
    "        NB2 = torch.empty((nm))\n",
    "        for i in range(nm):\n",
    "            B1y = By1[:,i] - eval_model.classifier.sp1.bias.data[i]\n",
    "            B2y = By2[:,i] - eval_model.classifier.sp2.bias.data[i]\n",
    "\n",
    "            BB1 = B1[i].T\n",
    "            BB2 = B2[i].T\n",
    "            PB1 = (torch.linalg.pinv(BB1.T @ BB1) @ BB1.T @ BB1)\n",
    "            PB2 = (torch.linalg.pinv(BB2.T @ BB2) @ BB2.T @ BB2)\n",
    "\n",
    "            # Update the weights and bias\n",
    "            NW1[:, i] = (torch.inverse(BB1.T @ BB1 + (LambdaB1/size1) * (DB.T @ DB)) @ BB1.T @ B1y)\n",
    "            NW2[:, i] = (torch.inverse(BB2.T @ BB2 + (LambdaB2/size2) * (DB.T @ DB)) @ BB2.T @ B2y)\n",
    "            NB1[i] = torch.mean(By1[:,i] - (NW1[:,i] @ BB1.T))\n",
    "            NB2[i] = torch.mean(By2[:,i] - (NW2[:,i] @ BB2.T))\n",
    "            \n",
    "        # update the weight\n",
    "        getattr(eval_model.classifier.sp1, 'control_p').data = NW1\n",
    "        getattr(eval_model.classifier.sp2, 'control_p').data = NW2\n",
    "        getattr(eval_model.classifier.sp1, 'bias').data = NB1\n",
    "        getattr(eval_model.classifier.sp2, 'bias').data = NB2\n",
    "        \n",
    "\n",
    "        MPSy = eval_model(X_train)\n",
    "        trainloss = np.round(criterion(MPSy.detach(), y_train).item(), 5)\n",
    "        GCV = np.round((criterion(MPSy.detach(), y_train)/(n*size2-torch.trace(P2))).item(), 5)\n",
    "        \n",
    "        if trainloss < Bestloss:\n",
    "            BestLambdaB1, BestLambdaB2 = LambdaB1, LambdaB2\n",
    "            Bestloss = trainloss\n",
    "            \n",
    "        MPSy = eval_model(X_test)\n",
    "        print('Lambda: ', np.round(LambdaB1, 5),' and ', np.round(LambdaB2, 5),'| Training Loss: ', trainloss, ' | GCV: ', GCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0e3ee-deaa-4d38-afdf-f93c67bfb63f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f98b62a-2de6-4d00-b1f2-cf30b9b41a98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2bbc72aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss:  0.38404369354248047  | , previous best loss:  9999  | saving best model ...\n",
      "| Epoch:  1 / 10000  | Loss:  0.38404\n",
      "| Epoch:  2 / 10000  | Loss:  0.38404\n",
      "| Epoch:  3 / 10000  | Loss:  0.38403\n",
      "| Epoch:  4 / 10000  | Loss:  0.38403\n",
      "| Epoch:  5 / 10000  | Loss:  0.38403\n",
      "| Epoch:  6 / 10000  | Loss:  0.38402\n",
      "Learning rate reduce to  0.0002\n",
      "| Epoch:  7 / 10000  | Loss:  0.38402\n",
      "| Epoch:  8 / 10000  | Loss:  0.38401\n",
      "| Epoch:  9 / 10000  | Loss:  0.38401\n",
      "| Epoch:  10 / 10000  | Loss:  0.38401\n",
      "| Epoch:  10 / 10000  | Train ACC:  0.94\n",
      "Convergence!\n",
      "tensor(0.7100)\n"
     ]
    }
   ],
   "source": [
    "fast_epoch = 10001\n",
    "eval_model = TumorClassifier(Fin = 64, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "eval_model.load_state_dict(torch.load('./Brain2MBS'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "\n",
    "lr_ft = 1e-3; tor = 1e-5\n",
    "optimizer = torch.optim.Adam(eval_model.parameters(), lr=lr_ft)\n",
    "early_stopper = EarlyStopper(patience=10, min_delta=tor)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.2)\n",
    "patientr = 5; patientc = 10; tpat = 0; bloss = 9999; bloss_list = [bloss]\n",
    "for t in range(1, fast_epoch):\n",
    "\n",
    "    # Forward pass: Compute predicted y by passing x to the modelsp\n",
    "    eval_model.train()\n",
    "    pyb_af = eval_model(X_train)\n",
    "\n",
    "    WB1 = eval_model.classifier.sp1.control_p.data; DB1 = diag_mat_weights(WB1.size()[0]).to(device)\n",
    "    WB2 = eval_model.classifier.sp2.control_p.data; DB2 = diag_mat_weights(WB2.size()[0]).to(device)\n",
    "\n",
    "    loss = criterion(pyb_af, y_train) + (BestLambdaB1/n) * torch.norm(DB1 @ WB1) + (BestLambdaB2/n) * torch.norm(DB2 @ WB2)\n",
    "    bloss_list.append(loss)\n",
    "    \n",
    "    '''\n",
    "    if early_stopper.early_stop(loss):   \n",
    "        print('Early Stop at Epoch: ', t)\n",
    "        with torch.no_grad():\n",
    "            tsprediction = torch.argmax(eval_model(X_test), axis = 1)\n",
    "            tsacc = (tsprediction == y_test).sum()/len(y_test)\n",
    "            \n",
    "            tsprediction = torch.argmax(eval_model(X_test), axis = 1)\n",
    "            tsacc = (tsprediction == y_test).sum()/len(y_test)\n",
    "            print('| Epoch: ',t,'/',str(fast_epoch-1),' | Train ACC: ', np.round(tracc.item(), 4),' | Test ACC: ', tsacc.item())\n",
    "        break  \n",
    "\n",
    "    scheduler.step(loss)\n",
    "    '''\n",
    "\n",
    "    if (t > 0) and ((bloss_list[t-1]-bloss_list[t])<tor):        \n",
    "        if (tpat!= 0) and (tpat % patientr) == 0:\n",
    "            lr_ft *= 0.2 \n",
    "            tpat += 1\n",
    "            print('Learning rate reduce to ', lr_ft)\n",
    "            optimizer = torch.optim.Adam(eval_model.parameters(), lr=lr_ft)\n",
    "            if lr_ft <= lr_tor:\n",
    "                print('Convergence!')\n",
    "                break\n",
    "        elif tpat < patientc:\n",
    "            tpat += 1\n",
    "            pass\n",
    "        else:\n",
    "            print('Convergence!')\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        if loss < bloss:\n",
    "            print('Current loss: ', loss.item(), ' | , previous best loss: ', bloss, ' | saving best model ...')\n",
    "            torch.save(eval_model.state_dict(), './PBrain2DPS'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk))\n",
    "            bloss = loss.item()\n",
    "            tpat = 0\n",
    "        else:\n",
    "            tpat += 1\n",
    "\n",
    "    if tpat == patientc:\n",
    "        print('Convergence!')\n",
    "        with torch.no_grad():\n",
    "            eval_model.load_state_dict(torch.load('./PBrain2DPS'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "            print((torch.argmax(eval_model(X_test).detach(), axis = 1) == y_test).sum()/len(y_test))\n",
    "        break\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('| Epoch: ',t,'/',str(fast_epoch-1),' | Loss: ', np.round(loss.item(), 5))\n",
    "    if t % 10 == 0:\n",
    "        eval_model.eval()\n",
    "        with torch.no_grad():\n",
    "            trprediction = torch.argmax(pyb_af, axis = 1)\n",
    "            tracc = (trprediction == y_train).sum()/len(y_train)\n",
    "            print('| Epoch: ',t,'/',str(fast_epoch-1),' | Train ACC: ', np.round(tracc.item(), 4))\n",
    "\n",
    "        if t % 50 == 0:\n",
    "            with torch.no_grad():\n",
    "                tsprediction = torch.argmax(eval_model(X_test), axis = 1)\n",
    "                tsacc = (tsprediction == y_test).sum()/len(y_test)\n",
    "                print('| Epoch: ',t,'/',str(fast_epoch-1),' | Test ACC: ', np.round(tsacc.item(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09f850c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8866c332-51f1-4e78-bfc0-959973de68c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([20, 3, 224, 224])\n",
      "Epoch [1/10000], Loss: 13.4171\n",
      "testing:  0.48500001430511475\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([20, 3, 224, 224])\n",
      "Epoch [2/10000], Loss: 11.8130\n",
      "testing:  0.5450000166893005\n",
      "torch.Size([32, 3, 224, 224])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(inputs\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 21\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mresnet50\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py:275\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m--> 275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[1;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py:146\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    144\u001b[0m     identity \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m--> 146\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m    148\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "resnet50 = models.resnet50(weights=True)\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "resnet50.fc = MPSv3(input_dim = resnet50.fc.in_features, degree = 3, num_knots = 10, num_neurons = 100, output_dim = 2, bias = True).to(device)\n",
    "learning_r = 1e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet50.parameters(), lr=learning_r)\n",
    "Iteration = 10000; tor = 1e-5\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.2)\n",
    "early_stopper = EarlyStopper(patience=10, min_delta=1e-5)\n",
    "bloss = 9999\n",
    "\n",
    "for t in range(Iteration):\n",
    "\n",
    "    train_loss = 0\n",
    "    resnet50.train()\n",
    "    for inputs, labels in dataloader:\n",
    "        print(inputs.size())\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet50(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{t+1}/{Iteration}], Loss: {train_loss:.4f}')\n",
    "    if train_loss < bloss:\n",
    "        best_model = resnet50.state_dict()\n",
    "        bloss = train_loss\n",
    "        \n",
    "    scheduler.step(train_loss)\n",
    "\n",
    "    if early_stopper.early_stop(train_loss):\n",
    "        print('Convergence!')\n",
    "        break \n",
    "\n",
    "    resnet50.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "    \n",
    "        outputs = resnet50(X_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        acc = (predicted == y_test).sum()/len(y_test)\n",
    "        print('testing: ', acc.item())\n",
    "        \n",
    "print('Saving the best model ...')\n",
    "torch.save(best_model, './model/MBS_Brain_n'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ea4ba5b-c0cb-4e08-9eff-e0df5aa4441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class TumorClassifier(nn.Module):\n",
    "    def __init__(self, Fin, dg, nk, nm, Fout, bias):\n",
    "        super(TumorClassifier, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.gap = nn.Flatten()\n",
    "        self.classifier = MPSv3(input_dim = Fin, degree = dg, num_knots = nk, num_neurons = nm, output_dim = Fout, bias = True).to(device)\n",
    "        self.sm = nn.Softmax(dim = 1)\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.gap(x)\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        x = self.sm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7a33126-c72e-4a83-899d-a4b5eec9c401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:  1 / 10001  | Loss:  0.635742  | Acc:  0.64\n",
      "| Epoch:  2 / 10001  | Loss:  0.510162  | Acc:  0.838\n",
      "| Epoch:  3 / 10001  | Loss:  0.47011  | Acc:  0.864\n",
      "| Epoch:  4 / 10001  | Loss:  0.442819  | Acc:  0.888\n",
      "| Epoch:  5 / 10001  | Loss:  0.428159  | Acc:  0.91\n",
      "| Epoch:  6 / 10001  | Loss:  0.415759  | Acc:  0.922\n",
      "| Epoch:  7 / 10001  | Loss:  0.407487  | Acc:  0.924\n",
      "| Epoch:  8 / 10001  | Loss:  0.402444  | Acc:  0.932\n",
      "| Epoch:  9 / 10001  | Loss:  0.402321  | Acc:  0.924\n",
      "| Epoch:  10 / 10001  | Loss:  0.396734  | Acc:  0.934\n",
      "tensor(0.9100)\n",
      "| Epoch:  11 / 10001  | Loss:  0.391842  | Acc:  0.936\n",
      "| Epoch:  12 / 10001  | Loss:  0.385826  | Acc:  0.942\n",
      "| Epoch:  13 / 10001  | Loss:  0.38053  | Acc:  0.94\n",
      "| Epoch:  14 / 10001  | Loss:  0.376995  | Acc:  0.948\n",
      "| Epoch:  15 / 10001  | Loss:  0.378152  | Acc:  0.944\n",
      "| Epoch:  16 / 10001  | Loss:  0.372062  | Acc:  0.952\n",
      "| Epoch:  17 / 10001  | Loss:  0.371311  | Acc:  0.952\n",
      "| Epoch:  18 / 10001  | Loss:  0.367258  | Acc:  0.956\n",
      "| Epoch:  19 / 10001  | Loss:  0.367659  | Acc:  0.952\n",
      "| Epoch:  20 / 10001  | Loss:  0.36114  | Acc:  0.962\n",
      "tensor(0.9000)\n",
      "| Epoch:  21 / 10001  | Loss:  0.361278  | Acc:  0.964\n",
      "| Epoch:  22 / 10001  | Loss:  0.358024  | Acc:  0.966\n",
      "| Epoch:  23 / 10001  | Loss:  0.357087  | Acc:  0.97\n",
      "| Epoch:  24 / 10001  | Loss:  0.354648  | Acc:  0.97\n",
      "| Epoch:  25 / 10001  | Loss:  0.357079  | Acc:  0.968\n",
      "| Epoch:  26 / 10001  | Loss:  0.35295  | Acc:  0.97\n",
      "| Epoch:  27 / 10001  | Loss:  0.353107  | Acc:  0.97\n",
      "| Epoch:  28 / 10001  | Loss:  0.350952  | Acc:  0.974\n",
      "| Epoch:  29 / 10001  | Loss:  0.35049  | Acc:  0.97\n",
      "| Epoch:  30 / 10001  | Loss:  0.349677  | Acc:  0.974\n",
      "tensor(0.8900)\n",
      "| Epoch:  31 / 10001  | Loss:  0.353848  | Acc:  0.97\n",
      "| Epoch:  32 / 10001  | Loss:  0.349752  | Acc:  0.968\n",
      "| Epoch:  33 / 10001  | Loss:  0.347495  | Acc:  0.974\n",
      "| Epoch:  34 / 10001  | Loss:  0.347518  | Acc:  0.97\n",
      "| Epoch:  35 / 10001  | Loss:  0.345413  | Acc:  0.976\n",
      "| Epoch:  36 / 10001  | Loss:  0.342937  | Acc:  0.978\n",
      "| Epoch:  37 / 10001  | Loss:  0.343807  | Acc:  0.978\n",
      "| Epoch:  38 / 10001  | Loss:  0.343605  | Acc:  0.978\n",
      "| Epoch:  39 / 10001  | Loss:  0.346848  | Acc:  0.978\n",
      "| Epoch:  40 / 10001  | Loss:  0.34344  | Acc:  0.976\n",
      "tensor(0.8850)\n",
      "| Epoch:  41 / 10001  | Loss:  0.343724  | Acc:  0.978\n",
      "| Epoch:  42 / 10001  | Loss:  0.340744  | Acc:  0.978\n",
      "| Epoch:  43 / 10001  | Loss:  0.338682  | Acc:  0.98\n",
      "| Epoch:  44 / 10001  | Loss:  0.339623  | Acc:  0.98\n",
      "| Epoch:  45 / 10001  | Loss:  0.339309  | Acc:  0.98\n",
      "| Epoch:  46 / 10001  | Loss:  0.338375  | Acc:  0.98\n",
      "| Epoch:  47 / 10001  | Loss:  0.338537  | Acc:  0.982\n",
      "| Epoch:  48 / 10001  | Loss:  0.337286  | Acc:  0.982\n",
      "| Epoch:  49 / 10001  | Loss:  0.336885  | Acc:  0.982\n",
      "| Epoch:  50 / 10001  | Loss:  0.339272  | Acc:  0.982\n",
      "tensor(0.8900)\n",
      "| Epoch:  51 / 10001  | Loss:  0.338094  | Acc:  0.982\n",
      "| Epoch:  52 / 10001  | Loss:  0.336053  | Acc:  0.982\n",
      "| Epoch:  53 / 10001  | Loss:  0.335637  | Acc:  0.982\n",
      "| Epoch:  54 / 10001  | Loss:  0.335534  | Acc:  0.982\n",
      "| Epoch:  55 / 10001  | Loss:  0.334986  | Acc:  0.982\n",
      "| Epoch:  56 / 10001  | Loss:  0.336058  | Acc:  0.982\n",
      "| Epoch:  57 / 10001  | Loss:  0.334841  | Acc:  0.982\n",
      "| Epoch:  58 / 10001  | Loss:  0.335713  | Acc:  0.982\n",
      "| Epoch:  59 / 10001  | Loss:  0.334174  | Acc:  0.982\n",
      "| Epoch:  60 / 10001  | Loss:  0.334074  | Acc:  0.982\n",
      "tensor(0.8900)\n",
      "| Epoch:  61 / 10001  | Loss:  0.333587  | Acc:  0.982\n",
      "| Epoch:  62 / 10001  | Loss:  0.333229  | Acc:  0.984\n",
      "| Epoch:  63 / 10001  | Loss:  0.332829  | Acc:  0.984\n",
      "| Epoch:  64 / 10001  | Loss:  0.332589  | Acc:  0.984\n",
      "| Epoch:  65 / 10001  | Loss:  0.333081  | Acc:  0.984\n",
      "| Epoch:  66 / 10001  | Loss:  0.332394  | Acc:  0.984\n",
      "| Epoch:  67 / 10001  | Loss:  0.331416  | Acc:  0.984\n",
      "| Epoch:  68 / 10001  | Loss:  0.331004  | Acc:  0.984\n",
      "| Epoch:  69 / 10001  | Loss:  0.331512  | Acc:  0.988\n",
      "| Epoch:  70 / 10001  | Loss:  0.329588  | Acc:  0.988\n",
      "tensor(0.8950)\n",
      "| Epoch:  71 / 10001  | Loss:  0.32984  | Acc:  0.988\n",
      "| Epoch:  72 / 10001  | Loss:  0.328616  | Acc:  0.988\n",
      "| Epoch:  73 / 10001  | Loss:  0.328231  | Acc:  0.988\n",
      "| Epoch:  74 / 10001  | Loss:  0.32791  | Acc:  0.988\n",
      "| Epoch:  75 / 10001  | Loss:  0.32725  | Acc:  0.988\n",
      "| Epoch:  76 / 10001  | Loss:  0.328381  | Acc:  0.988\n",
      "| Epoch:  77 / 10001  | Loss:  0.326747  | Acc:  0.99\n",
      "| Epoch:  78 / 10001  | Loss:  0.328933  | Acc:  0.99\n",
      "| Epoch:  79 / 10001  | Loss:  0.326786  | Acc:  0.99\n",
      "| Epoch:  80 / 10001  | Loss:  0.326557  | Acc:  0.99\n",
      "tensor(0.9000)\n",
      "| Epoch:  81 / 10001  | Loss:  0.326017  | Acc:  0.99\n",
      "| Epoch:  82 / 10001  | Loss:  0.326154  | Acc:  0.99\n",
      "| Epoch:  83 / 10001  | Loss:  0.325835  | Acc:  0.99\n",
      "| Epoch:  84 / 10001  | Loss:  0.325695  | Acc:  0.99\n",
      "| Epoch:  85 / 10001  | Loss:  0.32585  | Acc:  0.99\n",
      "| Epoch:  86 / 10001  | Loss:  0.32543  | Acc:  0.99\n",
      "| Epoch:  87 / 10001  | Loss:  0.326045  | Acc:  0.99\n",
      "| Epoch:  88 / 10001  | Loss:  0.325782  | Acc:  0.99\n",
      "| Epoch:  89 / 10001  | Loss:  0.325169  | Acc:  0.99\n",
      "| Epoch:  90 / 10001  | Loss:  0.325033  | Acc:  0.99\n",
      "tensor(0.9050)\n",
      "| Epoch:  91 / 10001  | Loss:  0.325102  | Acc:  0.99\n",
      "| Epoch:  92 / 10001  | Loss:  0.324991  | Acc:  0.99\n",
      "| Epoch:  93 / 10001  | Loss:  0.32476  | Acc:  0.99\n",
      "| Epoch:  94 / 10001  | Loss:  0.324822  | Acc:  0.99\n",
      "| Epoch:  95 / 10001  | Loss:  0.325863  | Acc:  0.99\n",
      "| Epoch:  96 / 10001  | Loss:  0.325794  | Acc:  0.99\n",
      "| Epoch:  97 / 10001  | Loss:  0.324662  | Acc:  0.99\n",
      "| Epoch:  98 / 10001  | Loss:  0.324572  | Acc:  0.99\n",
      "| Epoch:  99 / 10001  | Loss:  0.324504  | Acc:  0.99\n",
      "| Epoch:  100 / 10001  | Loss:  0.324521  | Acc:  0.99\n",
      "tensor(0.9050)\n",
      "| Epoch:  101 / 10001  | Loss:  0.32447  | Acc:  0.99\n",
      "| Epoch:  102 / 10001  | Loss:  0.325633  | Acc:  0.99\n",
      "| Epoch:  103 / 10001  | Loss:  0.324348  | Acc:  0.99\n",
      "| Epoch:  104 / 10001  | Loss:  0.324328  | Acc:  0.99\n",
      "| Epoch:  105 / 10001  | Loss:  0.324324  | Acc:  0.99\n",
      "| Epoch:  106 / 10001  | Loss:  0.324257  | Acc:  0.99\n",
      "| Epoch:  107 / 10001  | Loss:  0.325432  | Acc:  0.99\n",
      "| Epoch:  108 / 10001  | Loss:  0.32428  | Acc:  0.99\n",
      "| Epoch:  109 / 10001  | Loss:  0.325345  | Acc:  0.99\n",
      "| Epoch:  110 / 10001  | Loss:  0.325335  | Acc:  0.99\n",
      "tensor(0.9050)\n",
      "| Epoch:  111 / 10001  | Loss:  0.324105  | Acc:  0.99\n",
      "| Epoch:  112 / 10001  | Loss:  0.324149  | Acc:  0.99\n",
      "| Epoch:  113 / 10001  | Loss:  0.324096  | Acc:  0.99\n",
      "| Epoch:  114 / 10001  | Loss:  0.324092  | Acc:  0.99\n",
      "| Epoch:  115 / 10001  | Loss:  0.325171  | Acc:  0.99\n",
      "| Epoch:  116 / 10001  | Loss:  0.323982  | Acc:  0.99\n",
      "| Epoch:  117 / 10001  | Loss:  0.324066  | Acc:  0.99\n",
      "| Epoch:  118 / 10001  | Loss:  0.323948  | Acc:  0.99\n",
      "| Epoch:  119 / 10001  | Loss:  0.325122  | Acc:  0.99\n",
      "| Epoch:  120 / 10001  | Loss:  0.32396  | Acc:  0.99\n",
      "tensor(0.9100)\n",
      "| Epoch:  121 / 10001  | Loss:  0.323887  | Acc:  0.99\n",
      "| Epoch:  122 / 10001  | Loss:  0.32505  | Acc:  0.99\n",
      "| Epoch:  123 / 10001  | Loss:  0.325044  | Acc:  0.99\n",
      "| Epoch:  124 / 10001  | Loss:  0.323843  | Acc:  0.99\n",
      "| Epoch:  125 / 10001  | Loss:  0.323823  | Acc:  0.99\n",
      "| Epoch:  126 / 10001  | Loss:  0.32381  | Acc:  0.99\n",
      "| Epoch:  127 / 10001  | Loss:  0.323806  | Acc:  0.99\n",
      "| Epoch:  128 / 10001  | Loss:  0.323782  | Acc:  0.99\n",
      "| Epoch:  129 / 10001  | Loss:  0.323763  | Acc:  0.99\n",
      "| Epoch:  130 / 10001  | Loss:  0.323772  | Acc:  0.99\n",
      "tensor(0.9100)\n",
      "| Epoch:  131 / 10001  | Loss:  0.323745  | Acc:  0.99\n",
      "| Epoch:  132 / 10001  | Loss:  0.323724  | Acc:  0.99\n",
      "| Epoch:  133 / 10001  | Loss:  0.323709  | Acc:  0.99\n",
      "| Epoch:  134 / 10001  | Loss:  0.324881  | Acc:  0.99\n",
      "| Epoch:  135 / 10001  | Loss:  0.323699  | Acc:  0.99\n",
      "| Epoch:  136 / 10001  | Loss:  0.323668  | Acc:  0.99\n",
      "| Epoch:  137 / 10001  | Loss:  0.325989  | Acc:  0.99\n",
      "| Epoch:  138 / 10001  | Loss:  0.323645  | Acc:  0.99\n",
      "| Epoch:  139 / 10001  | Loss:  0.323657  | Acc:  0.99\n",
      "| Epoch:  140 / 10001  | Loss:  0.324786  | Acc:  0.99\n",
      "tensor(0.9050)\n",
      "| Epoch:  141 / 10001  | Loss:  0.32478  | Acc:  0.99\n",
      "| Epoch:  142 / 10001  | Loss:  0.32477  | Acc:  0.99\n",
      "| Epoch:  143 / 10001  | Loss:  0.324758  | Acc:  0.99\n",
      "| Epoch:  144 / 10001  | Loss:  0.32357  | Acc:  0.99\n",
      "| Epoch:  145 / 10001  | Loss:  0.324748  | Acc:  0.99\n",
      "| Epoch:  146 / 10001  | Loss:  0.323576  | Acc:  0.99\n",
      "| Epoch:  147 / 10001  | Loss:  0.323591  | Acc:  0.99\n",
      "| Epoch:  148 / 10001  | Loss:  0.323563  | Acc:  0.99\n",
      "| Epoch:  149 / 10001  | Loss:  0.323567  | Acc:  0.99\n",
      "| Epoch:  150 / 10001  | Loss:  0.323563  | Acc:  0.99\n",
      "tensor(0.9100)\n",
      "| Epoch:  151 / 10001  | Loss:  0.32355  | Acc:  0.99\n",
      "| Epoch:  152 / 10001  | Loss:  0.324727  | Acc:  0.99\n",
      "| Epoch:  153 / 10001  | Loss:  0.323553  | Acc:  0.99\n",
      "| Epoch:  154 / 10001  | Loss:  0.323556  | Acc:  0.99\n",
      "| Epoch:  155 / 10001  | Loss:  0.323569  | Acc:  0.99\n",
      "| Epoch:  156 / 10001  | Loss:  0.323556  | Acc:  0.99\n",
      "| Epoch:  157 / 10001  | Loss:  0.323574  | Acc:  0.99\n",
      "| Epoch:  158 / 10001  | Loss:  0.32356  | Acc:  0.99\n",
      "| Epoch:  159 / 10001  | Loss:  0.323548  | Acc:  0.99\n",
      "| Epoch:  160 / 10001  | Loss:  0.324732  | Acc:  0.99\n",
      "tensor(0.9100)\n",
      "| Epoch:  161 / 10001  | Loss:  0.323555  | Acc:  0.99\n",
      "| Epoch:  162 / 10001  | Loss:  0.323554  | Acc:  0.99\n",
      "| Epoch:  163 / 10001  | Loss:  0.324732  | Acc:  0.99\n",
      "| Epoch:  164 / 10001  | Loss:  0.323552  | Acc:  0.99\n",
      "| Epoch:  165 / 10001  | Loss:  0.323555  | Acc:  0.99\n",
      "| Epoch:  166 / 10001  | Loss:  0.324718  | Acc:  0.99\n",
      "| Epoch:  167 / 10001  | Loss:  0.324735  | Acc:  0.99\n",
      "| Epoch:  168 / 10001  | Loss:  0.323562  | Acc:  0.99\n",
      "| Epoch:  169 / 10001  | Loss:  0.323575  | Acc:  0.99\n",
      "| Epoch:  170 / 10001  | Loss:  0.323544  | Acc:  0.99\n",
      "tensor(0.9100)\n",
      "| Epoch:  171 / 10001  | Loss:  0.323559  | Acc:  0.99\n",
      "| Epoch:  172 / 10001  | Loss:  0.323556  | Acc:  0.99\n",
      "| Epoch:  173 / 10001  | Loss:  0.324734  | Acc:  0.99\n",
      "| Epoch:  174 / 10001  | Loss:  0.324722  | Acc:  0.99\n",
      "| Epoch:  175 / 10001  | Loss:  0.323546  | Acc:  0.99\n",
      "| Epoch:  176 / 10001  | Loss:  0.323555  | Acc:  0.99\n",
      "| Epoch:  177 / 10001  | Loss:  0.323553  | Acc:  0.99\n",
      "| Epoch:  178 / 10001  | Loss:  0.323548  | Acc:  0.99\n",
      "| Epoch:  179 / 10001  | Loss:  0.323547  | Acc:  0.99\n",
      "| Epoch:  180 / 10001  | Loss:  0.324744  | Acc:  0.99\n",
      "tensor(0.9100)\n",
      "| Epoch:  181 / 10001  | Loss:  0.323557  | Acc:  0.99\n",
      "| Epoch:  182 / 10001  | Loss:  0.323546  | Acc:  0.99\n",
      "| Epoch:  183 / 10001  | Loss:  0.323554  | Acc:  0.99\n",
      "| Epoch:  184 / 10001  | Loss:  0.323552  | Acc:  0.99\n",
      "| Epoch:  185 / 10001  | Loss:  0.323547  | Acc:  0.99\n",
      "| Epoch:  186 / 10001  | Loss:  0.323558  | Acc:  0.99\n",
      "| Epoch:  187 / 10001  | Loss:  0.323557  | Acc:  0.99\n",
      "Convergence!\n",
      "Saving the best model ...\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(X_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "nk = 10; nm = 50; doutput = 2\n",
    "tmc = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True)\n",
    "\n",
    "learning_r = 1e-2\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(tmc.parameters(), lr=learning_r)\n",
    "Iteration = 10001; bloss_list = []; tor = 1e-5; bloss = 9999\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.2)\n",
    "early_stopper = EarlyStopper(patience=10, min_delta=1e-5)\n",
    "\n",
    "for t in range(Iteration):\n",
    "\n",
    "    tmc.train()\n",
    "    # Forward pass: Compute predicted y by passing x to the modelsp\n",
    "\n",
    "    train_loss = 0\n",
    "    pch_acc = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = tmc(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss\n",
    "        pch_acc += (torch.argmax(outputs, axis = 1) == labels).sum()\n",
    "\n",
    "    avg_train_acc = pch_acc.item()/len(y_train)\n",
    "    avg_train_loss = np.round(train_loss.item()/len(dataloader), 6)\n",
    "    scheduler.step(avg_train_loss)\n",
    "\n",
    "    if avg_train_loss < bloss:\n",
    "        best_model = tmc.state_dict()\n",
    "        bloss = avg_train_loss\n",
    "\n",
    "    if early_stopper.early_stop(avg_train_loss):\n",
    "        print('Convergence!')\n",
    "        break \n",
    "        \n",
    "    print('| Epoch: ',t+1,'/',str(Iteration),' | Loss: ', avg_train_loss,' | Acc: ', avg_train_acc)\n",
    "    \n",
    "    tmc.eval()\n",
    "    if((t+1) % 10 == 0):\n",
    "        with torch.no_grad():\n",
    "            avg_test_acc = (torch.argmax(tmc(X_test).detach(), axis = 1) == y_test).sum()/len(y_test)\n",
    "            print(avg_test_acc)\n",
    "\n",
    "print('Saving the best model ...')\n",
    "torch.save(best_model, './model/MBS_Brain_n'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7716140-cc46-44fe-8534-9ce8083ca567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Before adding penalty ... \n",
      "------------------------------------------\n",
      "After adding penalty ... \n",
      "Lambda:  0.16596 | Training Loss:  0.32379\n",
      "Lambda:  0.166 | Training Loss:  0.32379\n",
      "Lambda:  0.16604 | Training Loss:  0.32379\n",
      "Lambda:  0.16607 | Training Loss:  0.32379\n",
      "Lambda:  0.16611 | Training Loss:  0.3238\n",
      "Lambda:  0.16615 | Training Loss:  0.3238\n",
      "Lambda:  0.16618 | Training Loss:  0.3238\n",
      "Lambda:  0.16622 | Training Loss:  0.3238\n",
      "Lambda:  0.16625 | Training Loss:  0.3238\n",
      "Lambda:  0.16629 | Training Loss:  0.3238\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print('------------------------------------------')\n",
    "    print('Before adding penalty ... ')\n",
    "    eval_model = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "    eval_model.load_state_dict(torch.load('./model/MBS_Brain_n'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "    print('------------------------------------------')\n",
    "    print('After adding penalty ... ')\n",
    "\n",
    "    \n",
    "    WB = eval_model.classifier.sp1.control_p\n",
    "    DB = diag_mat_weights(WB.size()[0], 'second').to(device)\n",
    "    Bestloss = 9999\n",
    "    \n",
    "    for i in range(10):\n",
    "        MPSy = eval_model(X_train)\n",
    "        LambdaB1 = ECM(model = eval_model.classifier, num_neurons = nm, num_knots = nk, L = 1)\n",
    "        B1 = eval_model.classifier.inter['ebasic']\n",
    "        P2 = (torch.linalg.pinv(B1.T @ B1) @ B1.T @ B1)\n",
    "        By1 = eval_model.classifier.inter['basic']        \n",
    "        size1 = B1.size()[1]\n",
    "        B1 = B1.view(nm, nk, size1)\n",
    "        NW1 = torch.empty((nk, nm))\n",
    "        NB1 = torch.empty((nm))\n",
    "        for i in range(nm):\n",
    "            B1y = By1[:,i] - eval_model.classifier.sp1.bias.data[i]\n",
    "            BB1 = B1[i].T\n",
    "            PB1 = (torch.linalg.pinv(BB1.T @ BB1) @ BB1.T @ BB1)\n",
    "            # Update the weights and bias\n",
    "            NW1[:, i] = (torch.inverse(BB1.T @ BB1 + (LambdaB1/size1) * (DB.T @ DB)) @ BB1.T @ B1y)\n",
    "            NB1[i] = torch.mean(By1[:,i] - (NW1[:,i] @ BB1.T))\n",
    "            \n",
    "        # update the weight\n",
    "        getattr(eval_model.classifier.sp1, 'control_p').data = NW1\n",
    "        getattr(eval_model.classifier.sp1, 'bias').data = NB1\n",
    "        \n",
    "\n",
    "        MPSy = eval_model(X_train)\n",
    "        trainloss = np.round(criterion(MPSy.detach(), y_train).item(), 5)\n",
    "        \n",
    "        if trainloss < Bestloss:\n",
    "            BestLambdaB = LambdaB1\n",
    "            Bestloss = trainloss\n",
    "            \n",
    "        print('Lambda: ', np.round(LambdaB1, 5),'| Training Loss: ', trainloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e08dd658-eb5f-4c03-bdc2-a3a77ed94eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:  2 / 10001  | Loss:  0.339708  | Acc:  0.99\n",
      "| Epoch:  3 / 10001  | Loss:  0.339449  | Acc:  0.99\n",
      "| Epoch:  4 / 10001  | Loss:  0.339459  | Acc:  0.99\n",
      "| Epoch:  5 / 10001  | Loss:  0.339493  | Acc:  0.99\n",
      "| Epoch:  6 / 10001  | Loss:  0.340683  | Acc:  0.99\n",
      "| Epoch:  7 / 10001  | Loss:  0.339579  | Acc:  0.99\n",
      "| Epoch:  8 / 10001  | Loss:  0.339762  | Acc:  0.99\n",
      "| Epoch:  9 / 10001  | Loss:  0.339756  | Acc:  0.99\n",
      "| Epoch:  10 / 10001  | Loss:  0.339755  | Acc:  0.99\n",
      "tensor(0.9100)\n",
      "| Epoch:  11 / 10001  | Loss:  0.339774  | Acc:  0.99\n",
      "| Epoch:  12 / 10001  | Loss:  0.339819  | Acc:  0.99\n",
      "| Epoch:  13 / 10001  | Loss:  0.33984  | Acc:  0.99\n",
      "Convergence!\n",
      "tensor(0.9100)\n"
     ]
    }
   ],
   "source": [
    "fast_epoch = 10001\n",
    "eval_model = TumorClassifier(Fin = 100352, dg = 3, nk = nk, nm = nm, Fout = doutput, bias = True).to(device)\n",
    "eval_model.load_state_dict(torch.load('./model/MBS_Brain_n'+str(X_train.size()[0])+'h'+str(nm)+'k'+str(nk), weights_only = True))\n",
    "lr_ft = 1e-2\n",
    "optimizer = torch.optim.Adam(eval_model.parameters(), lr=lr_ft)\n",
    "early_stopper = EarlyStopper(patience=10, min_delta=1e-5)\n",
    "\n",
    "for t in range(1, fast_epoch):\n",
    "\n",
    "    eval_model.train()\n",
    "    # Forward pass: Compute predicted y by passing x to the modelsp\n",
    "\n",
    "    WB1 = eval_model.classifier.sp1.control_p.data; DB1 = diag_mat_weights(WB1.size()[0]).to(device)\n",
    "\n",
    "\n",
    "    train_loss = 0\n",
    "    pch_acc = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = eval_model(inputs)\n",
    "        loss = criterion(outputs, labels) + (BestLambdaB/len(y_train)) * torch.norm(DB1 @ WB1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss\n",
    "        pch_acc += (torch.argmax(outputs, axis = 1) == labels).sum()\n",
    "\n",
    "    avg_train_acc = pch_acc.item()/len(y_train)\n",
    "    avg_train_loss = np.round(train_loss.item()/len(dataloader), 6)\n",
    "    scheduler.step(avg_train_loss)\n",
    "\n",
    "    if avg_train_loss < bloss:\n",
    "        best_model = eval_model.state_dict()\n",
    "        bloss = avg_train_loss\n",
    "\n",
    "    if early_stopper.early_stop(avg_train_loss):\n",
    "        print('Convergence!')\n",
    "        with torch.no_grad():\n",
    "            avg_test_acc = (torch.argmax(eval_model(X_test).detach(), axis = 1) == y_test).sum()/len(y_test)\n",
    "            print(avg_test_acc)\n",
    "            \n",
    "        break \n",
    "        \n",
    "    print('| Epoch: ',t+1,'/',str(Iteration),' | Loss: ', avg_train_loss,' | Acc: ', avg_train_acc)\n",
    "    \n",
    "    eval_model.eval()\n",
    "    if((t+1) % 10 == 0):\n",
    "        with torch.no_grad():\n",
    "            avg_test_acc = (torch.argmax(eval_model(X_test).detach(), axis = 1) == y_test).sum()/len(y_test)\n",
    "            print(avg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211079a0-175d-4bbd-8648-bfa5aed68c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d6899c-1f14-47c2-a974-f87893f6e7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddb97e5b-089e-4ad7-ae5f-eb0498a157d4",
   "metadata": {},
   "source": [
    "## CNN - GAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "066c7504-8df8-460e-b68b-6856ef89851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(32, 2)\n",
    "        #self.flatten = nn.Flatten()\n",
    "        self.sm = nn.Softmax(dim = 1)\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        x = self.sm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7001f6b2-a590-4c84-af3e-eab25a8295e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:  1 / 10001  | Loss:  0.684353  | Acc:  0.582\n",
      "| Epoch:  2 / 10001  | Loss:  0.660086  | Acc:  0.5\n",
      "| Epoch:  3 / 10001  | Loss:  0.636794  | Acc:  0.5\n",
      "| Epoch:  4 / 10001  | Loss:  0.60846  | Acc:  0.652\n",
      "| Epoch:  5 / 10001  | Loss:  0.563874  | Acc:  0.844\n",
      "| Epoch:  6 / 10001  | Loss:  0.521396  | Acc:  0.886\n",
      "| Epoch:  7 / 10001  | Loss:  0.49721  | Acc:  0.878\n",
      "| Epoch:  8 / 10001  | Loss:  0.474551  | Acc:  0.886\n",
      "| Epoch:  9 / 10001  | Loss:  0.471732  | Acc:  0.87\n",
      "| Epoch:  10 / 10001  | Loss:  0.458934  | Acc:  0.886\n",
      "tensor(0.8050)\n",
      "| Epoch:  11 / 10001  | Loss:  0.449763  | Acc:  0.898\n",
      "| Epoch:  12 / 10001  | Loss:  0.448291  | Acc:  0.894\n",
      "| Epoch:  13 / 10001  | Loss:  0.443393  | Acc:  0.896\n",
      "| Epoch:  14 / 10001  | Loss:  0.440811  | Acc:  0.898\n",
      "| Epoch:  15 / 10001  | Loss:  0.439684  | Acc:  0.892\n",
      "| Epoch:  16 / 10001  | Loss:  0.43945  | Acc:  0.896\n",
      "| Epoch:  17 / 10001  | Loss:  0.434486  | Acc:  0.894\n",
      "| Epoch:  18 / 10001  | Loss:  0.435455  | Acc:  0.89\n",
      "| Epoch:  19 / 10001  | Loss:  0.442701  | Acc:  0.874\n",
      "| Epoch:  20 / 10001  | Loss:  0.430355  | Acc:  0.898\n",
      "tensor(0.8100)\n",
      "| Epoch:  21 / 10001  | Loss:  0.428052  | Acc:  0.894\n",
      "| Epoch:  22 / 10001  | Loss:  0.427915  | Acc:  0.898\n",
      "| Epoch:  23 / 10001  | Loss:  0.428489  | Acc:  0.892\n",
      "| Epoch:  24 / 10001  | Loss:  0.426329  | Acc:  0.89\n",
      "| Epoch:  25 / 10001  | Loss:  0.426796  | Acc:  0.888\n",
      "| Epoch:  26 / 10001  | Loss:  0.426277  | Acc:  0.894\n",
      "| Epoch:  27 / 10001  | Loss:  0.424308  | Acc:  0.884\n",
      "| Epoch:  28 / 10001  | Loss:  0.42844  | Acc:  0.896\n",
      "| Epoch:  29 / 10001  | Loss:  0.426494  | Acc:  0.902\n",
      "| Epoch:  30 / 10001  | Loss:  0.422924  | Acc:  0.902\n",
      "tensor(0.8150)\n",
      "| Epoch:  31 / 10001  | Loss:  0.425323  | Acc:  0.896\n",
      "| Epoch:  32 / 10001  | Loss:  0.422136  | Acc:  0.892\n",
      "| Epoch:  33 / 10001  | Loss:  0.4266  | Acc:  0.892\n",
      "| Epoch:  34 / 10001  | Loss:  0.420992  | Acc:  0.898\n",
      "| Epoch:  35 / 10001  | Loss:  0.417896  | Acc:  0.898\n",
      "| Epoch:  36 / 10001  | Loss:  0.422799  | Acc:  0.888\n",
      "| Epoch:  37 / 10001  | Loss:  0.418035  | Acc:  0.896\n",
      "| Epoch:  38 / 10001  | Loss:  0.41955  | Acc:  0.892\n",
      "| Epoch:  39 / 10001  | Loss:  0.426975  | Acc:  0.892\n",
      "| Epoch:  40 / 10001  | Loss:  0.429622  | Acc:  0.89\n",
      "tensor(0.8200)\n",
      "| Epoch:  41 / 10001  | Loss:  0.422055  | Acc:  0.888\n",
      "| Epoch:  42 / 10001  | Loss:  0.418017  | Acc:  0.898\n",
      "| Epoch:  43 / 10001  | Loss:  0.417262  | Acc:  0.894\n",
      "| Epoch:  44 / 10001  | Loss:  0.419806  | Acc:  0.894\n",
      "| Epoch:  45 / 10001  | Loss:  0.415345  | Acc:  0.896\n",
      "| Epoch:  46 / 10001  | Loss:  0.421405  | Acc:  0.89\n",
      "| Epoch:  47 / 10001  | Loss:  0.416827  | Acc:  0.9\n",
      "| Epoch:  48 / 10001  | Loss:  0.417486  | Acc:  0.898\n",
      "| Epoch:  49 / 10001  | Loss:  0.416238  | Acc:  0.894\n",
      "| Epoch:  50 / 10001  | Loss:  0.417388  | Acc:  0.892\n",
      "tensor(0.8150)\n",
      "| Epoch:  51 / 10001  | Loss:  0.415294  | Acc:  0.892\n",
      "| Epoch:  52 / 10001  | Loss:  0.418196  | Acc:  0.894\n",
      "| Epoch:  53 / 10001  | Loss:  0.417005  | Acc:  0.894\n",
      "| Epoch:  54 / 10001  | Loss:  0.418367  | Acc:  0.892\n",
      "| Epoch:  55 / 10001  | Loss:  0.415562  | Acc:  0.892\n",
      "| Epoch:  56 / 10001  | Loss:  0.415424  | Acc:  0.894\n",
      "| Epoch:  57 / 10001  | Loss:  0.414879  | Acc:  0.894\n",
      "| Epoch:  58 / 10001  | Loss:  0.416114  | Acc:  0.894\n",
      "| Epoch:  59 / 10001  | Loss:  0.417923  | Acc:  0.898\n",
      "| Epoch:  60 / 10001  | Loss:  0.416608  | Acc:  0.894\n",
      "tensor(0.8200)\n",
      "| Epoch:  61 / 10001  | Loss:  0.415711  | Acc:  0.896\n",
      "| Epoch:  62 / 10001  | Loss:  0.415691  | Acc:  0.894\n",
      "| Epoch:  63 / 10001  | Loss:  0.41539  | Acc:  0.896\n",
      "| Epoch:  64 / 10001  | Loss:  0.414801  | Acc:  0.892\n",
      "| Epoch:  65 / 10001  | Loss:  0.41514  | Acc:  0.892\n",
      "| Epoch:  66 / 10001  | Loss:  0.415162  | Acc:  0.892\n",
      "| Epoch:  67 / 10001  | Loss:  0.415429  | Acc:  0.892\n",
      "| Epoch:  68 / 10001  | Loss:  0.418603  | Acc:  0.894\n",
      "| Epoch:  69 / 10001  | Loss:  0.415864  | Acc:  0.894\n",
      "| Epoch:  70 / 10001  | Loss:  0.417762  | Acc:  0.892\n",
      "tensor(0.8150)\n",
      "| Epoch:  71 / 10001  | Loss:  0.416877  | Acc:  0.892\n",
      "| Epoch:  72 / 10001  | Loss:  0.414865  | Acc:  0.892\n",
      "| Epoch:  73 / 10001  | Loss:  0.418878  | Acc:  0.892\n",
      "Convergence!\n",
      "tensor(0.8100)\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(X_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "cnn = CNN()\n",
    "\n",
    "learning_r = 1e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_r)\n",
    "Iteration = 10001; tor = 1e-5; bloss = 9999\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.2)\n",
    "early_stopper = EarlyStopper(patience=10, min_delta=1e-5)\n",
    "\n",
    "for t in range(Iteration):\n",
    "\n",
    "    cnn.train()\n",
    "    # Forward pass: Compute predicted y by passing x to the modelsp\n",
    "\n",
    "    train_loss = 0\n",
    "    pch_acc = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss\n",
    "        pch_acc += (torch.argmax(outputs, axis = 1) == labels).sum()\n",
    "\n",
    "    avg_train_acc = pch_acc.item()/len(y_train)\n",
    "    avg_train_loss = np.round(train_loss.item()/len(dataloader), 6)\n",
    "    scheduler.step(avg_train_loss)\n",
    "\n",
    "    if avg_train_loss < bloss:\n",
    "        best_model = cnn.state_dict()\n",
    "        bloss = avg_train_loss\n",
    "\n",
    "    if early_stopper.early_stop(avg_train_loss):\n",
    "        print('Convergence!')\n",
    "        with torch.no_grad():\n",
    "            avg_test_acc = (torch.argmax(cnn(X_test).detach(), axis = 1) == y_test).sum()/len(y_test)\n",
    "            print(avg_test_acc)\n",
    "        break \n",
    "        \n",
    "    print('| Epoch: ',t+1,'/',str(Iteration),' | Loss: ', avg_train_loss,' | Acc: ', avg_train_acc)\n",
    "    \n",
    "    tmc.eval()\n",
    "    if((t+1) % 10 == 0):\n",
    "        with torch.no_grad():\n",
    "            avg_test_acc = (torch.argmax(cnn(X_test).detach(), axis = 1) == y_test).sum()/len(y_test)\n",
    "            print(avg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb323709-4714-43e6-b8d3-608b41179312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07b9d3f-6c96-455e-a47f-9d373b800622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
